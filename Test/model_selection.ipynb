{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42744f82",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91bed7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python313.zip', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\DLLs', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313', '', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\viett\\\\label-studio', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\Pythonwin', '..', '..', '..', '..', '..', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from tools.fetching_description_from_huggingface import fetching_description_from_huggingface\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "22abc01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STT</th>\n",
       "      <th>Task</th>\n",
       "      <th>Validation data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nNh·∫≠n d·∫°ng ch·ªØ vi·∫øt ta...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nTrong th·ªùi ƒë·∫°i th√¥ng t...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nƒê√¢y l√† m·ªôt nhi·ªám v·ª• h·ªì...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nƒêi·ªÅu quan tr·ªçng l√† c√°c...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nTrong nhi·ªÅu ·ª©ng d·ª•ng t...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STT                                               Task Validation data\n",
       "0    1  \"B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nNh·∫≠n d·∫°ng ch·ªØ vi·∫øt ta...            Link\n",
       "1    2  B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nTrong th·ªùi ƒë·∫°i th√¥ng t...            Link\n",
       "2    3  B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nƒê√¢y l√† m·ªôt nhi·ªám v·ª• h·ªì...            Link\n",
       "3    4  B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nƒêi·ªÅu quan tr·ªçng l√† c√°c...            Link\n",
       "4    5  B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nTrong nhi·ªÅu ·ª©ng d·ª•ng t...            Link"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "953cae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\\r\\nNh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay l√† m·ªôt b√†i to√°n c∆° b·∫£n trong lƒ©nh v·ª±c h·ªçc m√°y v√† x·ª≠ l√Ω ·∫£nh, v·ªõi nhi·ªÅu ·ª©ng d·ª•ng th·ª±c ti·ªÖn nh∆∞ nh·∫≠n d·∫°ng ch·ªØ s·ªë tr√™n phi·∫øu kh·∫£o s√°t, h√≥a ƒë∆°n hay b√†i thi t·ª± ƒë·ªông. Vi·ªác ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay th√†nh s·ªë nguy√™n t·ªë ho·∫∑c kh√¥ng gi√∫p m·ªü r·ªông kh·∫£ nƒÉng ·ª©ng d·ª•ng trong c√°c b√†i to√°n to√°n h·ªçc t·ª± ƒë·ªông, ki·ªÉm tra b√†i t·∫≠p, ho·∫∑c c√°c ·ª©ng d·ª•ng gi√°o d·ª•c.\\r\\n\\r\\nY√™u c·∫ßu c·ª• th·ªÉ c·∫ßn ƒë·∫°t ƒë∆∞·ª£c:\\r\\nX√¢y d·ª±ng m·ªôt h·ªá th·ªëng c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ ·∫£nh v√† x√°c ƒë·ªãnh xem s·ªë ƒë√≥ c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng.\\r\\nƒê·∫ßu v√†o l√† ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay.\\r\\nƒê·∫ßu ra l√† nh√£n ph√¢n lo·∫°i nh·ªã ph√¢n: \"\"nguy√™n t·ªë\"\" ho·∫∑c \"\"kh√¥ng nguy√™n t·ªë\"\".\\r\\n\\r\\nƒê·ªãnh d·∫°ng d·ªØ li·ªáu ƒë·∫ßu v√†o cho b√†i to√°n t·ªïng th·ªÉ:\\r\\nM·ªôt th∆∞ m·ª•c c√≥ t√™n l√† \"\"images\"\" ch·ª©a c√°c ·∫£nh grayscale 28x28 pixel, m·ªói ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9.\\r\\n\\r\\nƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ƒë·∫ßu ra mong mu·ªën cho b√†i to√°n t·ªïng th·ªÉ:\\r\\nFile output.csv m·ªói h√†ng l√† k·∫øt qu·∫£ d·ª± ƒëo√°n m·ªói ·∫£nh\\r\\nc√≥ c√°c c·ªôt:\\r\\nfile_name: t√™n file ·∫£nh\\r\\nprediction: nh√£n c·ªßa ·∫£nh:\\r\\n\"\"s·ªë nguy√™n t·ªë\"\" n·∫øu s·ªë trong ·∫£nh l√† s·ªë nguy√™n t·ªë.\\r\\n\"\"kh√¥ng nguy√™n t·ªë\"\" n·∫øu s·ªë trong ·∫£nh kh√¥ng ph·∫£i s·ªë nguy√™n t·ªë.\"'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af3bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    # scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    # scrape_status = scraper.scrape_url(\n",
    "    #     url,\n",
    "    #     formats=['markdown']\n",
    "    # )\n",
    "    # return scrape_status.markdown\n",
    "    result = fetching_description_from_huggingface(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77f3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperParameters(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6a0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52a9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409f8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6511a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0de6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef593964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14b15c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = classify_agent(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab3d7f",
   "metadata": {},
   "source": [
    "# Modeling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f656ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInfo(BaseModel):\n",
    "    model: str = Field(..., description=\"Model name\")\n",
    "    url: str = Field(..., description=\"URL to the model\")\n",
    "\n",
    "class ModelSelection(BaseModel):\n",
    "    models: List[ModelInfo] = Field(..., description=\"List of available models with name and URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "18dcc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_parser = PydanticOutputParser(pydantic_object=ModelSelection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de4ed792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the suitable model for a given task.\n",
    "                    Given:\n",
    "                    - A user description about the task\n",
    "                    - A list of available model (names and links)\n",
    "                    Your job is to choose ALL suitable models provided in the list for user's specific tasks.\n",
    "                    Return the answer in the format\n",
    "                    {structured_output}\n",
    "                    Here are the list of model:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]).partial(structured_output=model_selection_parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | model_selection_parser\n",
    "\n",
    "    result = chain.invoke({\"input\": task, \"model_list\": format_model_list(df_model)})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd097a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viett\\AppData\\Local\\Temp\\ipykernel_33328\\7332665.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
      "C:\\Users\\viett\\AppData\\Local\\Temp\\ipykernel_33328\\7332665.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = str(row[2])\n"
     ]
    }
   ],
   "source": [
    "res = model_selection_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03a8819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelInfo(model='Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay', url='https://huggingface.co/thanhtlx/image_classification_01')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3b0dc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_using_tool_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the **Best-fit model** for a given task.\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and url)\n",
    "                    - A tool that fetches model details from a provided URL (it help gathers model description, input/output format, code sample usage)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - ‚úÖ Model description\n",
    "                        - üì• Input format\n",
    "                        - üì§ Output format\n",
    "                        - üõ†Ô∏è Library requirements\n",
    "                        - üß™ Code sample (usage code snippet)\n",
    "                    2. Select the best model for user given task based on the data that the tool gives you.\n",
    "\n",
    "                    ‚ö†Ô∏è VERY IMPORTANT RULES\n",
    "\n",
    "                    - ‚ùå DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - ‚ùå DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - ‚úÖ ONLY use the **actual output** returned from the tool\n",
    "                    - ‚úÖ Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ## üß† Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **‚úÖ Model name and link**  \n",
    "                    `<model name>` ‚Äî `<link>`\n",
    "\n",
    "                    **üìù Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **üì• Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **üì§ Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **üõ†Ô∏è Library Requirements (from tool) **\n",
    "                    <requirements to use the model>\n",
    "\n",
    "                    **üß™ Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "\n",
    "                    Here are the list of models and there corresponding URL:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    # result = executor.invoke({\"input\": task_input})\n",
    "    result = executor.invoke({\"input\": task_input, \"model_list\": res.models})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e8b0f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "üìù M√¥ t·∫£\n",
      "ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë vi·∫øt tay (t·ª´ 0 ƒë·∫øn 9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\n",
      "üìå Chi ti·∫øt c√°c m√¥ h√¨nh\n",
      "Ph√¢n lo·∫°i ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9\n",
      "üì• ƒê·∫ßu v√†o\n",
      "ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\n",
      "Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\n",
      "K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor (th∆∞·ªùng l√† 224x224)\n",
      "Gi√° tr·ªã pixel: [0, 255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\n",
      "üì§ ƒê·∫ßu ra\n",
      "M·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán trong ·∫£nh.\n",
      "üõ† Y√™u c·∫ßu th∆∞ vi·ªán\n",
      "C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\n",
      "pip install transformers torch\n",
      "üß™ S·ª≠ d·ª•ng m√¥ h√¨nh\n",
      "D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ m·∫´u ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\n",
      "image = Image.open(\"images.png\")\n",
      "# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "üìù M√¥ t·∫£\n",
      "ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë vi·∫øt tay (t·ª´ 0 ƒë·∫øn 9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\n",
      "üìå Chi ti·∫øt c√°c m√¥ h√¨nh\n",
      "Ph√¢n lo·∫°i ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9\n",
      "üì• ƒê·∫ßu v√†o\n",
      "ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\n",
      "Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\n",
      "K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor (th∆∞·ªùng l√† 224x224)\n",
      "Gi√° tr·ªã pixel: [0, 255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\n",
      "üì§ ƒê·∫ßu ra\n",
      "M·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán trong ·∫£nh.\n",
      "üõ† Y√™u c·∫ßu th∆∞ vi·ªán\n",
      "C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\n",
      "pip install transformers torch\n",
      "üß™ S·ª≠ d·ª•ng m√¥ h√¨nh\n",
      "D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ m·∫´u ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\n",
      "image = Image.open(\"images.png\")\n",
      "# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "üìù M√¥ t·∫£\n",
      "ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë vi·∫øt tay (t·ª´ 0 ƒë·∫øn 9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\n",
      "üìå Chi ti·∫øt c√°c m√¥ h√¨nh\n",
      "Ph√¢n lo·∫°i ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9\n",
      "üì• ƒê·∫ßu v√†o\n",
      "ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\n",
      "Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\n",
      "K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor (th∆∞·ªùng l√† 224x224)\n",
      "Gi√° tr·ªã pixel: [0, 255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\n",
      "üì§ ƒê·∫ßu ra\n",
      "M·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán trong ·∫£nh.\n",
      "üõ† Y√™u c·∫ßu th∆∞ vi·ªán\n",
      "C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\n",
      "pip install transformers torch\n",
      "üß™ S·ª≠ d·ª•ng m√¥ h√¨nh\n",
      "D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ m·∫´u ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\n",
      "image = Image.open(\"images.png\")\n",
      "# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m**‚úÖ Model name and link**  \n",
      " `Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay` ‚Äî `https://huggingface.co/thanhtlx/image_classification_01`\n",
      "\n",
      "**üìù Description (from tool):**  \n",
      " ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë vi·∫øt tay (t·ª´0 ƒë·∫øn9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\n",
      "\n",
      "**üì• Input format (from tool):**  \n",
      " ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\n",
      " Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\n",
      " K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor (th∆∞·ªùng l√†224x224)\n",
      " Gi√° tr·ªã pixel: [0,255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\n",
      "\n",
      "**üì§ Output format (from tool):**  \n",
      " M·ªôt s·ªë nguy√™n t·ª´0 ƒë·∫øn9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán trong ·∫£nh.\n",
      "\n",
      "**üõ†Ô∏è Library Requirements (from tool) **  \n",
      " C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\n",
      " pip install transformers torch\n",
      "\n",
      "**üß™ Example code (from tool):**  \n",
      " ```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\n",
      "image = Image.open(\"images.png\")\n",
      "# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      "# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "```\n",
      "\n",
      "Tuy nhi√™n, m√¥ h√¨nh n√†y ch·ªâ nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9, nh∆∞ng ch∆∞a ph√¢n lo·∫°i ƒë∆∞·ª£c s·ªë nguy√™n t·ªë hay kh√¥ng. ƒê·ªÉ gi·∫£i quy·∫øt b√†i to√°n y√™u c·∫ßu, c·∫ßn th·ª±c hi·ªán c√°c b∆∞·ªõc sau:\n",
      "\n",
      "1. **Ti·ªÅn x·ª≠ l√Ω ·∫£nh**: Chuy·ªÉn ƒë·ªïi ·∫£nh m√†u th√†nh ·∫£nh grayscale v√† resize v·ªÅ k√≠ch th∆∞·ªõc 28x28 pixel ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫ßu v√†o.\n",
      "2. **Nh·∫≠n di·ªán ch·ªØ s·ªë**: S·ª≠ d·ª•ng m√¥ h√¨nh `Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay` ƒë·ªÉ nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ ·∫£nh.\n",
      "3. **Ki·ªÉm tra s·ªë nguy√™n t·ªë**: Vi·∫øt h√†m ki·ªÉm tra s·ªë nguy√™n t·ªë ƒë·ªÉ x√°c ƒë·ªãnh s·ªë nh·∫≠n di·ªán c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng.\n",
      "\n",
      "D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ ho√†n ch·ªânh:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "def is_prime(n):\n",
      " if n <= 1:\n",
      " return False\n",
      " if n == 2:\n",
      " return True\n",
      " if n % 2 == 0:\n",
      " return False\n",
      " max_divisor = int(n**0.5) + 1\n",
      " for d in range(3, max_divisor, 2):\n",
      " if n % d == 0:\n",
      " return False\n",
      " return True\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      "\n",
      "# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "\n",
      "# Ki·ªÉm tra s·ªë nguy√™n t·ªë\n",
      "if is_prime(predicted_class):\n",
      " print(\"nguy√™n t·ªë\")\n",
      "else:\n",
      " print(\"kh√¥ng nguy√™n t·ªë\")\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res2 = model_selection_using_tool_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb681a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**‚úÖ Model name and link**  \\n'\n",
      " ' `Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay` ‚Äî '\n",
      " '`https://huggingface.co/thanhtlx/image_classification_01`\\n'\n",
      " '\\n'\n",
      " '**üìù Description (from tool):**  \\n'\n",
      " ' ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë '\n",
      " 'vi·∫øt tay (t·ª´0 ƒë·∫øn9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision '\n",
      " 'Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay '\n",
      " 'ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\\n'\n",
      " '\\n'\n",
      " '**üì• Input format (from tool):**  \\n'\n",
      " ' ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\\n'\n",
      " ' Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\\n'\n",
      " ' K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor '\n",
      " '(th∆∞·ªùng l√†224x224)\\n'\n",
      " ' Gi√° tr·ªã pixel: [0,255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\\n'\n",
      " '\\n'\n",
      " '**üì§ Output format (from tool):**  \\n'\n",
      " ' M·ªôt s·ªë nguy√™n t·ª´0 ƒë·∫øn9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán '\n",
      " 'trong ·∫£nh.\\n'\n",
      " '\\n'\n",
      " '**üõ†Ô∏è Library Requirements (from tool) **  \\n'\n",
      " ' C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\\n'\n",
      " ' pip install transformers torch\\n'\n",
      " '\\n'\n",
      " '**üß™ Example code (from tool):**  \\n'\n",
      " ' ```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " 'print(f\"prediction: {predicted_class}\")\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Tuy nhi√™n, m√¥ h√¨nh n√†y ch·ªâ nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9, nh∆∞ng ch∆∞a '\n",
      " 'ph√¢n lo·∫°i ƒë∆∞·ª£c s·ªë nguy√™n t·ªë hay kh√¥ng. ƒê·ªÉ gi·∫£i quy·∫øt b√†i to√°n y√™u c·∫ßu, c·∫ßn '\n",
      " 'th·ª±c hi·ªán c√°c b∆∞·ªõc sau:\\n'\n",
      " '\\n'\n",
      " '1. **Ti·ªÅn x·ª≠ l√Ω ·∫£nh**: Chuy·ªÉn ƒë·ªïi ·∫£nh m√†u th√†nh ·∫£nh grayscale v√† resize v·ªÅ '\n",
      " 'k√≠ch th∆∞·ªõc 28x28 pixel ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫ßu v√†o.\\n'\n",
      " '2. **Nh·∫≠n di·ªán ch·ªØ s·ªë**: S·ª≠ d·ª•ng m√¥ h√¨nh `Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay` ƒë·ªÉ '\n",
      " 'nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ ·∫£nh.\\n'\n",
      " '3. **Ki·ªÉm tra s·ªë nguy√™n t·ªë**: Vi·∫øt h√†m ki·ªÉm tra s·ªë nguy√™n t·ªë ƒë·ªÉ x√°c ƒë·ªãnh s·ªë '\n",
      " 'nh·∫≠n di·ªán c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng.\\n'\n",
      " '\\n'\n",
      " 'D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ ho√†n ch·ªânh:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " '\\n'\n",
      " 'def is_prime(n):\\n'\n",
      " ' if n <= 1:\\n'\n",
      " ' return False\\n'\n",
      " ' if n == 2:\\n'\n",
      " ' return True\\n'\n",
      " ' if n % 2 == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' max_divisor = int(n**0.5) + 1\\n'\n",
      " ' for d in range(3, max_divisor, 2):\\n'\n",
      " ' if n % d == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' return True\\n'\n",
      " '\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '\\n'\n",
      " '# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '\\n'\n",
      " '# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '\\n'\n",
      " '# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " '\\n'\n",
      " '# Ki·ªÉm tra s·ªë nguy√™n t·ªë\\n'\n",
      " 'if is_prime(predicted_class):\\n'\n",
      " ' print(\"nguy√™n t·ªë\")\\n'\n",
      " 'else:\\n'\n",
      " ' print(\"kh√¥ng nguy√™n t·ªë\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res2['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874a1c7",
   "metadata": {},
   "source": [
    "## Output Parser Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3658cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelingOutput(BaseModel):\n",
    "    model_description: str = Field(\n",
    "        ...,\n",
    "        description=\"The detailed description of the model.\"\n",
    "    )\n",
    "    model_input_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed input format\"\n",
    "    )\n",
    "    model_output_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed output format\"\n",
    "    )\n",
    "    model_requirements: str = Field(\n",
    "        ...,\n",
    "        description=\"Requirement libraries need to install to use the model.\"\n",
    "    )\n",
    "    model_sample_code: str = Field(\n",
    "        ...,\n",
    "        description=\"Example code to use the model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0b610e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=ModelingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "707428ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser_llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5a1f51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_parser_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a smart AI tasked with extracting structured technical details about a machine learning model from a reasoning result.\n",
    "                    You are given a detailed text description about a model.\n",
    "                    Your goal is to fill the following fields based on the text:\n",
    "\n",
    "                    - `model_description`: A detailed explanation of what the model is and what it does.\n",
    "                    - `model_input_format`: A detailed description of the model's input format, including dimensions, data types, and expected preprocessing if mentioned.\n",
    "                    - `model_output_format`: A detailed description of the output format including dimensions, data types, label name and its meaning.\n",
    "                    - `model_requirements`: A detailed description about the requirements needed to be sastified in order to use the model\n",
    "                    - `model_sample_code`: A sample code on how to use the model.\n",
    "\n",
    "                    You MUSTN'T create any data on your own, only using the data provided in the text.\n",
    "\n",
    "                    Return the data as a JSON object matching the following structure:\n",
    "                    {formatted_output}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]).partial(formatted_output=parser.get_format_instructions())\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"input\": res2['output']})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d82f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = output_parser_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "583a7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**‚úÖ Model name and link**  \\n'\n",
      " ' `Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay` ‚Äî '\n",
      " '`https://huggingface.co/thanhtlx/image_classification_01`\\n'\n",
      " '\\n'\n",
      " '**üìù Description (from tool):**  \\n'\n",
      " ' ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë '\n",
      " 'vi·∫øt tay (t·ª´0 ƒë·∫øn9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision '\n",
      " 'Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay '\n",
      " 'ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\\n'\n",
      " '\\n'\n",
      " '**üì• Input format (from tool):**  \\n'\n",
      " ' ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\\n'\n",
      " ' Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\\n'\n",
      " ' K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor '\n",
      " '(th∆∞·ªùng l√†224x224)\\n'\n",
      " ' Gi√° tr·ªã pixel: [0,255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\\n'\n",
      " '\\n'\n",
      " '**üì§ Output format (from tool):**  \\n'\n",
      " ' M·ªôt s·ªë nguy√™n t·ª´0 ƒë·∫øn9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán '\n",
      " 'trong ·∫£nh.\\n'\n",
      " '\\n'\n",
      " '**üõ†Ô∏è Library Requirements (from tool) **  \\n'\n",
      " ' C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\\n'\n",
      " ' pip install transformers torch\\n'\n",
      " '\\n'\n",
      " '**üß™ Example code (from tool):**  \\n'\n",
      " ' ```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " 'print(f\"prediction: {predicted_class}\")\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Tuy nhi√™n, m√¥ h√¨nh n√†y ch·ªâ nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9, nh∆∞ng ch∆∞a '\n",
      " 'ph√¢n lo·∫°i ƒë∆∞·ª£c s·ªë nguy√™n t·ªë hay kh√¥ng. ƒê·ªÉ gi·∫£i quy·∫øt b√†i to√°n y√™u c·∫ßu, c·∫ßn '\n",
      " 'th·ª±c hi·ªán c√°c b∆∞·ªõc sau:\\n'\n",
      " '\\n'\n",
      " '1. **Ti·ªÅn x·ª≠ l√Ω ·∫£nh**: Chuy·ªÉn ƒë·ªïi ·∫£nh m√†u th√†nh ·∫£nh grayscale v√† resize v·ªÅ '\n",
      " 'k√≠ch th∆∞·ªõc 28x28 pixel ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫ßu v√†o.\\n'\n",
      " '2. **Nh·∫≠n di·ªán ch·ªØ s·ªë**: S·ª≠ d·ª•ng m√¥ h√¨nh `Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay` ƒë·ªÉ '\n",
      " 'nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ ·∫£nh.\\n'\n",
      " '3. **Ki·ªÉm tra s·ªë nguy√™n t·ªë**: Vi·∫øt h√†m ki·ªÉm tra s·ªë nguy√™n t·ªë ƒë·ªÉ x√°c ƒë·ªãnh s·ªë '\n",
      " 'nh·∫≠n di·ªán c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng.\\n'\n",
      " '\\n'\n",
      " 'D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ ho√†n ch·ªânh:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " '\\n'\n",
      " 'def is_prime(n):\\n'\n",
      " ' if n <= 1:\\n'\n",
      " ' return False\\n'\n",
      " ' if n == 2:\\n'\n",
      " ' return True\\n'\n",
      " ' if n % 2 == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' max_divisor = int(n**0.5) + 1\\n'\n",
      " ' for d in range(3, max_divisor, 2):\\n'\n",
      " ' if n % d == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' return True\\n'\n",
      " '\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '\\n'\n",
      " '# ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '\\n'\n",
      " '# X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '\\n'\n",
      " '# L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " '\\n'\n",
      " '# Ki·ªÉm tra s·ªë nguy√™n t·ªë\\n'\n",
      " 'if is_prime(predicted_class):\\n'\n",
      " ' print(\"nguy√™n t·ªë\")\\n'\n",
      " 'else:\\n'\n",
      " ' print(\"kh√¥ng nguy√™n t·ªë\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res2['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "530f5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is an image classification model trained to recognize handwritten '\n",
      " 'digits (from 0 to 9) in color images. The model uses the Vision Transformer '\n",
      " '(ViT) architecture and was trained on a dataset of handwritten digits '\n",
      " 'captured or scanned as color images.')\n",
      "(\"The model's input format is a color image (RGB) of type PIL.Image.Image. The \"\n",
      " 'image size is automatically resized to 224x224 by the ViTImageProcessor. '\n",
      " 'Pixel values range from [0, 255] and are automatically normalized by the '\n",
      " 'processor.')\n",
      "(\"The model's output format is an integer from 0 to 9, representing the \"\n",
      " 'classification result corresponding to the digit appearing in the image.')\n",
      "('The required libraries are transformers and torch, which can be installed '\n",
      " 'using pip: pip install transformers torch')\n",
      "('```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '# Load image to classify\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '# Preprocess input image\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '# Make prediction with model\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '# Get prediction result\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " 'print(f\"prediction: {predicted_class}\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(ans.model_description)\n",
    "pprint.pprint(ans.model_input_format)\n",
    "pprint.pprint(ans.model_output_format)\n",
    "pprint.pprint(ans.model_requirements)\n",
    "pprint.pprint(ans.model_sample_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978bb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "77a72e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3643728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentCodingState(TypedDict):\n",
    "    problem_description: str | None\n",
    "    problem_input_description: str | None\n",
    "    problem_output_description: str | None\n",
    "    model_description: str | None\n",
    "    model_input_format: str | None\n",
    "    model_output_format: str | None\n",
    "    model_requirements: str | None\n",
    "    model_sample_code: str | None\n",
    "    output_classes: str | None\n",
    "    code: str | None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Variables\n",
    "\n",
    "# %% [code]\n",
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "\n",
    "# %% [markdown]\n",
    "# # Import Modules\n",
    "\n",
    "# %% [code]\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from tools.fetching_description_from_huggingface import fetching_description_from_huggingface\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "# %% [markdown]\n",
    "# # Testing\n",
    "\n",
    "# %% [code]\n",
    "df_task = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")\n",
    "\n",
    "# %% [code]\n",
    "df_task\n",
    "\n",
    "# %% [code]\n",
    "task = df_task[\"Task\"][0]\n",
    "\n",
    "# %% [code]\n",
    "task\n",
    "\n",
    "# %% [code]\n",
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Tools\n",
    "\n",
    "# %% [code]\n",
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    # scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    # scrape_status = scraper.scrape_url(\n",
    "    #     url,\n",
    "    #     formats=['markdown']\n",
    "    # )\n",
    "    # return scrape_status.markdown\n",
    "    result = fetching_description_from_huggingface(url)\n",
    "    return result\n",
    "\n",
    "# %% [code]\n",
    "class WebScraperParameters(BaseModel):\n",
    "    url: str\n",
    "\n",
    "# %% [code]\n",
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')\n",
    "\n",
    "# %% [code]\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Model\n",
    "\n",
    "# %% [code]\n",
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# %% [code]\n",
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )\n",
    "\n",
    "# %% [code]\n",
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks\n",
    "\n",
    "# %% [code]\n",
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state\n",
    "\n",
    "# %% [code]\n",
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}\n",
    "\n",
    "# %% [code]\n",
    "state = classify_agent(state)\n",
    "\n",
    "# %% [markdown]\n",
    "# # Modeling Agent\n",
    "\n",
    "# %% [code]\n",
    "class ModelInfo(BaseModel):\n",
    "    model: str = Field(..., description=\"Model name\")\n",
    "    url: str = Field(..., description=\"URL to the model\")\n",
    "\n",
    "class ModelSelection(BaseModel):\n",
    "    models: List[ModelInfo] = Field(..., description=\"List of available models with name and URL\")\n",
    "\n",
    "# %% [code]\n",
    "model_selection_parser = PydanticOutputParser(pydantic_object=ModelSelection)\n",
    "\n",
    "# %% [code]\n",
    "def model_selection_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the suitable model for a given task.\n",
    "                    Given:\n",
    "                    - A user description about the task\n",
    "                    - A list of available model (names and links)\n",
    "                    Your job is to choose ALL suitable models provided in the list for user's specific tasks.\n",
    "                    Return the answer in the format\n",
    "                    {structured_output}\n",
    "                    Here are the list of model:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]).partial(structured_output=model_selection_parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | model_selection_parser\n",
    "\n",
    "    result = chain.invoke({\"input\": task, \"model_list\": format_model_list(df_model)})\n",
    "    return result\n",
    "\n",
    "# %% [code]\n",
    "res = model_selection_agent(state)\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(res.models)\n",
    "\n",
    "# %% [code]\n",
    "def model_selection_using_tool_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the **Best-fit model** for a given task.\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and url)\n",
    "                    - A tool that fetches model details from a provided URL (it help gathers model description, input/output format, code sample usage)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - ‚úÖ Model description\n",
    "                        - üì• Input format\n",
    "                        - üì§ Output format\n",
    "                        - üõ†Ô∏è Library requirements\n",
    "                        - üß™ Code sample (usage code snippet)\n",
    "                    2. Select the best model for user given task based on the data that the tool gives you.\n",
    "\n",
    "                    ‚ö†Ô∏è VERY IMPORTANT RULES\n",
    "\n",
    "                    - ‚ùå DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - ‚ùå DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - ‚úÖ ONLY use the **actual output** returned from the tool\n",
    "                    - ‚úÖ Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ## üß† Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **‚úÖ Model name and link**  \n",
    "                    `<model name>` ‚Äî `<link>`\n",
    "\n",
    "                    **üìù Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **üì• Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **üì§ Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **üõ†Ô∏è Library Requirements (from tool) **\n",
    "                    <requirements to use the model>\n",
    "\n",
    "                    **üß™ Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "\n",
    "                    Here are the list of models and there corresponding URL:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    # result = executor.invoke({\"input\": task_input})\n",
    "    result = executor.invoke({\"input\": task_input, \"model_list\": res.models})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}\n",
    "\n",
    "# %% [code]\n",
    "res2 = model_selection_using_tool_agent(state)\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(res2['output'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Output Parser Agent\n",
    "\n",
    "# %% [code]\n",
    "class ModelingOutput(BaseModel):\n",
    "    model_description: str = Field(\n",
    "        ...,\n",
    "        description=\"The detailed description of the model.\"\n",
    "    )\n",
    "    model_input_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed input format\"\n",
    "    )\n",
    "    model_output_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed output format\"\n",
    "    )\n",
    "    model_requirements: str = Field(\n",
    "        ...,\n",
    "        description=\"Requirement libraries need to install to use the model.\"\n",
    "    )\n",
    "    model_sample_code: str = Field(\n",
    "        ...,\n",
    "        description=\"Example code to use the model\"\n",
    "    )\n",
    "\n",
    "# %% [code]\n",
    "parser = PydanticOutputParser(pydantic_object=ModelingOutput)\n",
    "\n",
    "# %% [code]\n",
    "output_parser_llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# %% [code]\n",
    "def output_parser_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a smart AI tasked with extracting structured technical details about a machine learning model from a reasoning result.\n",
    "                    You are given a detailed text description about a model.\n",
    "                    Your goal is to fill the following fields based on the text:\n",
    "\n",
    "                    - `model_description`: A detailed explanation of what the model is and what it does.\n",
    "                    - `model_input_format`: A detailed description of the model's input format, including dimensions, data types, and expected preprocessing if mentioned.\n",
    "                    - `model_output_format`: A detailed description of the output format including dimensions, data types, label name and its meaning.\n",
    "                    - `model_requirements`: A detailed description about the requirements needed to be sastified in order to use the model\n",
    "                    - `model_sample_code`: A sample code on how to use the model.\n",
    "\n",
    "                    You MUSTN'T create any data on your own, only using the data provided in the text.\n",
    "\n",
    "                    Return the data as a JSON object matching the following structure:\n",
    "                    {formatted_output}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]).partial(formatted_output=parser.get_format_instructions())\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"input\": res2['output']})\n",
    "    return response\n",
    "\n",
    "# %% [code]\n",
    "ans = output_parser_agent(state)\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(res2['output'])\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(ans.model_description)\n",
    "pprint.pprint(ans.model_input_format)\n",
    "pprint.pprint(ans.model_output_format)\n",
    "pprint.pprint(ans.model_requirements)\n",
    "pprint.pprint(ans.model_sample_code)\n",
    "\n",
    "# %% [code]\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "class AgentCodingState(TypedDict):\n",
    "    problem_description: str | None\n",
    "    problem_input_description: str | None\n",
    "    problem_output_description: str | None\n",
    "    model_description: str | None\n",
    "    model_input_format: str | None\n",
    "    model_output_format: str | None\n",
    "    model_requirements: str | None\n",
    "    model_sample_code: str | None\n",
    "    output_classes: str | None\n",
    "    code: str | None\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "base_prompt = r\"\"\"\n",
    "    You are a specialist in Machine Learning. Your task is to generate a *fully functional with all necessary imports and dependencies* codebase in *Python* that can be executed flawlessly.\n",
    "\n",
    "    You will be provided with:\n",
    "    - A problem description\n",
    "    - An input specification\n",
    "    - An output specification\n",
    "    - A model description\n",
    "\n",
    "    ### Input:\n",
    "    - Problem description: {problem_description}\n",
    "    - Problem input specification: {problem_input_description}\n",
    "    - Problem output specification: {problem_output_description}\n",
    "    - ML model description: {model_description}\n",
    "    - ML model input format: {model_input_format}\n",
    "    - ML model output format: {model_output_format}\n",
    "    - ML model requirements: {model_requirements}\n",
    "    - ML model sample code: {model_sample_code}\n",
    "    - Output classes: {output_classes}\n",
    "\n",
    "    ### Guidelines\n",
    "\n",
    "    You *must* strictly follow the following guidelines:\n",
    "    - The preprocessing step should be suitable for the data type.\n",
    "    - The postprocessing step should notices the differences between the data returned by the model and the output requirements. You must extract and use the exact class labels as defined in the output specification.\n",
    "    - Do *not invent new labels or translate* the class names. Use them exactly as given.\n",
    "    - You *must* make sure that your codebase can be executed flawlessly that would not encounter any errors or exceptions.\n",
    "\n",
    "    Your implementation *must strictly follow* the structure below:\n",
    "    1. *Imports*: All required libraries.\n",
    "    2. *Preprocessing*: Handle and transform the input as defined.\n",
    "    3. *Inference logic*: Use the described model for prediction. You *must* use tqdm or similar logging library to track progress.\n",
    "    4. *Postprocessing*: Format or transform the raw output into the final result as described.\n",
    "\n",
    "    You must *not* include any explanations, markdown, or logging outside what is required by the problem.\n",
    "\n",
    "    Return *only* the complete Python codebase. Wrap it with:\n",
    "    \\`\\`\\`python\n",
    "    # code here\n",
    "    \\`\\`\\`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "class OutputState(TypedDict):\n",
    "    output_classes: str | None\n",
    "\n",
    "# %% [code]\n",
    "def output_agent(state: OutputState) -> OutputState:\n",
    "    prompt = r\"\"\"\n",
    "        Your are a specialist in machine learning. Your task is to identify the absolute classes of the given problem description, following with an output description.\n",
    "        ### Input:\n",
    "        - Problem description: {problem_description}\n",
    "        - Output description: {output_description}\n",
    "\n",
    "        You must return an array, strictly following these guidelines:\n",
    "        - Understand the context from the given problem description.\n",
    "        - Extract the class names from the output description. You **must not** invent new labels or translate the class names. Use them exactly as given in the output description.\n",
    "        - Create an array containing the classes.\n",
    "\n",
    "        You must return only the array containing those classes, without any formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt.format(\n",
    "        problem_description = state[\"problem_description\"],\n",
    "        output_description = state[\"output_description\"]\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"output_classes\": response.content}\n",
    "\n",
    "# %% [code]\n",
    "output_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"output_description\": ans.model_output_format\n",
    "}\n",
    "\n",
    "# %% [code]\n",
    "new_state = output_agent(output_state)\n",
    "\n",
    "# %% [code]\n",
    "new_state[\"output_classes\"]\n",
    "\n",
    "# %% [code]\n",
    "def coding_agent(state: AgentCodingState) -> AgentCodingState:\n",
    "    prompt = base_prompt.format(\n",
    "        problem_description=state[\"problem_description\"],\n",
    "        problem_input_description=state[\"problem_input_description\"],\n",
    "        problem_output_description=state[\"problem_output_description\"],\n",
    "        model_description=state[\"model_description\"],\n",
    "        model_input_format=state[\"model_input_format\"],\n",
    "        model_output_format=state[\"model_output_format\"],\n",
    "        model_requirements=state[\"model_requirements\"],\n",
    "        model_sample_code=state[\"model_sample_code\"],\n",
    "        output_classes=state[\"output_classes\"],\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"code\": response.content}\n",
    "\n",
    "# %% [code]\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "prev_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"problem_input_description\": ans.problem_input_description,\n",
    "    \"problem_output_description\": ans.problem_output_description,\n",
    "    \"model_description\": res2['output'],\n",
    "    \"model_input_format\": ans.model_input_format,\n",
    "    \"model_output_format\": ans.model_output_format,\n",
    "    \"model_requirements\": ans.model_requirements,\n",
    "    \"model_sample_code\": ans.model_sample_code,\n",
    "    \"output_classes\": ans.output_classes,\n",
    "}\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "state = coding_agent(prev_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ad8e05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputState(TypedDict):\n",
    "    output_classes: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c4731165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_agent(state: OutputState) -> OutputState:\n",
    "    prompt = r\"\"\"\n",
    "        Your are a specialist in machine learning. Your task is to identify the absolute classes of the given problem description, following with an output description.\n",
    "        ### Input:\n",
    "        - Problem description: {problem_description}\n",
    "        - Output description: {output_description}\n",
    "\n",
    "        You must return an array, strictly following these guidelines:\n",
    "        - Understand the context from the given problem description.\n",
    "        - Extract the class names from the output description. You **must not** invent new labels or translate the class names. Use them exactly as given in the output description.\n",
    "        - Create an array containing the classes.\n",
    "\n",
    "        You must return only the array containing those classes, without any formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt.format(\n",
    "        problem_description = state[\"problem_description\"],\n",
    "        output_description = state[\"output_description\"]\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"output_classes\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3895d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"output_description\": ans.model_output_format\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a52076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = output_agent(output_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72a9f7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[\"output_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c3313114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_agent(state: AgentCodingState) -> AgentCodingState:\n",
    "    prompt = base_prompt.format(\n",
    "        problem_description=state[\"problem_description\"],\n",
    "        problem_input_description=state[\"problem_input_description\"],\n",
    "        problem_output_description=state[\"problem_output_description\"],\n",
    "        model_description=state[\"model_description\"],\n",
    "        model_input_format=state[\"model_input_format\"],\n",
    "        model_output_format=state[\"model_output_format\"],\n",
    "        model_requirements=state[\"model_requirements\"],\n",
    "        model_sample_code=state[\"model_sample_code\"],\n",
    "        output_classes=state[\"output_classes\"],\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"code\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a72457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d80aeddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelingOutput' object has no attribute 'problem_input_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m prev_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproblem_description\u001b[39m\u001b[33m\"\u001b[39m: task,\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproblem_input_description\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproblem_input_description\u001b[49m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproblem_output_description\u001b[39m\u001b[33m\"\u001b[39m: ans.problem_output_description,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_description\u001b[39m\u001b[33m\"\u001b[39m: res2[\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_input_format\u001b[39m\u001b[33m\"\u001b[39m: ans.model_input_format,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_output_format\u001b[39m\u001b[33m\"\u001b[39m: ans.model_output_format,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_requirements\u001b[39m\u001b[33m\"\u001b[39m: ans.model_requirements,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_sample_code\u001b[39m\u001b[33m\"\u001b[39m: ans.model_sample_code,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_classes\u001b[39m\u001b[33m\"\u001b[39m: ans.output_classes,\n\u001b[32m     11\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viett\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelingOutput' object has no attribute 'problem_input_description'"
     ]
    }
   ],
   "source": [
    "prev_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"problem_input_description\": ans.problem_input_description,\n",
    "    \"problem_output_description\": ans.problem_output_description,\n",
    "    \"model_description\": res2['output'],\n",
    "    \"model_input_format\": ans.model_input_format,\n",
    "    \"model_output_format\": ans.model_output_format,\n",
    "    \"model_requirements\": ans.model_requirements,\n",
    "    \"model_sample_code\": ans.model_sample_code,\n",
    "    \"output_classes\": ans.output_classes,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a56d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = coding_agent(prev_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

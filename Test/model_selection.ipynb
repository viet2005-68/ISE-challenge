{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42744f82",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "91bed7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/mnt/g/Ai agents course/LangGraph/venv/lib/python3.12/site-packages', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from tools.fetching_description_from_huggingface import fetching_description_from_huggingface\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "22abc01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STT</th>\n",
       "      <th>Task</th>\n",
       "      <th>Validation data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Bối cảnh của vấn đề:\\nNhận dạng chữ viết tay ...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nTrong thời đại thông tin...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nĐây là một nhiệm vụ hồi ...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nĐiều quan trọng là các c...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nTrong nhiều ứng dụng thự...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STT                                               Task Validation data\n",
       "0    1  \"Bối cảnh của vấn đề:\\nNhận dạng chữ viết tay ...            Link\n",
       "1    2  Bối cảnh của vấn đề:\\nTrong thời đại thông tin...            Link\n",
       "2    3  Bối cảnh của vấn đề:\\nĐây là một nhiệm vụ hồi ...            Link\n",
       "3    4  Bối cảnh của vấn đề:\\nĐiều quan trọng là các c...            Link\n",
       "4    5  Bối cảnh của vấn đề:\\nTrong nhiều ứng dụng thự...            Link"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "953cae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bối cảnh của vấn đề:\\nTrong nhiều ứng dụng thực tế như tổng hợp nội dung hình ảnh, phân loại album, hay trích xuất đặc trưng nội dung cho ảnh tổ hợp, cần xác định chủ đề chính của một ảnh ghép từ nhiều ảnh con. Bài toán này đòi hỏi ứng dụng không chỉ nhận diện được nội dung của từng ảnh con, mà còn cần xác định chủ đề chiếm ưu thế trong toàn bộ ảnh tổng thể.\\n\\nYêu cầu cụ thể cần đạt được:\\nMỗi đầu vào là một ảnh tổ hợp, ghép từ 9 ảnh màu nhỏ (3x3).\\nNhiệm vụ của ứng dụng là:\\nXác định chủ đề chiếm số lượng nhiều nhất trong 9 ảnh con.\\nTrường hợp có nhiều chủ đề xuất hiện với tần suất bằng nhau, có thể chọn một chủ đề bất kỳ trong số đó làm kết quả.\\n\\nĐịnh dạng dữ liệu đầu vào cho bài toán tổng thể:\\nMột thư mục có tên là \"images\" chứa các ảnh màu RGB (288x288), được ghép từ 9 ảnh RGB con (32x32) (3 hàng × 3 cột).\\n\\nĐịnh dạng kết quả đầu ra mong muốn cho bài toán tổng thể:\\nFile output.csv mỗi hàng là kết quả dự đoán mỗi ảnh\\ncó các cột:\\nfile_name: tên file ảnh\\nprediction: nhãn của ảnh. \\nnhãn của ảnh là một nhãn duy nhất đại diện cho chủ đề xuất hiện nhiều nhất trong 9 ảnh con.\\nCác chủ đề sau nằm trong danh sách sau:\\n       [\\'forest\\', \\'orchid\\', \\'spider\\', \\'fox\\', \\'caterpillar\\', \\'crocodile\\',\\n       \\'whale\\', \\'road\\', \\'motorcycle\\', \\'tiger\\', \\'woman\\', \\'orange\\',\\n       \\'elephant\\', \\'otter\\', \\'flatfish\\', \\'cup\\', \\'sea\\', \\'mountain\\', \\'cloud\\',\\n       \\'willow_tree\\', \\'rabbit\\', \\'couch\\', \\'maple_tree\\', \\'wardrobe\\',\\n       \\'mushroom\\', \\'plain\\', \\'telephone\\', \\'shrew\\', \\'bowl\\', \\'tractor\\',\\n       \\'camel\\', \\'bus\\', \\'cattle\\', \\'house\\', \\'cockroach\\', \\'lawn_mower\\',\\n       \\'oak_tree\\', \\'apple\\', \\'bicycle\\', \\'beetle\\', \\'palm_tree\\', \\'sunflower\\',\\n       \\'poppy\\', \\'keyboard\\', \\'porcupine\\', \\'snake\\', \\'can\\', \\'pear\\', \\'shark\\',\\n       \\'chimpanzee\\', \\'hamster\\', \\'train\\', \\'cra\\', \\'bear\\', \\'sweet_pepper\\',\\n       \\'pine_tree\\', \\'bed\\', \\'tank\\', \\'beaver\\', \\'bridge\\', \\'girl\\',\\n       \\'skyscraper\\', \\'wolf\\', \\'raccoon\\', \\'rose\\', \\'worm\\', \\'table\\',\\n       \\'pickup_truck\\', \\'turtle\\', \\'lizard\\', \\'leopard\\', \\'streetcar\\',\\n       \\'rocket\\', \\'man\\', \\'tulip\\', \\'lamp\\', \\'seal\\', \\'lion\\', \\'butterfly\\',\\n       \\'kangaroo\\', \\'television\\', \\'ray\\', \\'chair\\', \\'skunk\\', \\'trout\\',\\n       \\'possum\\', \\'mouse\\']'"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "af3bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    # scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    # scrape_status = scraper.scrape_url(\n",
    "    #     url,\n",
    "    #     formats=['markdown']\n",
    "    # )\n",
    "    # return scrape_status.markdown\n",
    "    result = fetching_description_from_huggingface(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "77f3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperParameters(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "b6a0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "52a9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409f8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "eca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6511a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "0de6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "ef593964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "14b15c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "78675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = classify_agent(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab3d7f",
   "metadata": {},
   "source": [
    "# Modeling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "f656ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInfo(BaseModel):\n",
    "    model: str = Field(..., description=\"Model name\")\n",
    "    url: str = Field(..., description=\"URL to the model\")\n",
    "\n",
    "class ModelSelection(BaseModel):\n",
    "    models: List[ModelInfo] = Field(..., description=\"List of available models with name and URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "18dcc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_parser = PydanticOutputParser(pydantic_object=ModelSelection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "de4ed792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the suitable model for a given task.\n",
    "                    Given:\n",
    "                    - A user description about the task\n",
    "                    - A list of available model (names and links)\n",
    "                    Your job is to choose ALL suitable models provided in the list for user's specific tasks.\n",
    "                    Return the answer in the format\n",
    "                    {structured_output}\n",
    "                    Here are the list of model:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]).partial(structured_output=model_selection_parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | model_selection_parser\n",
    "\n",
    "    result = chain.invoke({\"input\": task, \"model_list\": format_model_list(df_model)})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "fd097a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27136/7332665.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
      "/tmp/ipykernel_27136/7332665.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = str(row[2])\n"
     ]
    }
   ],
   "source": [
    "res = model_selection_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "03a8819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelInfo(model='Phân loại hình ảnh', url='https://huggingface.co/zhaospei/Model_7'),\n",
      " ModelInfo(model='Phân loại hình ảnh thành 100 lớp đối tượng chi tiết (fine-grained)', url='https://huggingface.co/zhaospei/Model_6'),\n",
      " ModelInfo(model='Nhận diện ảnh chữ viết tay', url='https://huggingface.co/thanhtlx/image_classification_01')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "3b0dc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_using_tool_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the **Best-fit model** for a given task.\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and url)\n",
    "                    - A tool that fetches model details from a provided URL (it help gathers model description, input/output format, code sample usage)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - ✅ Model description\n",
    "                        - 📥 Input format\n",
    "                        - 📤 Output format\n",
    "                        - 🛠️ Library requirements\n",
    "                        - 🧪 Code sample (usage code snippet)\n",
    "                    2. Select the best model for user given task based on the data that the tool gives you.\n",
    "\n",
    "                    ⚠️ VERY IMPORTANT RULES\n",
    "\n",
    "                    - ❌ DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - ❌ DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - ✅ ONLY use the **actual output** returned from the tool\n",
    "                    - ✅ Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ## 🧠 Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **✅ Model name and link**  \n",
    "                    `<model name>` — `<link>`\n",
    "\n",
    "                    **📝 Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **📥 Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **📤 Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **🛠️ Library Requirements (from tool) **\n",
    "                    <requirements to use the model>\n",
    "\n",
    "                    **🧪 Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "\n",
    "                    Here are the list of models and there corresponding URL:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    # result = executor.invoke({\"input\": task_input})\n",
    "    result = executor.invoke({\"input\": task_input, \"model_list\": res.models})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "e8b0f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_7'}`\n",
      "responded: I understand the task. You want me to select the best-fit model for a given task based on the data retrieved from the provided tool. The task is to determine the dominant theme in a collage image composed of 9 smaller images.\n",
      "\n",
      "I will start by retrieving the details of each candidate model using the provided tool.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "🖼️ Mô hình Phân loại Ảnh - ViT Fine-tuned trên CIFAR-10\n",
      "📝 Mô tả\n",
      "Đây là mô hình Vision Transformer (ViT) được fine-tuned từ mô hình khác trên tập dữ liệu CIFAR-10. Mô hình được huấn luyện để phân loại ảnh vào 10 lớp khác nhau, mỗi lớp đại diện cho một danh mục đối tượng cụ thể.\n",
      "📌 Nhiệm vụ\n",
      "Loại bài toán: Phân loại ảnh (Image Classification)\n",
      "Số lớp: 10 (Tương ứng nhãn) CIFAR-10\n",
      "📥 Đầu vào\n",
      "Định dạng: Ảnh màu RGB\n",
      "Kích thước ảnh: 224x224 pixels\n",
      "📤 Đầu ra\n",
      "Định dạng: Xác suất cho mỗi lớp (logits)\n",
      "Kiểu dữ liệu: Tensor có kích thước [batch_size, 10]\n",
      "Ý nghĩa: Xác suất dự đoán cho từng lớp trong 10 lớp của CIFAR-10\n",
      "🛠 Yêu cầu thư viện\n",
      "Cài đặt các thư viện cần thiết bằng:\n",
      "pip install transformers torch torchvision\n",
      "🧪 Cách sử dụng mô hình\n",
      "Dưới đây là ví dụ về cách sử dụng mô hình để phân loại một ảnh:\n",
      "import torch\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "# Tải ảnh cần phân loại\n",
      "image = Image.open(\"path_to_your_image.jpg\")\n",
      "# Tải processor và mô hình từ Hugging Face\n",
      "processor = ViTImageProcessor.from_pretrained(\"zhaospei/Model_7\")\n",
      "model = ViTForImageClassification.from_pretrained(\"zhaospei/Model_7\")\n",
      "# Xử lý đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "    logits = outputs.logits\n",
      "    predicted_label = logits.argmax(-1).item()\n",
      "print(f\"Nhãn dự đoán: {model.config.id2label[predicted_label]}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_6'}`\n",
      "responded: I understand the task. You want me to select the best-fit model for a given task based on the data retrieved from the provided tool. The task is to determine the dominant theme in a collage image composed of 9 smaller images.\n",
      "\n",
      "I will start by retrieving the details of each candidate model using the provided tool.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "🖼️ Mô hình Phân loại Ảnh - ViT Fine-tuned trên CIFAR-100\n",
      "📝 Mô tả\n",
      "Đây là mô hình Vision Transformer (ViT) được fine-tuned từ mô hình gốc google/vit-base-patch16-224-in21k trên tập dữ liệu CIFAR-100. Mô hình được huấn luyện để phân loại ảnh vào 100 lớp khác nhau, mỗi lớp đại diện cho một danh mục đối tượng cụ thể.\n",
      "📌 Nhiệm vụ\n",
      "Loại bài toán: Phân loại ảnh (Image Classification)\n",
      "Số lớp: 100\n",
      "Tập dữ liệu: CIFAR-100\n",
      "📥 Đầu vào\n",
      "Định dạng: Ảnh màu RGB\n",
      "Kích thước ảnh:  224x224\n",
      "📤 Đầu ra\n",
      "Định dạng: Xác suất cho mỗi lớp (logits)\n",
      "Kiểu dữ liệu: Tensor có kích thước [batch_size, 100]\n",
      "Ý nghĩa: Xác suất dự đoán cho từng lớp trong 100 lớp của CIFAR-100\n",
      "🛠 Yêu cầu thư viện\n",
      "Cài đặt các thư viện cần thiết bằng:\n",
      "pip install transformers torch torchvision\n",
      "🧪 Cách sử dụng mô hình\n",
      "Dưới đây là ví dụ về cách sử dụng mô hình để phân loại một ảnh:\n",
      "import torch\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "# Tải ảnh cần phân loại\n",
      "image = Image.open(\"path_to_your_image.jpg\")\n",
      "# Tải processor và mô hình từ Hugging Face\n",
      "processor = ViTImageProcessor.from_pretrained(\"zhaospei/Model_6\")\n",
      "model = ViTForImageClassification.from_pretrained(\"zhaospei/Model_6\")\n",
      "# Xử lý đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "    logits = outputs.logits\n",
      "    predicted_label = logits.argmax(-1).item()\n",
      "print(f\"Nhãn dự đoán: {model.config.id2label[predicted_label]}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "responded: I understand the task. You want me to select the best-fit model for a given task based on the data retrieved from the provided tool. The task is to determine the dominant theme in a collage image composed of 9 smaller images.\n",
      "\n",
      "I will start by retrieving the details of each candidate model using the provided tool.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "📝 Mô tả\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "📌 Chi tiết các mô hình\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "📥 Đầu vào\n",
      "Định dạng: Ảnh màu (RGB)\n",
      "Kiểu dữ liệu: PIL.Image.Image\n",
      "Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor (thường là 224x224)\n",
      "Giá trị pixel: [0, 255] (chuẩn hóa tự động bởi processor)\n",
      "📤 Đầu ra\n",
      "Một số nguyên từ 0 đến 9, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "🛠 Yêu cầu thư viện\n",
      "Cài đặt các thư viện sau bằng pip:\n",
      "pip install transformers torch\n",
      "🧪 Sử dụng mô hình\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mTo solve this task, we need to analyze the details of each model and select the best one that fits the requirements.\n",
      "\n",
      "The task is to determine the dominant theme in a collage image composed of 9 smaller images. The input is a 288x288 image, which is a 3x3 grid of 32x32 images. The output should be a single label representing the most dominant theme among the 9 sub-images.\n",
      "\n",
      "Let's analyze the models:\n",
      "\n",
      "1. **Phân loại hình ảnh** — https://huggingface.co/zhaospei/Model_7\n",
      "   - Description: This is a ViT model fine-tuned on CIFAR-10 dataset for image classification into 10 classes.\n",
      "   - Input format: RGB images of size 224x224.\n",
      "   - Output format: Probabilities for each class.\n",
      "   - Library requirements: transformers, torch, torchvision.\n",
      "   - Example code: Provided.\n",
      "\n",
      "2. **Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)** — https://huggingface.co/zhaospei/Model_6\n",
      "   - Description: This is a ViT model fine-tuned on CIFAR-100 dataset for image classification into 100 classes.\n",
      "   - Input format: RGB images of size 224x224.\n",
      "   - Output format: Probabilities for each class.\n",
      "   - Library requirements: transformers, torch, torchvision.\n",
      "   - Example code: Provided.\n",
      "\n",
      "3. **Nhận diện ảnh chữ viết tay** — https://huggingface.co/thanhtlx/image_classification_01\n",
      "   - Description: This model is for handwritten digit recognition (0-9) in color images.\n",
      "   - Input format: Color images, resized to a suitable size by the processor.\n",
      "   - Output format: A single integer from 0 to 9 representing the recognized digit.\n",
      "   - Library requirements: transformers, torch.\n",
      "   - Example code: Provided.\n",
      "\n",
      "Given the task requirements:\n",
      "\n",
      "- The input is a 288x288 image composed of 9 smaller images.\n",
      "- The task is to identify the dominant theme among these 9 images.\n",
      "\n",
      "**Best-fit Model:** \n",
      "\n",
      "The models provided are primarily for image classification tasks but are fine-tuned on different datasets (CIFAR-10, CIFAR-100, and handwritten digits). The task at hand involves classifying a composite image into one of several themes, not exactly matching any of the model's training tasks.\n",
      "\n",
      "However, **Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)** — https://huggingface.co/zhaospei/Model_6 seems more versatile as it deals with 100 classes, offering a broader range of themes that might encompass the variety needed for the task. \n",
      "\n",
      "But, we need to consider if the themes in the task are within the 100 classes of CIFAR-100 or closer to the 10 classes of CIFAR-10.\n",
      "\n",
      "**Assuming the themes can align with CIFAR-100 classes or are close to them:**\n",
      "\n",
      "**✅ Model name and link**  \n",
      " `Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)` — `https://huggingface.co/zhaospei/Model_6`\n",
      "\n",
      "**📝 Description (from tool):**  \n",
      " `Đây là mô hình Vision Transformer (ViT) được fine-tuned từ mô hình gốc google/vit-base-patch16-224-in21k trên tập dữ liệu CIFAR-100. Mô hình được huấn luyện để phân loại ảnh vào100 lớp khác nhau, mỗi lớp đại diện cho một danh mục đối tượng cụ thể.`\n",
      "\n",
      "**📥 Input format (from tool):**  \n",
      " `Định dạng: Ảnh màu RGB, Kích thước ảnh:224x224`\n",
      "\n",
      "**📤 Output format (from tool):**  \n",
      " `Định dạng: Xác suất cho mỗi lớp (logits), Kiểu dữ liệu: Tensor có kích thước [batch_size,100]`\n",
      "\n",
      "**🛠️ Library Requirements (from tool) **  \n",
      " `Cài đặt các thư viện cần thiết bằng: pip install transformers torch torchvision`\n",
      "\n",
      "**🧪 Example code (from tool):**  \n",
      " ```python\n",
      "import torch\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "\n",
      "# Tải ảnh cần phân loại\n",
      "image = Image.open(\"path_to_your_image.jpg\")\n",
      "\n",
      "# Tải processor và mô hình từ Hugging Face\n",
      "processor = ViTImageProcessor.from_pretrained(\"zhaospei/Model_6\")\n",
      "model = ViTForImageClassification.from_pretrained(\"zhaospei/Model_6\")\n",
      "\n",
      "# Xử lý đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      " logits = outputs.logits\n",
      " predicted_label = logits.argmax(-1).item()\n",
      "print(f\"Nhãn dự đoán: {model.config.id2label[predicted_label]}\")\n",
      "```\n",
      "\n",
      "**However, it's crucial to note that:**\n",
      "\n",
      "- The input image size in the task (288x288 composed of 9 images) is different from what the models are expecting (224x224).\n",
      "- The task requires processing a 3x3 grid of images to determine the dominant theme, which is not directly supported by the provided models' example codes.\n",
      "\n",
      "**To align with the task, consider preprocessing the 288x288 image into 9 segments, classify each, and then determine the dominant theme.** \n",
      "\n",
      "This approach would require adjustments beyond the provided example codes, especially to handle the 3x3 grid of images and to map the classifications back to the task's required output format. \n",
      "\n",
      "Given the constraint and aiming for simplicity, **Model_6** seems like a reasonable choice if the themes align with CIFAR-100, but a more tailored approach might be necessary to strictly adhere to the task's specifics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res2 = model_selection_using_tool_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "cb681a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('To solve this task, we need to analyze the details of each model and select '\n",
      " 'the best one that fits the requirements.\\n'\n",
      " '\\n'\n",
      " 'The task is to determine the dominant theme in a collage image composed of 9 '\n",
      " 'smaller images. The input is a 288x288 image, which is a 3x3 grid of 32x32 '\n",
      " 'images. The output should be a single label representing the most dominant '\n",
      " 'theme among the 9 sub-images.\\n'\n",
      " '\\n'\n",
      " \"Let's analyze the models:\\n\"\n",
      " '\\n'\n",
      " '1. **Phân loại hình ảnh** — https://huggingface.co/zhaospei/Model_7\\n'\n",
      " '   - Description: This is a ViT model fine-tuned on CIFAR-10 dataset for '\n",
      " 'image classification into 10 classes.\\n'\n",
      " '   - Input format: RGB images of size 224x224.\\n'\n",
      " '   - Output format: Probabilities for each class.\\n'\n",
      " '   - Library requirements: transformers, torch, torchvision.\\n'\n",
      " '   - Example code: Provided.\\n'\n",
      " '\\n'\n",
      " '2. **Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)** — '\n",
      " 'https://huggingface.co/zhaospei/Model_6\\n'\n",
      " '   - Description: This is a ViT model fine-tuned on CIFAR-100 dataset for '\n",
      " 'image classification into 100 classes.\\n'\n",
      " '   - Input format: RGB images of size 224x224.\\n'\n",
      " '   - Output format: Probabilities for each class.\\n'\n",
      " '   - Library requirements: transformers, torch, torchvision.\\n'\n",
      " '   - Example code: Provided.\\n'\n",
      " '\\n'\n",
      " '3. **Nhận diện ảnh chữ viết tay** — '\n",
      " 'https://huggingface.co/thanhtlx/image_classification_01\\n'\n",
      " '   - Description: This model is for handwritten digit recognition (0-9) in '\n",
      " 'color images.\\n'\n",
      " '   - Input format: Color images, resized to a suitable size by the '\n",
      " 'processor.\\n'\n",
      " '   - Output format: A single integer from 0 to 9 representing the recognized '\n",
      " 'digit.\\n'\n",
      " '   - Library requirements: transformers, torch.\\n'\n",
      " '   - Example code: Provided.\\n'\n",
      " '\\n'\n",
      " 'Given the task requirements:\\n'\n",
      " '\\n'\n",
      " '- The input is a 288x288 image composed of 9 smaller images.\\n'\n",
      " '- The task is to identify the dominant theme among these 9 images.\\n'\n",
      " '\\n'\n",
      " '**Best-fit Model:** \\n'\n",
      " '\\n'\n",
      " 'The models provided are primarily for image classification tasks but are '\n",
      " 'fine-tuned on different datasets (CIFAR-10, CIFAR-100, and handwritten '\n",
      " 'digits). The task at hand involves classifying a composite image into one of '\n",
      " \"several themes, not exactly matching any of the model's training tasks.\\n\"\n",
      " '\\n'\n",
      " 'However, **Phân loại hình ảnh thành100 lớp đối tượng chi tiết '\n",
      " '(fine-grained)** — https://huggingface.co/zhaospei/Model_6 seems more '\n",
      " 'versatile as it deals with 100 classes, offering a broader range of themes '\n",
      " 'that might encompass the variety needed for the task. \\n'\n",
      " '\\n'\n",
      " 'But, we need to consider if the themes in the task are within the 100 '\n",
      " 'classes of CIFAR-100 or closer to the 10 classes of CIFAR-10.\\n'\n",
      " '\\n'\n",
      " '**Assuming the themes can align with CIFAR-100 classes or are close to '\n",
      " 'them:**\\n'\n",
      " '\\n'\n",
      " '**✅ Model name and link**  \\n'\n",
      " ' `Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)` — '\n",
      " '`https://huggingface.co/zhaospei/Model_6`\\n'\n",
      " '\\n'\n",
      " '**📝 Description (from tool):**  \\n'\n",
      " ' `Đây là mô hình Vision Transformer (ViT) được fine-tuned từ mô hình gốc '\n",
      " 'google/vit-base-patch16-224-in21k trên tập dữ liệu CIFAR-100. Mô hình được '\n",
      " 'huấn luyện để phân loại ảnh vào100 lớp khác nhau, mỗi lớp đại diện cho một '\n",
      " 'danh mục đối tượng cụ thể.`\\n'\n",
      " '\\n'\n",
      " '**📥 Input format (from tool):**  \\n'\n",
      " ' `Định dạng: Ảnh màu RGB, Kích thước ảnh:224x224`\\n'\n",
      " '\\n'\n",
      " '**📤 Output format (from tool):**  \\n'\n",
      " ' `Định dạng: Xác suất cho mỗi lớp (logits), Kiểu dữ liệu: Tensor có kích '\n",
      " 'thước [batch_size,100]`\\n'\n",
      " '\\n'\n",
      " '**🛠️ Library Requirements (from tool) **  \\n'\n",
      " ' `Cài đặt các thư viện cần thiết bằng: pip install transformers torch '\n",
      " 'torchvision`\\n'\n",
      " '\\n'\n",
      " '**🧪 Example code (from tool):**  \\n'\n",
      " ' ```python\\n'\n",
      " 'import torch\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " '\\n'\n",
      " '# Tải ảnh cần phân loại\\n'\n",
      " 'image = Image.open(\"path_to_your_image.jpg\")\\n'\n",
      " '\\n'\n",
      " '# Tải processor và mô hình từ Hugging Face\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(\"zhaospei/Model_6\")\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(\"zhaospei/Model_6\")\\n'\n",
      " '\\n'\n",
      " '# Xử lý đầu vào\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# Dự đoán với mô hình\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " ' logits = outputs.logits\\n'\n",
      " ' predicted_label = logits.argmax(-1).item()\\n'\n",
      " 'print(f\"Nhãn dự đoán: {model.config.id2label[predicted_label]}\")\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " \"**However, it's crucial to note that:**\\n\"\n",
      " '\\n'\n",
      " '- The input image size in the task (288x288 composed of 9 images) is '\n",
      " 'different from what the models are expecting (224x224).\\n'\n",
      " '- The task requires processing a 3x3 grid of images to determine the '\n",
      " \"dominant theme, which is not directly supported by the provided models' \"\n",
      " 'example codes.\\n'\n",
      " '\\n'\n",
      " '**To align with the task, consider preprocessing the 288x288 image into 9 '\n",
      " 'segments, classify each, and then determine the dominant theme.** \\n'\n",
      " '\\n'\n",
      " 'This approach would require adjustments beyond the provided example codes, '\n",
      " 'especially to handle the 3x3 grid of images and to map the classifications '\n",
      " \"back to the task's required output format. \\n\"\n",
      " '\\n'\n",
      " 'Given the constraint and aiming for simplicity, **Model_6** seems like a '\n",
      " 'reasonable choice if the themes align with CIFAR-100, but a more tailored '\n",
      " \"approach might be necessary to strictly adhere to the task's specifics.\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res2['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874a1c7",
   "metadata": {},
   "source": [
    "## Output Parser Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "3658cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelingOutput(BaseModel):\n",
    "    model_description: str = Field(\n",
    "        ...,\n",
    "        description=\"The detailed description of the model.\"\n",
    "    )\n",
    "    model_input_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed input format\"\n",
    "    )\n",
    "    model_output_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed output format\"\n",
    "    )\n",
    "    model_sample_code: str = Field(\n",
    "        ...,\n",
    "        description=\"Example code to use the model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "0b610e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=ModelingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "707428ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser_llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "5a1f51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_parser_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a smart AI tasked with extracting structured technical details about a machine learning model from a reasoning result.\n",
    "                    You are given a detailed text description about a model.\n",
    "                    Your goal is to fill the following fields based on the text:\n",
    "\n",
    "                    - `model_description`: A detailed explanation of what the model is and what it does.\n",
    "                    - `model_input_format`: A detailed description of the model's input format, including dimensions, data types, and expected preprocessing if mentioned.\n",
    "                    - `model_output_format`: A detailed description of the output format including dimensions, data types, label name and its meaning.\n",
    "                    - `model_sample_code`: A sample code on how to use the model.\n",
    "\n",
    "                    You MUSTN'T create any data on your own, only using the data provided in the text.\n",
    "\n",
    "                    Return the data as a JSON object matching the following structure:\n",
    "                    {formatted_output}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]).partial(formatted_output=parser.get_format_instructions())\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"input\": res2['output']})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "0d82f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = output_parser_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "583a7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('To solve this task, we need to analyze the details of each model and select '\n",
      " 'the best one that fits the requirements.\\n'\n",
      " '\\n'\n",
      " 'The task is to determine the dominant theme in a collage image composed of 9 '\n",
      " 'smaller images. The input is a 288x288 image, which is a 3x3 grid of 32x32 '\n",
      " 'images. The output should be a single label representing the most dominant '\n",
      " 'theme among the 9 sub-images.\\n'\n",
      " '\\n'\n",
      " \"Let's analyze the models:\\n\"\n",
      " '\\n'\n",
      " '1. **Phân loại hình ảnh** — https://huggingface.co/zhaospei/Model_7\\n'\n",
      " '   - Description: This is a ViT model fine-tuned on CIFAR-10 dataset for '\n",
      " 'image classification into 10 classes.\\n'\n",
      " '   - Input format: RGB images of size 224x224.\\n'\n",
      " '   - Output format: Probabilities for each class.\\n'\n",
      " '   - Library requirements: transformers, torch, torchvision.\\n'\n",
      " '   - Example code: Provided.\\n'\n",
      " '\\n'\n",
      " '2. **Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)** — '\n",
      " 'https://huggingface.co/zhaospei/Model_6\\n'\n",
      " '   - Description: This is a ViT model fine-tuned on CIFAR-100 dataset for '\n",
      " 'image classification into 100 classes.\\n'\n",
      " '   - Input format: RGB images of size 224x224.\\n'\n",
      " '   - Output format: Probabilities for each class.\\n'\n",
      " '   - Library requirements: transformers, torch, torchvision.\\n'\n",
      " '   - Example code: Provided.\\n'\n",
      " '\\n'\n",
      " '3. **Nhận diện ảnh chữ viết tay** — '\n",
      " 'https://huggingface.co/thanhtlx/image_classification_01\\n'\n",
      " '   - Description: This model is for handwritten digit recognition (0-9) in '\n",
      " 'color images.\\n'\n",
      " '   - Input format: Color images, resized to a suitable size by the '\n",
      " 'processor.\\n'\n",
      " '   - Output format: A single integer from 0 to 9 representing the recognized '\n",
      " 'digit.\\n'\n",
      " '   - Library requirements: transformers, torch.\\n'\n",
      " '   - Example code: Provided.\\n'\n",
      " '\\n'\n",
      " 'Given the task requirements:\\n'\n",
      " '\\n'\n",
      " '- The input is a 288x288 image composed of 9 smaller images.\\n'\n",
      " '- The task is to identify the dominant theme among these 9 images.\\n'\n",
      " '\\n'\n",
      " '**Best-fit Model:** \\n'\n",
      " '\\n'\n",
      " 'The models provided are primarily for image classification tasks but are '\n",
      " 'fine-tuned on different datasets (CIFAR-10, CIFAR-100, and handwritten '\n",
      " 'digits). The task at hand involves classifying a composite image into one of '\n",
      " \"several themes, not exactly matching any of the model's training tasks.\\n\"\n",
      " '\\n'\n",
      " 'However, **Phân loại hình ảnh thành100 lớp đối tượng chi tiết '\n",
      " '(fine-grained)** — https://huggingface.co/zhaospei/Model_6 seems more '\n",
      " 'versatile as it deals with 100 classes, offering a broader range of themes '\n",
      " 'that might encompass the variety needed for the task. \\n'\n",
      " '\\n'\n",
      " 'But, we need to consider if the themes in the task are within the 100 '\n",
      " 'classes of CIFAR-100 or closer to the 10 classes of CIFAR-10.\\n'\n",
      " '\\n'\n",
      " '**Assuming the themes can align with CIFAR-100 classes or are close to '\n",
      " 'them:**\\n'\n",
      " '\\n'\n",
      " '**✅ Model name and link**  \\n'\n",
      " ' `Phân loại hình ảnh thành100 lớp đối tượng chi tiết (fine-grained)` — '\n",
      " '`https://huggingface.co/zhaospei/Model_6`\\n'\n",
      " '\\n'\n",
      " '**📝 Description (from tool):**  \\n'\n",
      " ' `Đây là mô hình Vision Transformer (ViT) được fine-tuned từ mô hình gốc '\n",
      " 'google/vit-base-patch16-224-in21k trên tập dữ liệu CIFAR-100. Mô hình được '\n",
      " 'huấn luyện để phân loại ảnh vào100 lớp khác nhau, mỗi lớp đại diện cho một '\n",
      " 'danh mục đối tượng cụ thể.`\\n'\n",
      " '\\n'\n",
      " '**📥 Input format (from tool):**  \\n'\n",
      " ' `Định dạng: Ảnh màu RGB, Kích thước ảnh:224x224`\\n'\n",
      " '\\n'\n",
      " '**📤 Output format (from tool):**  \\n'\n",
      " ' `Định dạng: Xác suất cho mỗi lớp (logits), Kiểu dữ liệu: Tensor có kích '\n",
      " 'thước [batch_size,100]`\\n'\n",
      " '\\n'\n",
      " '**🛠️ Library Requirements (from tool) **  \\n'\n",
      " ' `Cài đặt các thư viện cần thiết bằng: pip install transformers torch '\n",
      " 'torchvision`\\n'\n",
      " '\\n'\n",
      " '**🧪 Example code (from tool):**  \\n'\n",
      " ' ```python\\n'\n",
      " 'import torch\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " '\\n'\n",
      " '# Tải ảnh cần phân loại\\n'\n",
      " 'image = Image.open(\"path_to_your_image.jpg\")\\n'\n",
      " '\\n'\n",
      " '# Tải processor và mô hình từ Hugging Face\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(\"zhaospei/Model_6\")\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(\"zhaospei/Model_6\")\\n'\n",
      " '\\n'\n",
      " '# Xử lý đầu vào\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# Dự đoán với mô hình\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " ' logits = outputs.logits\\n'\n",
      " ' predicted_label = logits.argmax(-1).item()\\n'\n",
      " 'print(f\"Nhãn dự đoán: {model.config.id2label[predicted_label]}\")\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " \"**However, it's crucial to note that:**\\n\"\n",
      " '\\n'\n",
      " '- The input image size in the task (288x288 composed of 9 images) is '\n",
      " 'different from what the models are expecting (224x224).\\n'\n",
      " '- The task requires processing a 3x3 grid of images to determine the '\n",
      " \"dominant theme, which is not directly supported by the provided models' \"\n",
      " 'example codes.\\n'\n",
      " '\\n'\n",
      " '**To align with the task, consider preprocessing the 288x288 image into 9 '\n",
      " 'segments, classify each, and then determine the dominant theme.** \\n'\n",
      " '\\n'\n",
      " 'This approach would require adjustments beyond the provided example codes, '\n",
      " 'especially to handle the 3x3 grid of images and to map the classifications '\n",
      " \"back to the task's required output format. \\n\"\n",
      " '\\n'\n",
      " 'Given the constraint and aiming for simplicity, **Model_6** seems like a '\n",
      " 'reasonable choice if the themes align with CIFAR-100, but a more tailored '\n",
      " \"approach might be necessary to strictly adhere to the task's specifics.\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res2['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "530f5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is a ViT model fine-tuned on CIFAR-100 dataset for image classification '\n",
      " 'into 100 classes. The model is expected to classify images into one of 100 '\n",
      " 'different themes, which could potentially align with the themes present in a '\n",
      " '3x3 grid of images.')\n",
      "('RGB images of size 224x224. However, the task requires a 288x288 image '\n",
      " 'composed of 9 smaller 32x32 images. The input image would need to be '\n",
      " \"preprocessed to fit the model's expected input size.\")\n",
      "('Probabilities for each class. The output is a tensor of size [batch_size, '\n",
      " '100] representing the logits for each class. The predicted label is '\n",
      " 'determined by taking the argmax of the logits.')\n",
      "('import torch\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " '\\n'\n",
      " '# Load image\\n'\n",
      " 'image = Image.open(\"path_to_your_image.jpg\")\\n'\n",
      " '\\n'\n",
      " '# Load processor and model from Hugging Face\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(\"zhaospei/Model_6\")\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(\"zhaospei/Model_6\")\\n'\n",
      " '\\n'\n",
      " '# Process input\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# Predict with model\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " '    outputs = model(**inputs)\\n'\n",
      " '    logits = outputs.logits\\n'\n",
      " '    predicted_label = logits.argmax(-1).item()\\n'\n",
      " 'print(f\"Predicted label: {model.config.id2label[predicted_label]}\")')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(ans.model_description)\n",
    "pprint.pprint(ans.model_input_format)\n",
    "pprint.pprint(ans.model_output_format)\n",
    "pprint.pprint(ans.model_sample_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

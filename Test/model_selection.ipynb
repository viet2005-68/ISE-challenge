{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42744f82",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91bed7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python313.zip', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\DLLs', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313', '', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\viett\\\\label-studio', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\viett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\Pythonwin', '..', '..', '..', '..', '..', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from tools.fetching_description_from_huggingface import fetching_description_from_huggingface\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "22abc01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STT</th>\n",
       "      <th>Task</th>\n",
       "      <th>Validation data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Bối cảnh của vấn đề:\\r\\nNhận dạng chữ viết ta...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bối cảnh của vấn đề:\\r\\nTrong thời đại thông t...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bối cảnh của vấn đề:\\r\\nĐây là một nhiệm vụ hồ...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bối cảnh của vấn đề:\\r\\nĐiều quan trọng là các...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bối cảnh của vấn đề:\\r\\nTrong nhiều ứng dụng t...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STT                                               Task Validation data\n",
       "0    1  \"Bối cảnh của vấn đề:\\r\\nNhận dạng chữ viết ta...            Link\n",
       "1    2  Bối cảnh của vấn đề:\\r\\nTrong thời đại thông t...            Link\n",
       "2    3  Bối cảnh của vấn đề:\\r\\nĐây là một nhiệm vụ hồ...            Link\n",
       "3    4  Bối cảnh của vấn đề:\\r\\nĐiều quan trọng là các...            Link\n",
       "4    5  Bối cảnh của vấn đề:\\r\\nTrong nhiều ứng dụng t...            Link"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "953cae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Bối cảnh của vấn đề:\\r\\nNhận dạng chữ viết tay là một bài toán cơ bản trong lĩnh vực học máy và xử lý ảnh, với nhiều ứng dụng thực tiễn như nhận dạng chữ số trên phiếu khảo sát, hóa đơn hay bài thi tự động. Việc phân loại chữ số viết tay thành số nguyên tố hoặc không giúp mở rộng khả năng ứng dụng trong các bài toán toán học tự động, kiểm tra bài tập, hoặc các ứng dụng giáo dục.\\r\\n\\r\\nYêu cầu cụ thể cần đạt được:\\r\\nXây dựng một hệ thống có khả năng nhận diện chữ số viết tay từ ảnh và xác định xem số đó có phải là số nguyên tố hay không.\\r\\nĐầu vào là ảnh chứa một chữ số viết tay.\\r\\nĐầu ra là nhãn phân loại nhị phân: \"\"nguyên tố\"\" hoặc \"\"không nguyên tố\"\".\\r\\n\\r\\nĐịnh dạng dữ liệu đầu vào cho bài toán tổng thể:\\r\\nMột thư mục có tên là \"\"images\"\" chứa các ảnh grayscale 28x28 pixel, mỗi ảnh chứa một chữ số viết tay từ 0 đến 9.\\r\\n\\r\\nĐịnh dạng kết quả đầu ra mong muốn cho bài toán tổng thể:\\r\\nFile output.csv mỗi hàng là kết quả dự đoán mỗi ảnh\\r\\ncó các cột:\\r\\nfile_name: tên file ảnh\\r\\nprediction: nhãn của ảnh:\\r\\n\"\"số nguyên tố\"\" nếu số trong ảnh là số nguyên tố.\\r\\n\"\"không nguyên tố\"\" nếu số trong ảnh không phải số nguyên tố.\"'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af3bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    # scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    # scrape_status = scraper.scrape_url(\n",
    "    #     url,\n",
    "    #     formats=['markdown']\n",
    "    # )\n",
    "    # return scrape_status.markdown\n",
    "    result = fetching_description_from_huggingface(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77f3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperParameters(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6a0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52a9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409f8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6511a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0de6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef593964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14b15c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = classify_agent(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab3d7f",
   "metadata": {},
   "source": [
    "# Modeling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f656ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInfo(BaseModel):\n",
    "    model: str = Field(..., description=\"Model name\")\n",
    "    url: str = Field(..., description=\"URL to the model\")\n",
    "\n",
    "class ModelSelection(BaseModel):\n",
    "    models: List[ModelInfo] = Field(..., description=\"List of available models with name and URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "18dcc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_parser = PydanticOutputParser(pydantic_object=ModelSelection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de4ed792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the suitable model for a given task.\n",
    "                    Given:\n",
    "                    - A user description about the task\n",
    "                    - A list of available model (names and links)\n",
    "                    Your job is to choose ALL suitable models provided in the list for user's specific tasks.\n",
    "                    Return the answer in the format\n",
    "                    {structured_output}\n",
    "                    Here are the list of model:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]).partial(structured_output=model_selection_parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | model_selection_parser\n",
    "\n",
    "    result = chain.invoke({\"input\": task, \"model_list\": format_model_list(df_model)})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd097a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viett\\AppData\\Local\\Temp\\ipykernel_33328\\7332665.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
      "C:\\Users\\viett\\AppData\\Local\\Temp\\ipykernel_33328\\7332665.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = str(row[2])\n"
     ]
    }
   ],
   "source": [
    "res = model_selection_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03a8819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelInfo(model='Nhận diện ảnh chữ viết tay', url='https://huggingface.co/thanhtlx/image_classification_01')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3b0dc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_using_tool_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the **Best-fit model** for a given task.\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and url)\n",
    "                    - A tool that fetches model details from a provided URL (it help gathers model description, input/output format, code sample usage)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - ✅ Model description\n",
    "                        - 📥 Input format\n",
    "                        - 📤 Output format\n",
    "                        - 🛠️ Library requirements\n",
    "                        - 🧪 Code sample (usage code snippet)\n",
    "                    2. Select the best model for user given task based on the data that the tool gives you.\n",
    "\n",
    "                    ⚠️ VERY IMPORTANT RULES\n",
    "\n",
    "                    - ❌ DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - ❌ DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - ✅ ONLY use the **actual output** returned from the tool\n",
    "                    - ✅ Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ## 🧠 Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **✅ Model name and link**  \n",
    "                    `<model name>` — `<link>`\n",
    "\n",
    "                    **📝 Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **📥 Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **📤 Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **🛠️ Library Requirements (from tool) **\n",
    "                    <requirements to use the model>\n",
    "\n",
    "                    **🧪 Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "\n",
    "                    Here are the list of models and there corresponding URL:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    # result = executor.invoke({\"input\": task_input})\n",
    "    result = executor.invoke({\"input\": task_input, \"model_list\": res.models})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e8b0f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "📝 Mô tả\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "📌 Chi tiết các mô hình\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "📥 Đầu vào\n",
      "Định dạng: Ảnh màu (RGB)\n",
      "Kiểu dữ liệu: PIL.Image.Image\n",
      "Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor (thường là 224x224)\n",
      "Giá trị pixel: [0, 255] (chuẩn hóa tự động bởi processor)\n",
      "📤 Đầu ra\n",
      "Một số nguyên từ 0 đến 9, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "🛠 Yêu cầu thư viện\n",
      "Cài đặt các thư viện sau bằng pip:\n",
      "pip install transformers torch\n",
      "🧪 Sử dụng mô hình\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "📝 Mô tả\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "📌 Chi tiết các mô hình\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "📥 Đầu vào\n",
      "Định dạng: Ảnh màu (RGB)\n",
      "Kiểu dữ liệu: PIL.Image.Image\n",
      "Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor (thường là 224x224)\n",
      "Giá trị pixel: [0, 255] (chuẩn hóa tự động bởi processor)\n",
      "📤 Đầu ra\n",
      "Một số nguyên từ 0 đến 9, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "🛠 Yêu cầu thư viện\n",
      "Cài đặt các thư viện sau bằng pip:\n",
      "pip install transformers torch\n",
      "🧪 Sử dụng mô hình\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "📝 Mô tả\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "📌 Chi tiết các mô hình\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "📥 Đầu vào\n",
      "Định dạng: Ảnh màu (RGB)\n",
      "Kiểu dữ liệu: PIL.Image.Image\n",
      "Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor (thường là 224x224)\n",
      "Giá trị pixel: [0, 255] (chuẩn hóa tự động bởi processor)\n",
      "📤 Đầu ra\n",
      "Một số nguyên từ 0 đến 9, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "🛠 Yêu cầu thư viện\n",
      "Cài đặt các thư viện sau bằng pip:\n",
      "pip install transformers torch\n",
      "🧪 Sử dụng mô hình\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m**✅ Model name and link**  \n",
      " `Nhận diện ảnh chữ viết tay` — `https://huggingface.co/thanhtlx/image_classification_01`\n",
      "\n",
      "**📝 Description (from tool):**  \n",
      " Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ0 đến9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "**📥 Input format (from tool):**  \n",
      " Định dạng: Ảnh màu (RGB)\n",
      " Kiểu dữ liệu: PIL.Image.Image\n",
      " Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor (thường là224x224)\n",
      " Giá trị pixel: [0,255] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "**📤 Output format (from tool):**  \n",
      " Một số nguyên từ0 đến9, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "**🛠️ Library Requirements (from tool) **  \n",
      " Cài đặt các thư viện sau bằng pip:\n",
      " pip install transformers torch\n",
      "\n",
      "**🧪 Example code (from tool):**  \n",
      " ```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "```\n",
      "\n",
      "Tuy nhiên, mô hình này chỉ nhận diện chữ số viết tay từ 0 đến 9, nhưng chưa phân loại được số nguyên tố hay không. Để giải quyết bài toán yêu cầu, cần thực hiện các bước sau:\n",
      "\n",
      "1. **Tiền xử lý ảnh**: Chuyển đổi ảnh màu thành ảnh grayscale và resize về kích thước 28x28 pixel để phù hợp với định dạng đầu vào.\n",
      "2. **Nhận diện chữ số**: Sử dụng mô hình `Nhận diện ảnh chữ viết tay` để nhận diện chữ số viết tay từ ảnh.\n",
      "3. **Kiểm tra số nguyên tố**: Viết hàm kiểm tra số nguyên tố để xác định số nhận diện có phải là số nguyên tố hay không.\n",
      "\n",
      "Dưới đây là đoạn mã hoàn chỉnh:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "def is_prime(n):\n",
      " if n <= 1:\n",
      " return False\n",
      " if n == 2:\n",
      " return True\n",
      " if n % 2 == 0:\n",
      " return False\n",
      " max_divisor = int(n**0.5) + 1\n",
      " for d in range(3, max_divisor, 2):\n",
      " if n % d == 0:\n",
      " return False\n",
      " return True\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "\n",
      "# Kiểm tra số nguyên tố\n",
      "if is_prime(predicted_class):\n",
      " print(\"nguyên tố\")\n",
      "else:\n",
      " print(\"không nguyên tố\")\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res2 = model_selection_using_tool_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb681a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**✅ Model name and link**  \\n'\n",
      " ' `Nhận diện ảnh chữ viết tay` — '\n",
      " '`https://huggingface.co/thanhtlx/image_classification_01`\\n'\n",
      " '\\n'\n",
      " '**📝 Description (from tool):**  \\n'\n",
      " ' Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số '\n",
      " 'viết tay (từ0 đến9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision '\n",
      " 'Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay '\n",
      " 'được chụp hoặc scan dưới dạng ảnh màu.\\n'\n",
      " '\\n'\n",
      " '**📥 Input format (from tool):**  \\n'\n",
      " ' Định dạng: Ảnh màu (RGB)\\n'\n",
      " ' Kiểu dữ liệu: PIL.Image.Image\\n'\n",
      " ' Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor '\n",
      " '(thường là224x224)\\n'\n",
      " ' Giá trị pixel: [0,255] (chuẩn hóa tự động bởi processor)\\n'\n",
      " '\\n'\n",
      " '**📤 Output format (from tool):**  \\n'\n",
      " ' Một số nguyên từ0 đến9, là kết quả phân loại tương ứng với chữ số xuất hiện '\n",
      " 'trong ảnh.\\n'\n",
      " '\\n'\n",
      " '**🛠️ Library Requirements (from tool) **  \\n'\n",
      " ' Cài đặt các thư viện sau bằng pip:\\n'\n",
      " ' pip install transformers torch\\n'\n",
      " '\\n'\n",
      " '**🧪 Example code (from tool):**  \\n'\n",
      " ' ```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '# Đọc ảnh cần phân loại\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '# Xử lý ảnh đầu vào\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '# Dự đoán với mô hình\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '# Lấy kết quả dự đoán\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " 'print(f\"prediction: {predicted_class}\")\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Tuy nhiên, mô hình này chỉ nhận diện chữ số viết tay từ 0 đến 9, nhưng chưa '\n",
      " 'phân loại được số nguyên tố hay không. Để giải quyết bài toán yêu cầu, cần '\n",
      " 'thực hiện các bước sau:\\n'\n",
      " '\\n'\n",
      " '1. **Tiền xử lý ảnh**: Chuyển đổi ảnh màu thành ảnh grayscale và resize về '\n",
      " 'kích thước 28x28 pixel để phù hợp với định dạng đầu vào.\\n'\n",
      " '2. **Nhận diện chữ số**: Sử dụng mô hình `Nhận diện ảnh chữ viết tay` để '\n",
      " 'nhận diện chữ số viết tay từ ảnh.\\n'\n",
      " '3. **Kiểm tra số nguyên tố**: Viết hàm kiểm tra số nguyên tố để xác định số '\n",
      " 'nhận diện có phải là số nguyên tố hay không.\\n'\n",
      " '\\n'\n",
      " 'Dưới đây là đoạn mã hoàn chỉnh:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " '\\n'\n",
      " 'def is_prime(n):\\n'\n",
      " ' if n <= 1:\\n'\n",
      " ' return False\\n'\n",
      " ' if n == 2:\\n'\n",
      " ' return True\\n'\n",
      " ' if n % 2 == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' max_divisor = int(n**0.5) + 1\\n'\n",
      " ' for d in range(3, max_divisor, 2):\\n'\n",
      " ' if n % d == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' return True\\n'\n",
      " '\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '\\n'\n",
      " '# Đọc ảnh cần phân loại\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '\\n'\n",
      " '# Xử lý ảnh đầu vào\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# Dự đoán với mô hình\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '\\n'\n",
      " '# Lấy kết quả dự đoán\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " '\\n'\n",
      " '# Kiểm tra số nguyên tố\\n'\n",
      " 'if is_prime(predicted_class):\\n'\n",
      " ' print(\"nguyên tố\")\\n'\n",
      " 'else:\\n'\n",
      " ' print(\"không nguyên tố\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res2['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874a1c7",
   "metadata": {},
   "source": [
    "## Output Parser Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3658cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelingOutput(BaseModel):\n",
    "    model_description: str = Field(\n",
    "        ...,\n",
    "        description=\"The detailed description of the model.\"\n",
    "    )\n",
    "    model_input_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed input format\"\n",
    "    )\n",
    "    model_output_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed output format\"\n",
    "    )\n",
    "    model_requirements: str = Field(\n",
    "        ...,\n",
    "        description=\"Requirement libraries need to install to use the model.\"\n",
    "    )\n",
    "    model_sample_code: str = Field(\n",
    "        ...,\n",
    "        description=\"Example code to use the model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0b610e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=ModelingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "707428ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser_llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5a1f51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_parser_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a smart AI tasked with extracting structured technical details about a machine learning model from a reasoning result.\n",
    "                    You are given a detailed text description about a model.\n",
    "                    Your goal is to fill the following fields based on the text:\n",
    "\n",
    "                    - `model_description`: A detailed explanation of what the model is and what it does.\n",
    "                    - `model_input_format`: A detailed description of the model's input format, including dimensions, data types, and expected preprocessing if mentioned.\n",
    "                    - `model_output_format`: A detailed description of the output format including dimensions, data types, label name and its meaning.\n",
    "                    - `model_requirements`: A detailed description about the requirements needed to be sastified in order to use the model\n",
    "                    - `model_sample_code`: A sample code on how to use the model.\n",
    "\n",
    "                    You MUSTN'T create any data on your own, only using the data provided in the text.\n",
    "\n",
    "                    Return the data as a JSON object matching the following structure:\n",
    "                    {formatted_output}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]).partial(formatted_output=parser.get_format_instructions())\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"input\": res2['output']})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d82f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = output_parser_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "583a7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**✅ Model name and link**  \\n'\n",
      " ' `Nhận diện ảnh chữ viết tay` — '\n",
      " '`https://huggingface.co/thanhtlx/image_classification_01`\\n'\n",
      " '\\n'\n",
      " '**📝 Description (from tool):**  \\n'\n",
      " ' Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số '\n",
      " 'viết tay (từ0 đến9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision '\n",
      " 'Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay '\n",
      " 'được chụp hoặc scan dưới dạng ảnh màu.\\n'\n",
      " '\\n'\n",
      " '**📥 Input format (from tool):**  \\n'\n",
      " ' Định dạng: Ảnh màu (RGB)\\n'\n",
      " ' Kiểu dữ liệu: PIL.Image.Image\\n'\n",
      " ' Kích thước ảnh: Mô hình sẽ tự resize theo cấu hình của ViTImageProcessor '\n",
      " '(thường là224x224)\\n'\n",
      " ' Giá trị pixel: [0,255] (chuẩn hóa tự động bởi processor)\\n'\n",
      " '\\n'\n",
      " '**📤 Output format (from tool):**  \\n'\n",
      " ' Một số nguyên từ0 đến9, là kết quả phân loại tương ứng với chữ số xuất hiện '\n",
      " 'trong ảnh.\\n'\n",
      " '\\n'\n",
      " '**🛠️ Library Requirements (from tool) **  \\n'\n",
      " ' Cài đặt các thư viện sau bằng pip:\\n'\n",
      " ' pip install transformers torch\\n'\n",
      " '\\n'\n",
      " '**🧪 Example code (from tool):**  \\n'\n",
      " ' ```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '# Đọc ảnh cần phân loại\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '# Xử lý ảnh đầu vào\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '# Dự đoán với mô hình\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '# Lấy kết quả dự đoán\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " 'print(f\"prediction: {predicted_class}\")\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Tuy nhiên, mô hình này chỉ nhận diện chữ số viết tay từ 0 đến 9, nhưng chưa '\n",
      " 'phân loại được số nguyên tố hay không. Để giải quyết bài toán yêu cầu, cần '\n",
      " 'thực hiện các bước sau:\\n'\n",
      " '\\n'\n",
      " '1. **Tiền xử lý ảnh**: Chuyển đổi ảnh màu thành ảnh grayscale và resize về '\n",
      " 'kích thước 28x28 pixel để phù hợp với định dạng đầu vào.\\n'\n",
      " '2. **Nhận diện chữ số**: Sử dụng mô hình `Nhận diện ảnh chữ viết tay` để '\n",
      " 'nhận diện chữ số viết tay từ ảnh.\\n'\n",
      " '3. **Kiểm tra số nguyên tố**: Viết hàm kiểm tra số nguyên tố để xác định số '\n",
      " 'nhận diện có phải là số nguyên tố hay không.\\n'\n",
      " '\\n'\n",
      " 'Dưới đây là đoạn mã hoàn chỉnh:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " '\\n'\n",
      " 'def is_prime(n):\\n'\n",
      " ' if n <= 1:\\n'\n",
      " ' return False\\n'\n",
      " ' if n == 2:\\n'\n",
      " ' return True\\n'\n",
      " ' if n % 2 == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' max_divisor = int(n**0.5) + 1\\n'\n",
      " ' for d in range(3, max_divisor, 2):\\n'\n",
      " ' if n % d == 0:\\n'\n",
      " ' return False\\n'\n",
      " ' return True\\n'\n",
      " '\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '\\n'\n",
      " '# Đọc ảnh cần phân loại\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '\\n'\n",
      " '# Xử lý ảnh đầu vào\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '\\n'\n",
      " '# Dự đoán với mô hình\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '\\n'\n",
      " '# Lấy kết quả dự đoán\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " '\\n'\n",
      " '# Kiểm tra số nguyên tố\\n'\n",
      " 'if is_prime(predicted_class):\\n'\n",
      " ' print(\"nguyên tố\")\\n'\n",
      " 'else:\\n'\n",
      " ' print(\"không nguyên tố\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res2['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "530f5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is an image classification model trained to recognize handwritten '\n",
      " 'digits (from 0 to 9) in color images. The model uses the Vision Transformer '\n",
      " '(ViT) architecture and was trained on a dataset of handwritten digits '\n",
      " 'captured or scanned as color images.')\n",
      "(\"The model's input format is a color image (RGB) of type PIL.Image.Image. The \"\n",
      " 'image size is automatically resized to 224x224 by the ViTImageProcessor. '\n",
      " 'Pixel values range from [0, 255] and are automatically normalized by the '\n",
      " 'processor.')\n",
      "(\"The model's output format is an integer from 0 to 9, representing the \"\n",
      " 'classification result corresponding to the digit appearing in the image.')\n",
      "('The required libraries are transformers and torch, which can be installed '\n",
      " 'using pip: pip install transformers torch')\n",
      "('```python\\n'\n",
      " 'from transformers import ViTForImageClassification, ViTImageProcessor\\n'\n",
      " 'from PIL import Image\\n'\n",
      " 'import torch\\n'\n",
      " 'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      " 'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      " 'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      " '# Load image to classify\\n'\n",
      " 'image = Image.open(\"images.png\")\\n'\n",
      " '# Preprocess input image\\n'\n",
      " 'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      " '# Make prediction with model\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " ' outputs = model(**inputs)\\n'\n",
      " '# Get prediction result\\n'\n",
      " 'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      " 'print(f\"prediction: {predicted_class}\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(ans.model_description)\n",
    "pprint.pprint(ans.model_input_format)\n",
    "pprint.pprint(ans.model_output_format)\n",
    "pprint.pprint(ans.model_requirements)\n",
    "pprint.pprint(ans.model_sample_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978bb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "77a72e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3643728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentCodingState(TypedDict):\n",
    "    problem_description: str | None\n",
    "    problem_input_description: str | None\n",
    "    problem_output_description: str | None\n",
    "    model_description: str | None\n",
    "    model_input_format: str | None\n",
    "    model_output_format: str | None\n",
    "    model_requirements: str | None\n",
    "    model_sample_code: str | None\n",
    "    output_classes: str | None\n",
    "    code: str | None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Variables\n",
    "\n",
    "# %% [code]\n",
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "\n",
    "# %% [markdown]\n",
    "# # Import Modules\n",
    "\n",
    "# %% [code]\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from tools.fetching_description_from_huggingface import fetching_description_from_huggingface\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "# %% [markdown]\n",
    "# # Testing\n",
    "\n",
    "# %% [code]\n",
    "df_task = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")\n",
    "\n",
    "# %% [code]\n",
    "df_task\n",
    "\n",
    "# %% [code]\n",
    "task = df_task[\"Task\"][0]\n",
    "\n",
    "# %% [code]\n",
    "task\n",
    "\n",
    "# %% [code]\n",
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Tools\n",
    "\n",
    "# %% [code]\n",
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    # scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    # scrape_status = scraper.scrape_url(\n",
    "    #     url,\n",
    "    #     formats=['markdown']\n",
    "    # )\n",
    "    # return scrape_status.markdown\n",
    "    result = fetching_description_from_huggingface(url)\n",
    "    return result\n",
    "\n",
    "# %% [code]\n",
    "class WebScraperParameters(BaseModel):\n",
    "    url: str\n",
    "\n",
    "# %% [code]\n",
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')\n",
    "\n",
    "# %% [code]\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Model\n",
    "\n",
    "# %% [code]\n",
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# %% [code]\n",
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )\n",
    "\n",
    "# %% [code]\n",
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks\n",
    "\n",
    "# %% [code]\n",
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state\n",
    "\n",
    "# %% [code]\n",
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}\n",
    "\n",
    "# %% [code]\n",
    "state = classify_agent(state)\n",
    "\n",
    "# %% [markdown]\n",
    "# # Modeling Agent\n",
    "\n",
    "# %% [code]\n",
    "class ModelInfo(BaseModel):\n",
    "    model: str = Field(..., description=\"Model name\")\n",
    "    url: str = Field(..., description=\"URL to the model\")\n",
    "\n",
    "class ModelSelection(BaseModel):\n",
    "    models: List[ModelInfo] = Field(..., description=\"List of available models with name and URL\")\n",
    "\n",
    "# %% [code]\n",
    "model_selection_parser = PydanticOutputParser(pydantic_object=ModelSelection)\n",
    "\n",
    "# %% [code]\n",
    "def model_selection_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the suitable model for a given task.\n",
    "                    Given:\n",
    "                    - A user description about the task\n",
    "                    - A list of available model (names and links)\n",
    "                    Your job is to choose ALL suitable models provided in the list for user's specific tasks.\n",
    "                    Return the answer in the format\n",
    "                    {structured_output}\n",
    "                    Here are the list of model:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]).partial(structured_output=model_selection_parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | model_selection_parser\n",
    "\n",
    "    result = chain.invoke({\"input\": task, \"model_list\": format_model_list(df_model)})\n",
    "    return result\n",
    "\n",
    "# %% [code]\n",
    "res = model_selection_agent(state)\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(res.models)\n",
    "\n",
    "# %% [code]\n",
    "def model_selection_using_tool_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a machine learning expert assigned to select the **Best-fit model** for a given task.\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and url)\n",
    "                    - A tool that fetches model details from a provided URL (it help gathers model description, input/output format, code sample usage)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - ✅ Model description\n",
    "                        - 📥 Input format\n",
    "                        - 📤 Output format\n",
    "                        - 🛠️ Library requirements\n",
    "                        - 🧪 Code sample (usage code snippet)\n",
    "                    2. Select the best model for user given task based on the data that the tool gives you.\n",
    "\n",
    "                    ⚠️ VERY IMPORTANT RULES\n",
    "\n",
    "                    - ❌ DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - ❌ DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - ✅ ONLY use the **actual output** returned from the tool\n",
    "                    - ✅ Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ## 🧠 Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **✅ Model name and link**  \n",
    "                    `<model name>` — `<link>`\n",
    "\n",
    "                    **📝 Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **📥 Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **📤 Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **🛠️ Library Requirements (from tool) **\n",
    "                    <requirements to use the model>\n",
    "\n",
    "                    **🧪 Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "\n",
    "                    Here are the list of models and there corresponding URL:\n",
    "                    {model_list}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    # result = executor.invoke({\"input\": task_input})\n",
    "    result = executor.invoke({\"input\": task_input, \"model_list\": res.models})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}\n",
    "\n",
    "# %% [code]\n",
    "res2 = model_selection_using_tool_agent(state)\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(res2['output'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Output Parser Agent\n",
    "\n",
    "# %% [code]\n",
    "class ModelingOutput(BaseModel):\n",
    "    model_description: str = Field(\n",
    "        ...,\n",
    "        description=\"The detailed description of the model.\"\n",
    "    )\n",
    "    model_input_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed input format\"\n",
    "    )\n",
    "    model_output_format: str = Field(\n",
    "        ...,\n",
    "        description=\"Model's detailed output format\"\n",
    "    )\n",
    "    model_requirements: str = Field(\n",
    "        ...,\n",
    "        description=\"Requirement libraries need to install to use the model.\"\n",
    "    )\n",
    "    model_sample_code: str = Field(\n",
    "        ...,\n",
    "        description=\"Example code to use the model\"\n",
    "    )\n",
    "\n",
    "# %% [code]\n",
    "parser = PydanticOutputParser(pydantic_object=ModelingOutput)\n",
    "\n",
    "# %% [code]\n",
    "output_parser_llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# %% [code]\n",
    "def output_parser_agent(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a smart AI tasked with extracting structured technical details about a machine learning model from a reasoning result.\n",
    "                    You are given a detailed text description about a model.\n",
    "                    Your goal is to fill the following fields based on the text:\n",
    "\n",
    "                    - `model_description`: A detailed explanation of what the model is and what it does.\n",
    "                    - `model_input_format`: A detailed description of the model's input format, including dimensions, data types, and expected preprocessing if mentioned.\n",
    "                    - `model_output_format`: A detailed description of the output format including dimensions, data types, label name and its meaning.\n",
    "                    - `model_requirements`: A detailed description about the requirements needed to be sastified in order to use the model\n",
    "                    - `model_sample_code`: A sample code on how to use the model.\n",
    "\n",
    "                    You MUSTN'T create any data on your own, only using the data provided in the text.\n",
    "\n",
    "                    Return the data as a JSON object matching the following structure:\n",
    "                    {formatted_output}\n",
    "                    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]).partial(formatted_output=parser.get_format_instructions())\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"input\": res2['output']})\n",
    "    return response\n",
    "\n",
    "# %% [code]\n",
    "ans = output_parser_agent(state)\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(res2['output'])\n",
    "\n",
    "# %% [code]\n",
    "pprint.pprint(ans.model_description)\n",
    "pprint.pprint(ans.model_input_format)\n",
    "pprint.pprint(ans.model_output_format)\n",
    "pprint.pprint(ans.model_requirements)\n",
    "pprint.pprint(ans.model_sample_code)\n",
    "\n",
    "# %% [code]\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "class AgentCodingState(TypedDict):\n",
    "    problem_description: str | None\n",
    "    problem_input_description: str | None\n",
    "    problem_output_description: str | None\n",
    "    model_description: str | None\n",
    "    model_input_format: str | None\n",
    "    model_output_format: str | None\n",
    "    model_requirements: str | None\n",
    "    model_sample_code: str | None\n",
    "    output_classes: str | None\n",
    "    code: str | None\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "base_prompt = r\"\"\"\n",
    "    You are a specialist in Machine Learning. Your task is to generate a *fully functional with all necessary imports and dependencies* codebase in *Python* that can be executed flawlessly.\n",
    "\n",
    "    You will be provided with:\n",
    "    - A problem description\n",
    "    - An input specification\n",
    "    - An output specification\n",
    "    - A model description\n",
    "\n",
    "    ### Input:\n",
    "    - Problem description: {problem_description}\n",
    "    - Problem input specification: {problem_input_description}\n",
    "    - Problem output specification: {problem_output_description}\n",
    "    - ML model description: {model_description}\n",
    "    - ML model input format: {model_input_format}\n",
    "    - ML model output format: {model_output_format}\n",
    "    - ML model requirements: {model_requirements}\n",
    "    - ML model sample code: {model_sample_code}\n",
    "    - Output classes: {output_classes}\n",
    "\n",
    "    ### Guidelines\n",
    "\n",
    "    You *must* strictly follow the following guidelines:\n",
    "    - The preprocessing step should be suitable for the data type.\n",
    "    - The postprocessing step should notices the differences between the data returned by the model and the output requirements. You must extract and use the exact class labels as defined in the output specification.\n",
    "    - Do *not invent new labels or translate* the class names. Use them exactly as given.\n",
    "    - You *must* make sure that your codebase can be executed flawlessly that would not encounter any errors or exceptions.\n",
    "\n",
    "    Your implementation *must strictly follow* the structure below:\n",
    "    1. *Imports*: All required libraries.\n",
    "    2. *Preprocessing*: Handle and transform the input as defined.\n",
    "    3. *Inference logic*: Use the described model for prediction. You *must* use tqdm or similar logging library to track progress.\n",
    "    4. *Postprocessing*: Format or transform the raw output into the final result as described.\n",
    "\n",
    "    You must *not* include any explanations, markdown, or logging outside what is required by the problem.\n",
    "\n",
    "    Return *only* the complete Python codebase. Wrap it with:\n",
    "    \\`\\`\\`python\n",
    "    # code here\n",
    "    \\`\\`\\`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "class OutputState(TypedDict):\n",
    "    output_classes: str | None\n",
    "\n",
    "# %% [code]\n",
    "def output_agent(state: OutputState) -> OutputState:\n",
    "    prompt = r\"\"\"\n",
    "        Your are a specialist in machine learning. Your task is to identify the absolute classes of the given problem description, following with an output description.\n",
    "        ### Input:\n",
    "        - Problem description: {problem_description}\n",
    "        - Output description: {output_description}\n",
    "\n",
    "        You must return an array, strictly following these guidelines:\n",
    "        - Understand the context from the given problem description.\n",
    "        - Extract the class names from the output description. You **must not** invent new labels or translate the class names. Use them exactly as given in the output description.\n",
    "        - Create an array containing the classes.\n",
    "\n",
    "        You must return only the array containing those classes, without any formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt.format(\n",
    "        problem_description = state[\"problem_description\"],\n",
    "        output_description = state[\"output_description\"]\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"output_classes\": response.content}\n",
    "\n",
    "# %% [code]\n",
    "output_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"output_description\": ans.model_output_format\n",
    "}\n",
    "\n",
    "# %% [code]\n",
    "new_state = output_agent(output_state)\n",
    "\n",
    "# %% [code]\n",
    "new_state[\"output_classes\"]\n",
    "\n",
    "# %% [code]\n",
    "def coding_agent(state: AgentCodingState) -> AgentCodingState:\n",
    "    prompt = base_prompt.format(\n",
    "        problem_description=state[\"problem_description\"],\n",
    "        problem_input_description=state[\"problem_input_description\"],\n",
    "        problem_output_description=state[\"problem_output_description\"],\n",
    "        model_description=state[\"model_description\"],\n",
    "        model_input_format=state[\"model_input_format\"],\n",
    "        model_output_format=state[\"model_output_format\"],\n",
    "        model_requirements=state[\"model_requirements\"],\n",
    "        model_sample_code=state[\"model_sample_code\"],\n",
    "        output_classes=state[\"output_classes\"],\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"code\": response.content}\n",
    "\n",
    "# %% [code]\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "prev_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"problem_input_description\": ans.problem_input_description,\n",
    "    \"problem_output_description\": ans.problem_output_description,\n",
    "    \"model_description\": res2['output'],\n",
    "    \"model_input_format\": ans.model_input_format,\n",
    "    \"model_output_format\": ans.model_output_format,\n",
    "    \"model_requirements\": ans.model_requirements,\n",
    "    \"model_sample_code\": ans.model_sample_code,\n",
    "    \"output_classes\": ans.output_classes,\n",
    "}\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "state = coding_agent(prev_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ad8e05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputState(TypedDict):\n",
    "    output_classes: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c4731165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_agent(state: OutputState) -> OutputState:\n",
    "    prompt = r\"\"\"\n",
    "        Your are a specialist in machine learning. Your task is to identify the absolute classes of the given problem description, following with an output description.\n",
    "        ### Input:\n",
    "        - Problem description: {problem_description}\n",
    "        - Output description: {output_description}\n",
    "\n",
    "        You must return an array, strictly following these guidelines:\n",
    "        - Understand the context from the given problem description.\n",
    "        - Extract the class names from the output description. You **must not** invent new labels or translate the class names. Use them exactly as given in the output description.\n",
    "        - Create an array containing the classes.\n",
    "\n",
    "        You must return only the array containing those classes, without any formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt.format(\n",
    "        problem_description = state[\"problem_description\"],\n",
    "        output_description = state[\"output_description\"]\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"output_classes\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3895d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"output_description\": ans.model_output_format\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a52076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = output_agent(output_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72a9f7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[\"output_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c3313114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_agent(state: AgentCodingState) -> AgentCodingState:\n",
    "    prompt = base_prompt.format(\n",
    "        problem_description=state[\"problem_description\"],\n",
    "        problem_input_description=state[\"problem_input_description\"],\n",
    "        problem_output_description=state[\"problem_output_description\"],\n",
    "        model_description=state[\"model_description\"],\n",
    "        model_input_format=state[\"model_input_format\"],\n",
    "        model_output_format=state[\"model_output_format\"],\n",
    "        model_requirements=state[\"model_requirements\"],\n",
    "        model_sample_code=state[\"model_sample_code\"],\n",
    "        output_classes=state[\"output_classes\"],\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"code\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a72457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d80aeddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelingOutput' object has no attribute 'problem_input_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m prev_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproblem_description\u001b[39m\u001b[33m\"\u001b[39m: task,\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproblem_input_description\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproblem_input_description\u001b[49m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproblem_output_description\u001b[39m\u001b[33m\"\u001b[39m: ans.problem_output_description,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_description\u001b[39m\u001b[33m\"\u001b[39m: res2[\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_input_format\u001b[39m\u001b[33m\"\u001b[39m: ans.model_input_format,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_output_format\u001b[39m\u001b[33m\"\u001b[39m: ans.model_output_format,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_requirements\u001b[39m\u001b[33m\"\u001b[39m: ans.model_requirements,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_sample_code\u001b[39m\u001b[33m\"\u001b[39m: ans.model_sample_code,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_classes\u001b[39m\u001b[33m\"\u001b[39m: ans.output_classes,\n\u001b[32m     11\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viett\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelingOutput' object has no attribute 'problem_input_description'"
     ]
    }
   ],
   "source": [
    "prev_state = {\n",
    "    \"problem_description\": task,\n",
    "    \"problem_input_description\": ans.problem_input_description,\n",
    "    \"problem_output_description\": ans.problem_output_description,\n",
    "    \"model_description\": res2['output'],\n",
    "    \"model_input_format\": ans.model_input_format,\n",
    "    \"model_output_format\": ans.model_output_format,\n",
    "    \"model_requirements\": ans.model_requirements,\n",
    "    \"model_sample_code\": ans.model_sample_code,\n",
    "    \"output_classes\": ans.output_classes,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a56d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = coding_agent(prev_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

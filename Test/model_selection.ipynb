{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42744f82",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "91bed7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "22abc01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STT</th>\n",
       "      <th>Task</th>\n",
       "      <th>Validation data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Bối cảnh của vấn đề:\\nNhận dạng chữ viết tay ...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nTrong thời đại thông tin...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nĐây là một nhiệm vụ hồi ...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nĐiều quan trọng là các c...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bối cảnh của vấn đề:\\nTrong nhiều ứng dụng thự...</td>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STT                                               Task Validation data\n",
       "0    1  \"Bối cảnh của vấn đề:\\nNhận dạng chữ viết tay ...            Link\n",
       "1    2  Bối cảnh của vấn đề:\\nTrong thời đại thông tin...            Link\n",
       "2    3  Bối cảnh của vấn đề:\\nĐây là một nhiệm vụ hồi ...            Link\n",
       "3    4  Bối cảnh của vấn đề:\\nĐiều quan trọng là các c...            Link\n",
       "4    5  Bối cảnh của vấn đề:\\nTrong nhiều ứng dụng thự...            Link"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "953cae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Bối cảnh của vấn đề:\\nNhận dạng chữ viết tay là một bài toán cơ bản trong lĩnh vực học máy và xử lý ảnh, với nhiều ứng dụng thực tiễn như nhận dạng chữ số trên phiếu khảo sát, hóa đơn hay bài thi tự động. Việc phân loại chữ số viết tay thành số nguyên tố hoặc không giúp mở rộng khả năng ứng dụng trong các bài toán toán học tự động, kiểm tra bài tập, hoặc các ứng dụng giáo dục.\\n\\nYêu cầu cụ thể cần đạt được:\\nXây dựng một hệ thống có khả năng nhận diện chữ số viết tay từ ảnh và xác định xem số đó có phải là số nguyên tố hay không.\\nĐầu vào là ảnh chứa một chữ số viết tay.\\nĐầu ra là nhãn phân loại nhị phân: \"\"nguyên tố\"\" hoặc \"\"không nguyên tố\"\".\\n\\nĐịnh dạng dữ liệu đầu vào cho bài toán tổng thể:\\nMột thư mục có tên là \"\"images\"\" chứa các ảnh grayscale 28x28 pixel, mỗi ảnh chứa một chữ số viết tay từ 0 đến 9.\\n\\nĐịnh dạng kết quả đầu ra mong muốn cho bài toán tổng thể:\\nFile output.csv mỗi hàng là kết quả dự đoán mỗi ảnh\\ncó các cột:\\nfile_name: tên file ảnh\\nprediction: nhãn của ảnh:\\n\"\"số nguyên tố\"\" nếu số trong ảnh là số nguyên tố.\\n\"\"không nguyên tố\"\" nếu số trong ảnh không phải số nguyên tố.\"'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "af3bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    scrape_status = scraper.scrape_url(\n",
    "        url,\n",
    "        formats=['markdown']\n",
    "    )\n",
    "    return scrape_status.markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "77f3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperParameters(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b6a0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "52a9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409f8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "eca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6511a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0de6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ef593964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "14b15c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "78675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = classify_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bdd41986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_agent(state: AgentState) -> AgentState:\n",
    "    system_prompt = f\"\"\"\n",
    "                    You are a machine learning expert assigned to select the **best-fit model** for a given task.\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## 🎯 Your Goal\n",
    "\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and links)\n",
    "                    - A tool that fetches model details from a provided URL (description, input/output format, usage code)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Analyze the task and identify what type of problem it is (e.g., classification, regression, NLP, etc.)\n",
    "                    2. Select a small number of candidate models whose **name or purpose suggests relevance**\n",
    "                    3. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - ✅ Model description\n",
    "                        - 📥 Input format\n",
    "                        - 📤 Output format\n",
    "                        - 🧪 Code sample (usage code snippet)\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## ⚠️ VERY IMPORTANT RULES\n",
    "\n",
    "                    - ❌ DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - ❌ DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - ✅ ONLY use the **actual output** returned from the tool\n",
    "                    - ✅ Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## 📦 Available Models:\n",
    "\n",
    "                    {format_model_list(df_model)}\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## 🧠 Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **✅ Model name and link**  \n",
    "                    `<model name>` — `<link>`\n",
    "\n",
    "                    **📝 Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **📥 Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **📤 Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **🧪 Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "                    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    result = executor.invoke({\"input\": task_input})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d8f92e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34131/7332665.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
      "/tmp/ipykernel_34131/7332665.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = str(row[2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "\n",
      "## 📝 Mô tả\n",
      "\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "## 📌 Chi tiết các mô hình\n",
      "\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "\n",
      "## 📥 Đầu vào\n",
      "\n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là 224x224)\n",
      "- **Giá trị pixel**: \\[0, 255\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "## 📤 Đầu ra\n",
      "\n",
      "- Một số nguyên từ **0 đến 9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "## 🛠 Yêu cầu thư viện\n",
      "\n",
      "Cài đặt các thư viện sau bằng `pip`:\n",
      "\n",
      "```bash\n",
      "pip install transformers torch\n",
      "\n",
      "```\n",
      "\n",
      "## 🧪 Sử dụng mô hình\n",
      "\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month324\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [🙋Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=thanhtlx/image_classification_01&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bthanhtlx%2Fimage_classification_01%5D(%2Fthanhtlx%2Fimage_classification_01)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "responded: To solve this task, we need to analyze the problem description and select a suitable model from the provided list. The task involves handwritten digit recognition and determining whether the digit is a prime number or not.\n",
      "\n",
      "## Step 1: Analyze the task description\n",
      "The task requires building a system that can recognize handwritten digits from images and classify them as prime or non-prime numbers. The input is an image containing a handwritten digit, and the output is a binary classification label: \"nguyên tố\" (prime) or \"không nguyên tố\" (non-prime).\n",
      "\n",
      "## Step 2: Identify relevant models\n",
      "From the list of available models, we can see that model 1 is specifically designed for handwritten digit recognition: \"Nhận diện ảnh chữ viết tay\" (Handwritten digit recognition). This model seems to be the most relevant for our task.\n",
      "\n",
      "## Step 3: Retrieve model details using the web_scrapper tool\n",
      "We will use the web_scrapper tool to retrieve more details about model 1.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "\n",
      "## 📝 Mô tả\n",
      "\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "## 📌 Chi tiết các mô hình\n",
      "\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "\n",
      "## 📥 Đầu vào\n",
      "\n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là 224x224)\n",
      "- **Giá trị pixel**: \\[0, 255\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "## 📤 Đầu ra\n",
      "\n",
      "- Một số nguyên từ **0 đến 9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "## 🛠 Yêu cầu thư viện\n",
      "\n",
      "Cài đặt các thư viện sau bằng `pip`:\n",
      "\n",
      "```bash\n",
      "pip install transformers torch\n",
      "\n",
      "```\n",
      "\n",
      "## 🧪 Sử dụng mô hình\n",
      "\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month324\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [🙋Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=thanhtlx/image_classification_01&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bthanhtlx%2Fimage_classification_01%5D(%2Fthanhtlx%2Fimage_classification_01)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "responded: ## Step 1: Analyze the task description\n",
      "The task requires building a system that can recognize handwritten digits from images and classify them as prime or non-prime numbers. The input is an image containing a handwritten digit, and the output is a binary classification label: \"nguyên tố\" (prime) or \"không nguyên tố\" (non-prime).\n",
      "\n",
      "## Step 2: Identify relevant models\n",
      "From the list of available models, we can see that model 1 is specifically designed for handwritten digit recognition: \"Nhận diện ảnh chữ viết tay\" (Handwritten digit recognition). This model seems to be the most relevant for our task.\n",
      "\n",
      "## Step 3: Retrieve model details using the web_scrapper tool\n",
      "We will use the web_scrapper tool to retrieve more details about model 1.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "\n",
      "## 📝 Mô tả\n",
      "\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "## 📌 Chi tiết các mô hình\n",
      "\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "\n",
      "## 📥 Đầu vào\n",
      "\n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là 224x224)\n",
      "- **Giá trị pixel**: \\[0, 255\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "## 📤 Đầu ra\n",
      "\n",
      "- Một số nguyên từ **0 đến 9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "## 🛠 Yêu cầu thư viện\n",
      "\n",
      "Cài đặt các thư viện sau bằng `pip`:\n",
      "\n",
      "```bash\n",
      "pip install transformers torch\n",
      "\n",
      "```\n",
      "\n",
      "## 🧪 Sử dụng mô hình\n",
      "\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month324\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [🙋Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=thanhtlx/image_classification_01&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bthanhtlx%2Fimage_classification_01%5D(%2Fthanhtlx%2Fimage_classification_01)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "responded: ## Step 1: Analyze the task description\n",
      "The task requires building a system that can recognize handwritten digits from images and classify them as prime or non-prime numbers. The input is an image containing a handwritten digit, and the output is a binary classification label: \"nguyên tố\" (prime) or \"không nguyên tố\" (non-prime).\n",
      "\n",
      "## Step 2: Identify relevant models\n",
      "From the list of available models, we can see that model1 is specifically designed for handwritten digit recognition: \"Nhận diện ảnh chữ viết tay\" (Handwritten digit recognition). This model seems to be the most relevant for our task.\n",
      "\n",
      "## Step 3: Retrieve model details using the web_scrapper tool\n",
      "We will use the web_scrapper tool to retrieve more details about model1.\n",
      "\n",
      "## Step 4: Evaluate model details\n",
      "Based on the model details retrieved, we will evaluate if the model fits the task requirements.\n",
      "\n",
      "## Step 5: Select the best-fit model\n",
      "After evaluating the model details, we will select the best-fit model for the task.\n",
      "\n",
      "## Step 6: Provide the final answer\n",
      "We will provide the final answer in the required format.\n",
      "\n",
      "## Step 7: Implementation\n",
      "Let's implement the solution.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "\n",
      "## 📝 Mô tả\n",
      "\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "## 📌 Chi tiết các mô hình\n",
      "\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "\n",
      "## 📥 Đầu vào\n",
      "\n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là 224x224)\n",
      "- **Giá trị pixel**: \\[0, 255\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "## 📤 Đầu ra\n",
      "\n",
      "- Một số nguyên từ **0 đến 9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "## 🛠 Yêu cầu thư viện\n",
      "\n",
      "Cài đặt các thư viện sau bằng `pip`:\n",
      "\n",
      "```bash\n",
      "pip install transformers torch\n",
      "\n",
      "```\n",
      "\n",
      "## 🧪 Sử dụng mô hình\n",
      "\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month324\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [🙋Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=thanhtlx/image_classification_01&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bthanhtlx%2Fimage_classification_01%5D(%2Fthanhtlx%2Fimage_classification_01)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/thanhtlx/image_classification_01'}`\n",
      "responded: ## Step 1: Analyze the task description\n",
      "The task requires building a system that can recognize handwritten digits from images and classify them as prime or non-prime numbers. The input is an image containing a handwritten digit, and the output is a binary classification label: \"nguyên tố\" (prime) or \"không nguyên tố\" (non-prime).\n",
      "\n",
      "## Step 2: Identify relevant models\n",
      "From the list of available models, we can see that model1 is specifically designed for handwritten digit recognition: \"Nhận diện ảnh chữ viết tay\" (Handwritten digit recognition). This model seems to be the most relevant for our task.\n",
      "\n",
      "## Step 3: Retrieve model details using the web_scrapper tool\n",
      "We will use the web_scrapper tool to retrieve more details about model1.\n",
      "\n",
      "## Step 4: Evaluate model details\n",
      "Based on the model details retrieved, we will evaluate if the model fits the task requirements.\n",
      "\n",
      "## Step 5: Select the best-fit model\n",
      "After evaluating the model details, we will select the best-fit model for the task.\n",
      "\n",
      "## Step 6: Provide the final answer\n",
      "We will provide the final answer in the required format.\n",
      "\n",
      "## Step 7: Implementation\n",
      "Let's implement the solution.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
      "\n",
      "## 📝 Mô tả\n",
      "\n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ 0 đến 9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "## 📌 Chi tiết các mô hình\n",
      "\n",
      "Phân loại ảnh chữ số viết tay từ 0 đến 9\n",
      "\n",
      "## 📥 Đầu vào\n",
      "\n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là 224x224)\n",
      "- **Giá trị pixel**: \\[0, 255\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "## 📤 Đầu ra\n",
      "\n",
      "- Một số nguyên từ **0 đến 9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "## 🛠 Yêu cầu thư viện\n",
      "\n",
      "Cài đặt các thư viện sau bằng `pip`:\n",
      "\n",
      "```bash\n",
      "pip install transformers torch\n",
      "\n",
      "```\n",
      "\n",
      "## 🧪 Sử dụng mô hình\n",
      "\n",
      "Dưới đây là đoạn mã mẫu để sử dụng mô hình:\n",
      "\n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      "    outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month324\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [🙋Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=thanhtlx/image_classification_01&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bthanhtlx%2Fimage_classification_01%5D(%2Fthanhtlx%2Fimage_classification_01)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m## Step 1: Analyze the task description\n",
      "The task requires building a system that can recognize handwritten digits from images and classify them as prime or non-prime numbers. The input is an image containing a handwritten digit, and the output is a binary classification label: \"nguyên tố\" (prime) or \"không nguyên tố\" (non-prime).\n",
      "\n",
      "## Step 2: Identify relevant models\n",
      "From the list of available models, we can see that model 1 is specifically designed for handwritten digit recognition: \"Nhận diện ảnh chữ viết tay\" (Handwritten digit recognition). This model seems to be the most relevant for our task.\n",
      "\n",
      "## Step 3: Retrieve model details using the web_scrapper tool\n",
      "We have retrieved the details of model 1 using the web_scrapper tool.\n",
      "\n",
      "## Step 4: Evaluate model details\n",
      "Based on the model details retrieved, we can see that the model can recognize handwritten digits from 0 to 9. However, the model does not directly classify the digits as prime or non-prime.\n",
      "\n",
      "## Step 5: Select the best-fit model\n",
      "Although the model does not directly classify digits as prime or non-prime, it can still be used as a starting point. We can use the model's output (the recognized digit) and then apply a prime-checking function to classify it as prime or non-prime.\n",
      "\n",
      "## Step 6: Provide the final answer\n",
      "We will provide the final answer in the required format.\n",
      "\n",
      "## Step 7: Implementation\n",
      "Let's implement the solution.\n",
      "\n",
      "The best-fit model for the task is:\n",
      "\n",
      "**✅ Model name and link**  \n",
      "`image_classification_01` — `https://huggingface.co/thanhtlx/image_classification_01`\n",
      "\n",
      "**📝 Description (from tool):**  \n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ0 đến9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "**📥 Input format (from tool):**  \n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là224x224)\n",
      "- **Giá trị pixel**: \\\\[0,255\\\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "**📤 Output format (from tool):**  \n",
      "- Một số nguyên từ **0 đến9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "**🧪 Example code (from tool):**  \n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = modeling_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3da68bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': '## Step 1: Analyze the task description\\n'\n",
      "           'The task requires building a system that can recognize handwritten '\n",
      "           'digits from images and classify them as prime or non-prime '\n",
      "           'numbers. The input is an image containing a handwritten digit, and '\n",
      "           'the output is a binary classification label: \"nguyên tố\" (prime) '\n",
      "           'or \"không nguyên tố\" (non-prime).\\n'\n",
      "           '\\n'\n",
      "           '## Step 2: Identify relevant models\\n'\n",
      "           'From the list of available models, we can see that model 1 is '\n",
      "           'specifically designed for handwritten digit recognition: \"Nhận '\n",
      "           'diện ảnh chữ viết tay\" (Handwritten digit recognition). This model '\n",
      "           'seems to be the most relevant for our task.\\n'\n",
      "           '\\n'\n",
      "           '## Step 3: Retrieve model details using the web_scrapper tool\\n'\n",
      "           'We have retrieved the details of model 1 using the web_scrapper '\n",
      "           'tool.\\n'\n",
      "           '\\n'\n",
      "           '## Step 4: Evaluate model details\\n'\n",
      "           'Based on the model details retrieved, we can see that the model '\n",
      "           'can recognize handwritten digits from 0 to 9. However, the model '\n",
      "           'does not directly classify the digits as prime or non-prime.\\n'\n",
      "           '\\n'\n",
      "           '## Step 5: Select the best-fit model\\n'\n",
      "           'Although the model does not directly classify digits as prime or '\n",
      "           'non-prime, it can still be used as a starting point. We can use '\n",
      "           \"the model's output (the recognized digit) and then apply a \"\n",
      "           'prime-checking function to classify it as prime or non-prime.\\n'\n",
      "           '\\n'\n",
      "           '## Step 6: Provide the final answer\\n'\n",
      "           'We will provide the final answer in the required format.\\n'\n",
      "           '\\n'\n",
      "           '## Step 7: Implementation\\n'\n",
      "           \"Let's implement the solution.\\n\"\n",
      "           '\\n'\n",
      "           'The best-fit model for the task is:\\n'\n",
      "           '\\n'\n",
      "           '**✅ Model name and link**  \\n'\n",
      "           '`image_classification_01` — '\n",
      "           '`https://huggingface.co/thanhtlx/image_classification_01`\\n'\n",
      "           '\\n'\n",
      "           '**📝 Description (from tool):**  \\n'\n",
      "           'Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các '\n",
      "           'chữ số viết tay (từ0 đến9) trong ảnh màu. Mô hình sử dụng kiến '\n",
      "           'trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu '\n",
      "           'gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\\n'\n",
      "           '\\n'\n",
      "           '**📥 Input format (from tool):**  \\n'\n",
      "           '- **Định dạng**: Ảnh màu (RGB)\\n'\n",
      "           '- **Kiểu dữ liệu**: `PIL.Image.Image`\\n'\n",
      "           '- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của '\n",
      "           '`ViTImageProcessor` (thường là224x224)\\n'\n",
      "           '- **Giá trị pixel**: \\\\\\\\[0,255\\\\\\\\] (chuẩn hóa tự động bởi '\n",
      "           'processor)\\n'\n",
      "           '\\n'\n",
      "           '**📤 Output format (from tool):**  \\n'\n",
      "           '- Một số nguyên từ **0 đến9**, là kết quả phân loại tương ứng với '\n",
      "           'chữ số xuất hiện trong ảnh.\\n'\n",
      "           '\\n'\n",
      "           '**🧪 Example code (from tool):**  \\n'\n",
      "           '```python\\n'\n",
      "           'from transformers import ViTForImageClassification, '\n",
      "           'ViTImageProcessor\\n'\n",
      "           'from PIL import Image\\n'\n",
      "           'import torch\\n'\n",
      "           '\\n'\n",
      "           'model_name = \"thanhtlx/image_classification_01\"\\n'\n",
      "           'model = ViTForImageClassification.from_pretrained(model_name)\\n'\n",
      "           'processor = ViTImageProcessor.from_pretrained(model_name)\\n'\n",
      "           '\\n'\n",
      "           '# Đọc ảnh cần phân loại\\n'\n",
      "           'image = Image.open(\"images.png\")\\n'\n",
      "           '\\n'\n",
      "           '# Xử lý ảnh đầu vào\\n'\n",
      "           'inputs = processor(images=image, return_tensors=\"pt\")\\n'\n",
      "           '\\n'\n",
      "           '# Dự đoán với mô hình\\n'\n",
      "           'with torch.no_grad():\\n'\n",
      "           ' outputs = model(**inputs)\\n'\n",
      "           '\\n'\n",
      "           '# Lấy kết quả dự đoán\\n'\n",
      "           'predicted_class = outputs.logits.argmax(-1).item()\\n'\n",
      "           'print(f\"prediction: {predicted_class}\")\\n'\n",
      "           '```'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "41077f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Step 1: Analyze the task description\n",
      "The task requires building a system that can recognize handwritten digits from images and classify them as prime or non-prime numbers. The input is an image containing a handwritten digit, and the output is a binary classification label: \"nguyên tố\" (prime) or \"không nguyên tố\" (non-prime).\n",
      "\n",
      "## Step 2: Identify relevant models\n",
      "From the list of available models, we can see that model 1 is specifically designed for handwritten digit recognition: \"Nhận diện ảnh chữ viết tay\" (Handwritten digit recognition). This model seems to be the most relevant for our task.\n",
      "\n",
      "## Step 3: Retrieve model details using the web_scrapper tool\n",
      "We have retrieved the details of model 1 using the web_scrapper tool.\n",
      "\n",
      "## Step 4: Evaluate model details\n",
      "Based on the model details retrieved, we can see that the model can recognize handwritten digits from 0 to 9. However, the model does not directly classify the digits as prime or non-prime.\n",
      "\n",
      "## Step 5: Select the best-fit model\n",
      "Although the model does not directly classify digits as prime or non-prime, it can still be used as a starting point. We can use the model's output (the recognized digit) and then apply a prime-checking function to classify it as prime or non-prime.\n",
      "\n",
      "## Step 6: Provide the final answer\n",
      "We will provide the final answer in the required format.\n",
      "\n",
      "## Step 7: Implementation\n",
      "Let's implement the solution.\n",
      "\n",
      "The best-fit model for the task is:\n",
      "\n",
      "**✅ Model name and link**  \n",
      "`image_classification_01` — `https://huggingface.co/thanhtlx/image_classification_01`\n",
      "\n",
      "**📝 Description (from tool):**  \n",
      "Đây là một mô hình phân loại ảnh được huấn luyện để nhận diện các chữ số viết tay (từ0 đến9) trong ảnh màu. Mô hình sử dụng kiến trúc Vision Transformer (ViT) và được huấn luyện với tập dữ liệu gồm các chữ số viết tay được chụp hoặc scan dưới dạng ảnh màu.\n",
      "\n",
      "**📥 Input format (from tool):**  \n",
      "- **Định dạng**: Ảnh màu (RGB)\n",
      "- **Kiểu dữ liệu**: `PIL.Image.Image`\n",
      "- **Kích thước ảnh**: Mô hình sẽ tự resize theo cấu hình của `ViTImageProcessor` (thường là224x224)\n",
      "- **Giá trị pixel**: \\\\[0,255\\\\] (chuẩn hóa tự động bởi processor)\n",
      "\n",
      "**📤 Output format (from tool):**  \n",
      "- Một số nguyên từ **0 đến9**, là kết quả phân loại tương ứng với chữ số xuất hiện trong ảnh.\n",
      "\n",
      "**🧪 Example code (from tool):**  \n",
      "```python\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "from PIL import Image\n",
      "import torch\n",
      "\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "\n",
      "# Đọc ảnh cần phân loại\n",
      "image = Image.open(\"images.png\")\n",
      "\n",
      "# Xử lý ảnh đầu vào\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "\n",
      "# Dự đoán với mô hình\n",
      "with torch.no_grad():\n",
      " outputs = model(**inputs)\n",
      "\n",
      "# Lấy kết quả dự đoán\n",
      "predicted_class = outputs.logits.argmax(-1).item()\n",
      "print(f\"prediction: {predicted_class}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(res[\"output\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42744f82",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bed7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    scrape_status = scraper.scrape_url(\n",
    "        url,\n",
    "        formats=['markdown']\n",
    "    )\n",
    "    return scrape_status.markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperParameters(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409f8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6511a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef593964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14b15c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = classify_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd41986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_agent(state: AgentState) -> AgentState:\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert in machine learning. Given a task, choose the best model\n",
    "    from this list:\n",
    "\n",
    "    {format_model_list(df_model)}\n",
    "\n",
    "    Then, use tools to get more information about the selected model\n",
    "    (description, input format, output format, sample code, ...).\n",
    "    When done, summarize everything in your final answer.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    result = executor.invoke({\"input\": task_input})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f92e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69115/7332665.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
      "/tmp/ipykernel_69115/7332665.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = str(row[2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_3'}`\n",
      "responded: To solve this problem, we need to select a suitable model from the given list and then gather more information about the selected model.\n",
      "\n",
      "The task involves regression to predict the median house value of areas in California based on features like median income, average house age, average number of rooms, etc. The goal is to categorize the house prices into three groups: \"low\", \"medium\", and \"high\".\n",
      "\n",
      "Given the nature of the task, which involves regression and classification based on multiple features, we should look for models that can handle regression tasks and potentially be adapted for classification or have a straightforward way to output categorical values.\n",
      "\n",
      "Let's consider the models:\n",
      "\n",
      "1. Nh·∫≠n di·ªán ·∫£nh ch·ªØ vi·∫øt tay - Not suitable for this task.\n",
      "2. Ph√¢n lo·∫°i vƒÉn b·∫£n th√†nh c√°c topic - Not suitable for this task.\n",
      "3. D·ª± ƒëo√°n gi√° trung b√¨nh nh√† ·ªü c√°c qu·∫≠n Cali - This seems directly relevant.\n",
      "4. D·ª± ƒëo√°n gi√° trung b√¨nh nh√† ·ªü c√°c qu·∫≠n Cali - Another potential model for house price prediction.\n",
      "5. Ph√¢n lo·∫°i gian l·∫≠n th·∫ª t√≠n d·ª•ng - Not directly relevant.\n",
      "6. Ph√¢n lo·∫°i h√¨nh ·∫£nh - Not suitable for this task.\n",
      "7. Ph√¢n lo·∫°i h√¨nh ·∫£nh th√†nh100 l·ªõp ƒë·ªëi t∆∞·ª£ng chi ti·∫øt (fine-grained) - Not suitable for this task.\n",
      "\n",
      "Models 3 and 4 seem directly relevant as they are about predicting the median house value in California districts.\n",
      "\n",
      "Let's gather more information about Model 3:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# üè† M√¥ h√¨nh D·ª± ƒëo√°n Gi√° Nh√† California (MLP)\n",
      "\n",
      "## üìù M√¥ t·∫£\n",
      "\n",
      "ƒê√¢y l√† m·ªôt m√¥ h√¨nh multi-layer perceptron (MLP) ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p d·ªØ li·ªáu California Housing ƒë·ªÉ d·ª± ƒëo√°n gi√° nh√† trung b√¨nh (MedHouseVal). M√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng PyTorch, l√† b·∫£n chuy·ªÉn th·ªÉ t·ª´ m√¥ h√¨nh TensorFlow trong Ch∆∞∆°ng 10 c·ªßa cu·ªën Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow c·ªßa Aurelien Geron.\n",
      "\n",
      "## üìå Nhi·ªám v·ª•\n",
      "\n",
      "D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o d·∫°ng b·∫£ng (tabular regression).\n",
      "\n",
      "## üì• ƒê·∫ßu v√†o\n",
      "\n",
      "S·ªë chi·ªÅu: \\[batch\\_size, 8\\]\n",
      "\n",
      "Ki·ªÉu d·ªØ li·ªáu: torch.FloatTensor\n",
      "\n",
      "C√°c ƒë·∫∑c tr∆∞ng:\n",
      "\n",
      "- 'MedInc' ‚Äì Thu nh·∫≠p trung v·ªã\n",
      "- 'HouseAge' ‚Äì Tu·ªïi trung b√¨nh c·ªßa cƒÉn nh√†\n",
      "- 'AveRooms' ‚Äì S·ªë ph√≤ng trung b√¨nh\n",
      "- 'AveBedrms' ‚Äì S·ªë ph√≤ng ng·ªß trung b√¨nh\n",
      "- 'Population' ‚Äì D√¢n s·ªë\n",
      "- 'AveOccup' ‚Äì S·ªë ng∆∞·ªùi trung b√¨nh tr√™n m·ªói h·ªô\n",
      "- 'Latitude' ‚Äì Vƒ© ƒë·ªô\n",
      "- 'Longitude' ‚Äì Kinh ƒë·ªô\n",
      "\n",
      "## üì§ ƒê·∫ßu ra\n",
      "\n",
      "Ki·ªÉu: torch.FloatTensor c√≥ shape \\[batch\\_size, 1\\]\n",
      "√ù nghƒ©a: M·ªôt gi√° tr·ªã th·ª±c duy nh·∫•t d·ª± ƒëo√°n gi√° nh√† trung b√¨nh cho m·ªói m·∫´u.\n",
      "\n",
      "üõ† Y√™u c·∫ßu th∆∞ vi·ªán\n",
      "\n",
      "C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt b·∫±ng:\n",
      "\n",
      "```bash\n",
      "pip install torch scikit-learn huggingface_hub\n",
      "\n",
      "```\n",
      "\n",
      "## üß™ S·ª≠ d·ª•ng m√¥ h√¨nh\n",
      "\n",
      "D∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• v·ªÅ c√°ch s·ª≠ d·ª•ng m√¥ h√¨nh:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from huggingface_hub import PyTorchModelHubMixin\n",
      "\n",
      "# T·∫°o ƒë·∫ßu v√†o m·∫´u ng·∫´u nhi√™n (chu·∫©n h√≥a gi·∫£ ƒë·ªãnh ~ N(0,1))\n",
      "x_input = torch.randn(1, 8)  # 1 m·∫´u, 8 ƒë·∫∑c tr∆∞ng\n",
      "print(\"Mock input:\")\n",
      "print(x_input)\n",
      "\n",
      "# ƒê·ªãnh nghƒ©a l·∫°i m√¥ h√¨nh\n",
      "class MLP(nn.Module, PyTorchModelHubMixin):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(8, 50)\n",
      "        self.fc2 = nn.Linear(50, 50)\n",
      "        self.fc3 = nn.Linear(50, 50)\n",
      "        self.fc4 = nn.Linear(50, 1)\n",
      "\n",
      "    def forward(self, x):\n",
      "        act = torch.relu(self.fc1(x))\n",
      "        act = torch.relu(self.fc2(act))\n",
      "        act = torch.relu(self.fc3(act))\n",
      "        return self.fc4(act)\n",
      "\n",
      "# T·∫£i m√¥ h√¨nh t·ª´ Hugging Face Hub\n",
      "model = MLP.from_pretrained(\"zhaospei/Model_3\")\n",
      "model.eval()\n",
      "\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      "    prediction = model(x_input)\n",
      "\n",
      "print(f\"Gi√° nh√† d·ª± ƒëo√°n (mock input): {prediction.item():.3f}\")\n",
      "\n",
      "```\n",
      "\n",
      "## üîó Tham kh·∫£o\n",
      "\n",
      "PyTorchModelHubMixin Documentation\n",
      "\n",
      "Downloads last month\n",
      "\n",
      "-\n",
      "\n",
      "Downloads are not tracked for this model.\n",
      "[How to track](https://huggingface.co/docs/hub/models-download-stats)\n",
      "\n",
      "Safetensors\n",
      "\n",
      "Model size\n",
      "\n",
      "5.6k params\n",
      "\n",
      "Tensor type\n",
      "\n",
      "F32\n",
      "\n",
      "¬∑\n",
      "\n",
      "Files info\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [üôãAsk for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=zhaospei/Model_3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bzhaospei%2FModel_3%5D(%2Fzhaospei%2FModel_3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# üè† M√¥ h√¨nh D·ª± ƒëo√°n Gi√° Nh√† California (MLP)\n",
      "\n",
      "## üìù M√¥ t·∫£\n",
      "\n",
      "ƒê√¢y l√† m·ªôt m√¥ h√¨nh multi-layer perceptron (MLP) ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p d·ªØ li·ªáu California Housing ƒë·ªÉ d·ª± ƒëo√°n gi√° nh√† trung b√¨nh (MedHouseVal). M√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng PyTorch, l√† b·∫£n chuy·ªÉn th·ªÉ t·ª´ m√¥ h√¨nh TensorFlow trong Ch∆∞∆°ng 10 c·ªßa cu·ªën Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow c·ªßa Aurelien Geron.\n",
      "\n",
      "## üìå Nhi·ªám v·ª•\n",
      "\n",
      "D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o d·∫°ng b·∫£ng (tabular regression).\n",
      "\n",
      "## üì• ƒê·∫ßu v√†o\n",
      "\n",
      "S·ªë chi·ªÅu: \\[batch\\_size, 8\\]\n",
      "\n",
      "Ki·ªÉu d·ªØ li·ªáu: torch.FloatTensor\n",
      "\n",
      "C√°c ƒë·∫∑c tr∆∞ng:\n",
      "\n",
      "- 'MedInc' ‚Äì Thu nh·∫≠p trung v·ªã\n",
      "- 'HouseAge' ‚Äì Tu·ªïi trung b√¨nh c·ªßa cƒÉn nh√†\n",
      "- 'AveRooms' ‚Äì S·ªë ph√≤ng trung b√¨nh\n",
      "- 'AveBedrms' ‚Äì S·ªë ph√≤ng ng·ªß trung b√¨nh\n",
      "- 'Population' ‚Äì D√¢n s·ªë\n",
      "- 'AveOccup' ‚Äì S·ªë ng∆∞·ªùi trung b√¨nh tr√™n m·ªói h·ªô\n",
      "- 'Latitude' ‚Äì Vƒ© ƒë·ªô\n",
      "- 'Longitude' ‚Äì Kinh ƒë·ªô\n",
      "\n",
      "## üì§ ƒê·∫ßu ra\n",
      "\n",
      "Ki·ªÉu: torch.FloatTensor c√≥ shape \\[batch\\_size, 1\\]\n",
      "√ù nghƒ©a: M·ªôt gi√° tr·ªã th·ª±c duy nh·∫•t d·ª± ƒëo√°n gi√° nh√† trung b√¨nh cho m·ªói m·∫´u.\n",
      "\n",
      "üõ† Y√™u c·∫ßu th∆∞ vi·ªán\n",
      "\n",
      "C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt b·∫±ng:\n",
      "\n",
      "```bash\n",
      "pip install torch scikit-learn huggingface_hub\n",
      "\n",
      "```\n",
      "\n",
      "## üß™ S·ª≠ d·ª•ng m√¥ h√¨nh\n",
      "\n",
      "D∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• v·ªÅ c√°ch s·ª≠ d·ª•ng m√¥ h√¨nh:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from huggingface_hub import PyTorchModelHubMixin\n",
      "\n",
      "# T·∫°o ƒë·∫ßu v√†o m·∫´u ng·∫´u nhi√™n (chu·∫©n h√≥a gi·∫£ ƒë·ªãnh ~ N(0,1))\n",
      "x_input = torch.randn(1, 8)  # 1 m·∫´u, 8 ƒë·∫∑c tr∆∞ng\n",
      "print(\"Mock input:\")\n",
      "print(x_input)\n",
      "\n",
      "# ƒê·ªãnh nghƒ©a l·∫°i m√¥ h√¨nh\n",
      "class MLP(nn.Module, PyTorchModelHubMixin):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(8, 50)\n",
      "        self.fc2 = nn.Linear(50, 50)\n",
      "        self.fc3 = nn.Linear(50, 50)\n",
      "        self.fc4 = nn.Linear(50, 1)\n",
      "\n",
      "    def forward(self, x):\n",
      "        act = torch.relu(self.fc1(x))\n",
      "        act = torch.relu(self.fc2(act))\n",
      "        act = torch.relu(self.fc3(act))\n",
      "        return self.fc4(act)\n",
      "\n",
      "# T·∫£i m√¥ h√¨nh t·ª´ Hugging Face Hub\n",
      "model = MLP.from_pretrained(\"zhaospei/Model_3\")\n",
      "model.eval()\n",
      "\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      "    prediction = model(x_input)\n",
      "\n",
      "print(f\"Gi√° nh√† d·ª± ƒëo√°n (mock input): {prediction.item():.3f}\")\n",
      "\n",
      "```\n",
      "\n",
      "## üîó Tham kh·∫£o\n",
      "\n",
      "PyTorchModelHubMixin Documentation\n",
      "\n",
      "Downloads last month\n",
      "\n",
      "-\n",
      "\n",
      "Downloads are not tracked for this model.\n",
      "[How to track](https://huggingface.co/docs/hub/models-download-stats)\n",
      "\n",
      "Safetensors\n",
      "\n",
      "Model size\n",
      "\n",
      "5.6k params\n",
      "\n",
      "Tensor type\n",
      "\n",
      "F32\n",
      "\n",
      "¬∑\n",
      "\n",
      "Files info\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [üôãAsk for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=zhaospei/Model_3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bzhaospei%2FModel_3%5D(%2Fzhaospei%2FModel_3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_2'}`\n",
      "responded: Based on the task description, I will select Model 3 or Model 4  since both are directly relevant to predicting the median house value in California districts.\n",
      "\n",
      "Let's gather more information about Model 4:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# üè† M√¥ h√¨nh Wide & Deep Neural Network - D·ª± ƒëo√°n Gi√° Nh√† California\n",
      "\n",
      "## üìù M√¥ t·∫£\n",
      "\n",
      "ƒê√¢y l√† m·ªôt m√¥ h√¨nh **Wide & Deep Neural Network** ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p d·ªØ li·ªáu **California Housing** ƒë·ªÉ d·ª± ƒëo√°n gi√° nh√† trung b√¨nh ( `MedHouseVal`). M√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng **PyTorch**, d·ª±a tr√™n ki·∫øn tr√∫c trong cu·ªën _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ c·ªßa **Aur√©lien G√©ron**.\n",
      "\n",
      "## üìå Nhi·ªám v·ª•\n",
      "\n",
      "D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n d·ªØ li·ªáu b·∫£ng (tabular regression) v·ªõi 8 ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o.\n",
      "\n",
      "## üì• ƒê·∫ßu v√†o\n",
      "\n",
      "- **S·ªë chi·ªÅu**: `[batch_size, 8]`\n",
      "- **Ki·ªÉu d·ªØ li·ªáu**: `torch.FloatTensor`\n",
      "- **C√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o**:\n",
      "  - `'MedInc'` ‚Äì Thu nh·∫≠p trung v·ªã\n",
      "  - `'HouseAge'` ‚Äì Tu·ªïi trung b√¨nh c·ªßa cƒÉn nh√†\n",
      "  - `'AveRooms'` ‚Äì S·ªë ph√≤ng trung b√¨nh\n",
      "  - `'AveBedrms'` ‚Äì S·ªë ph√≤ng ng·ªß trung b√¨nh\n",
      "  - `'Population'` ‚Äì D√¢n s·ªë\n",
      "  - `'AveOccup'` ‚Äì S·ªë ng∆∞·ªùi trung b√¨nh tr√™n m·ªói h·ªô\n",
      "  - `'Latitude'` ‚Äì Vƒ© ƒë·ªô\n",
      "  - `'Longitude'` ‚Äì Kinh ƒë·ªô\n",
      "\n",
      "## üì§ ƒê·∫ßu ra\n",
      "\n",
      "- **Ki·ªÉu**: `torch.FloatTensor` c√≥ shape `[batch_size, 1]`\n",
      "- **√ù nghƒ©a**: Gi√° nh√† trung b√¨nh d·ª± ƒëo√°n (gi√° tr·ªã th·ª±c).\n",
      "\n",
      "## üß™ C√°ch s·ª≠ d·ª•ng m√¥ h√¨nh\n",
      "\n",
      "D∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• v·ªÅ c√°ch s·ª≠ d·ª•ng m√¥ h√¨nh v·ªõi d·ªØ li·ªáu ƒë·∫ßu v√†o gi·∫£ l·∫≠p:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from huggingface_hub import PyTorchModelHubMixin\n",
      "\n",
      "# T·∫°o d·ªØ li·ªáu ƒë·∫ßu v√†o gi·∫£ l·∫≠p (batch 1, 8 features)\n",
      "x_input = torch.randn(1, 8)\n",
      "print(\"Mock input:\")\n",
      "print(x_input)\n",
      "\n",
      "# ƒê·ªãnh nghƒ©a m√¥ h√¨nh Wide & Deep Neural Network\n",
      "class WideAndDeepNet(nn.Module, PyTorchModelHubMixin):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.hidden1 = nn.Linear(6, 30)\n",
      "        self.hidden2 = nn.Linear(30, 30)\n",
      "        self.main_head = nn.Linear(35, 1)\n",
      "        self.aux_head = nn.Linear(30, 1)\n",
      "        self.main_loss_fn = nn.MSELoss(reduction='sum')\n",
      "        self.aux_loss_fn = nn.MSELoss(reduction='sum')\n",
      "\n",
      "    def forward(self, input_wide, input_deep, label=None):\n",
      "        act = torch.relu(self.hidden1(input_deep))\n",
      "        act = torch.relu(self.hidden2(act))\n",
      "        concat = torch.cat([input_wide, act], dim=1)\n",
      "        main_output = self.main_head(concat)\n",
      "        aux_output = self.aux_head(act)\n",
      "        if label is not None:\n",
      "            main_loss = self.main_loss_fn(main_output.squeeze(), label)\n",
      "            aux_loss = self.aux_loss_fn(aux_output.squeeze(), label)\n",
      "        return WideAndDeepNetOutput(main_output=main_output, aux_output=aux_output)\n",
      "\n",
      "# T·∫£i m√¥ h√¨nh t·ª´ Hugging Face Hub\n",
      "model = WideAndDeepNet.from_pretrained(\"sadhaklal/wide-and-deep-net-california-housing-v3\")\n",
      "model.eval()\n",
      "\n",
      "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
      "with torch.no_grad():\n",
      "    prediction = model(x_input)\n",
      "\n",
      "print(f\"Gi√° nh√† d·ª± ƒëo√°n (mock input): {prediction.item():.3f}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month\n",
      "\n",
      "-\n",
      "\n",
      "Downloads are not tracked for this model.\n",
      "[How to track](https://huggingface.co/docs/hub/models-download-stats)\n",
      "\n",
      "Safetensors\n",
      "\n",
      "Model size\n",
      "\n",
      "1.24k params\n",
      "\n",
      "Tensor type\n",
      "\n",
      "F32\n",
      "\n",
      "¬∑\n",
      "\n",
      "Files info\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [üôãAsk for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=zhaospei/Model_2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bzhaospei%2FModel_2%5D(%2Fzhaospei%2FModel_2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3mBased on the task description, I will select Model3 since it is directly relevant to predicting the median house value in California districts.\n",
      "\n",
      "Let's summarize the information about Model3:\n",
      "\n",
      "**Model3: D·ª± ƒëo√°n gi√° nh√† ·ªü c√°c qu·∫≠n Cali (MLP)**\n",
      "\n",
      "*   **Task**: D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o d·∫°ng b·∫£ng (tabular regression).\n",
      "*   **Input**:\n",
      "    *   S·ªë chi·ªÅu: `[batch_size, 8]`\n",
      "    *   Ki·ªÉu d·ªØ li·ªáu: `torch.FloatTensor`\n",
      "    *   C√°c ƒë·∫∑c tr∆∞ng:\n",
      "        *   `MedInc` ‚Äì Thu nh·∫≠p trung v·ªã\n",
      "        *   `HouseAge` ‚Äì Tu·ªïi trung b√¨nh c·ªßa cƒÉn nh√†\n",
      "        *   `AveRooms` ‚Äì S·ªë ph√≤ng trung b√¨nh\n",
      "        *   `AveBedrms` ‚Äì S·ªë ph√≤ng ng·ªß trung b√¨nh\n",
      "        *   `Population` ‚Äì D√¢n s·ªë\n",
      "        *   `AveOccup` ‚Äì S·ªë ng∆∞·ªùi trung b√¨nh tr√™n m·ªói h·ªô\n",
      "        *   `Latitude` ‚Äì Vƒ© ƒë·ªô\n",
      "        *   `Longitude` ‚Äì Kinh ƒë·ªô\n",
      "*   **Output**:\n",
      "    *   Ki·ªÉu: `torch.FloatTensor` c√≥ shape `[batch_size, 1]`\n",
      "    *   √ù nghƒ©a: M·ªôt gi√° tr·ªã th·ª±c duy nh·∫•t d·ª± ƒëo√°n gi√° nh√† trung b√¨nh cho m·ªói m·∫´u.\n",
      "\n",
      "To adapt Model3 for the specific requirements of the task, which involves classifying areas into \"low\", \"medium\", and \"high\" price groups, we can modify the model to output categorical labels instead of continuous values. We can achieve this by:\n",
      "\n",
      "1.  Modifying the model's output layer to produce logits for the three categories.\n",
      "2.  Applying a softmax activation function to obtain probabilities for each category.\n",
      "3.  Using a loss function suitable for classification, such as cross-entropy loss.\n",
      "\n",
      "Here is a Python code snippet demonstrating how to modify Model3 for classification:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from huggingface_hub import PyTorchModelHubMixin\n",
      "\n",
      "class MLP(nn.Module, PyTorchModelHubMixin):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(8, 50)\n",
      "        self.fc2 = nn.Linear(50, 50)\n",
      "        self.fc3 = nn.Linear(50, 50)\n",
      "        self.fc4 = nn.Linear(50, 3)  # Output layer with 3 logits\n",
      "\n",
      "    def forward(self, x):\n",
      "        act = torch.relu(self.fc1(x))\n",
      "        act = torch.relu(self.fc2(act))\n",
      "        act = torch.relu(self.fc3(act))\n",
      "        output = self.fc4(act)\n",
      "        return output\n",
      "\n",
      "# Load the pre-trained model\n",
      "model = MLP.from_pretrained(\"zhaospei/Model_3\")\n",
      "\n",
      "# Modify the model to output categorical labels\n",
      "def classify_price(output):\n",
      "    probabilities = torch.softmax(output, dim=1)\n",
      "    _, predicted = torch.max(probabilities, dim=1)\n",
      "    labels = {0: \"low\", 1: \"medium\", 2: \"high\"}\n",
      "    return [labels[predicted.item()] for predicted in predicted]\n",
      "\n",
      "# Example usage\n",
      "input_features = torch.randn(1, 8)  # Mock input features\n",
      "output = model(input_features)\n",
      "predicted_label = classify_price(output)\n",
      "print(predicted_label)\n",
      "\n",
      "```\n",
      "\n",
      "With this modification, the model can now classify areas into \"low\", \"medium\", and \"high\" price groups based on their input features.\n",
      "\n",
      "The output will be a list of labels, where each label corresponds to the predicted price group for the input features.\n",
      "\n",
      "**Summary**:\n",
      "\n",
      "*   **Model**: Model3 (MLP)\n",
      "*   **Task**: Classification of areas into \"low\", \"medium\", and \"high\" price groups\n",
      "*   **Input**: List of features (MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude)\n",
      "*   **Output**: List of labels (\"low\", \"medium\", or \"high\")\n",
      "\n",
      "This modified Model3 can be used to classify areas into different price groups based on their features, meeting the specific requirements of the task.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = modeling_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da68bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': 'Based on the task description, I will select Model3 since it is '\n",
      "           'directly relevant to predicting the median house value in '\n",
      "           'California districts.\\n'\n",
      "           '\\n'\n",
      "           \"Let's summarize the information about Model3:\\n\"\n",
      "           '\\n'\n",
      "           '**Model3: D·ª± ƒëo√°n gi√° nh√† ·ªü c√°c qu·∫≠n Cali (MLP)**\\n'\n",
      "           '\\n'\n",
      "           '*   **Task**: D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o d·∫°ng '\n",
      "           'b·∫£ng (tabular regression).\\n'\n",
      "           '*   **Input**:\\n'\n",
      "           '    *   S·ªë chi·ªÅu: `[batch_size, 8]`\\n'\n",
      "           '    *   Ki·ªÉu d·ªØ li·ªáu: `torch.FloatTensor`\\n'\n",
      "           '    *   C√°c ƒë·∫∑c tr∆∞ng:\\n'\n",
      "           '        *   `MedInc` ‚Äì Thu nh·∫≠p trung v·ªã\\n'\n",
      "           '        *   `HouseAge` ‚Äì Tu·ªïi trung b√¨nh c·ªßa cƒÉn nh√†\\n'\n",
      "           '        *   `AveRooms` ‚Äì S·ªë ph√≤ng trung b√¨nh\\n'\n",
      "           '        *   `AveBedrms` ‚Äì S·ªë ph√≤ng ng·ªß trung b√¨nh\\n'\n",
      "           '        *   `Population` ‚Äì D√¢n s·ªë\\n'\n",
      "           '        *   `AveOccup` ‚Äì S·ªë ng∆∞·ªùi trung b√¨nh tr√™n m·ªói h·ªô\\n'\n",
      "           '        *   `Latitude` ‚Äì Vƒ© ƒë·ªô\\n'\n",
      "           '        *   `Longitude` ‚Äì Kinh ƒë·ªô\\n'\n",
      "           '*   **Output**:\\n'\n",
      "           '    *   Ki·ªÉu: `torch.FloatTensor` c√≥ shape `[batch_size, 1]`\\n'\n",
      "           '    *   √ù nghƒ©a: M·ªôt gi√° tr·ªã th·ª±c duy nh·∫•t d·ª± ƒëo√°n gi√° nh√† trung '\n",
      "           'b√¨nh cho m·ªói m·∫´u.\\n'\n",
      "           '\\n'\n",
      "           'To adapt Model3 for the specific requirements of the task, which '\n",
      "           'involves classifying areas into \"low\", \"medium\", and \"high\" price '\n",
      "           'groups, we can modify the model to output categorical labels '\n",
      "           'instead of continuous values. We can achieve this by:\\n'\n",
      "           '\\n'\n",
      "           \"1.  Modifying the model's output layer to produce logits for the \"\n",
      "           'three categories.\\n'\n",
      "           '2.  Applying a softmax activation function to obtain probabilities '\n",
      "           'for each category.\\n'\n",
      "           '3.  Using a loss function suitable for classification, such as '\n",
      "           'cross-entropy loss.\\n'\n",
      "           '\\n'\n",
      "           'Here is a Python code snippet demonstrating how to modify Model3 '\n",
      "           'for classification:\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           'import torch\\n'\n",
      "           'import torch.nn as nn\\n'\n",
      "           'from huggingface_hub import PyTorchModelHubMixin\\n'\n",
      "           '\\n'\n",
      "           'class MLP(nn.Module, PyTorchModelHubMixin):\\n'\n",
      "           '    def __init__(self):\\n'\n",
      "           '        super().__init__()\\n'\n",
      "           '        self.fc1 = nn.Linear(8, 50)\\n'\n",
      "           '        self.fc2 = nn.Linear(50, 50)\\n'\n",
      "           '        self.fc3 = nn.Linear(50, 50)\\n'\n",
      "           '        self.fc4 = nn.Linear(50, 3)  # Output layer with 3 logits\\n'\n",
      "           '\\n'\n",
      "           '    def forward(self, x):\\n'\n",
      "           '        act = torch.relu(self.fc1(x))\\n'\n",
      "           '        act = torch.relu(self.fc2(act))\\n'\n",
      "           '        act = torch.relu(self.fc3(act))\\n'\n",
      "           '        output = self.fc4(act)\\n'\n",
      "           '        return output\\n'\n",
      "           '\\n'\n",
      "           '# Load the pre-trained model\\n'\n",
      "           'model = MLP.from_pretrained(\"zhaospei/Model_3\")\\n'\n",
      "           '\\n'\n",
      "           '# Modify the model to output categorical labels\\n'\n",
      "           'def classify_price(output):\\n'\n",
      "           '    probabilities = torch.softmax(output, dim=1)\\n'\n",
      "           '    _, predicted = torch.max(probabilities, dim=1)\\n'\n",
      "           '    labels = {0: \"low\", 1: \"medium\", 2: \"high\"}\\n'\n",
      "           '    return [labels[predicted.item()] for predicted in predicted]\\n'\n",
      "           '\\n'\n",
      "           '# Example usage\\n'\n",
      "           'input_features = torch.randn(1, 8)  # Mock input features\\n'\n",
      "           'output = model(input_features)\\n'\n",
      "           'predicted_label = classify_price(output)\\n'\n",
      "           'print(predicted_label)\\n'\n",
      "           '\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           'With this modification, the model can now classify areas into '\n",
      "           '\"low\", \"medium\", and \"high\" price groups based on their input '\n",
      "           'features.\\n'\n",
      "           '\\n'\n",
      "           'The output will be a list of labels, where each label corresponds '\n",
      "           'to the predicted price group for the input features.\\n'\n",
      "           '\\n'\n",
      "           '**Summary**:\\n'\n",
      "           '\\n'\n",
      "           '*   **Model**: Model3 (MLP)\\n'\n",
      "           '*   **Task**: Classification of areas into \"low\", \"medium\", and '\n",
      "           '\"high\" price groups\\n'\n",
      "           '*   **Input**: List of features (MedInc, HouseAge, AveRooms, '\n",
      "           'AveBedrms, Population, AveOccup, Latitude, Longitude)\\n'\n",
      "           '*   **Output**: List of labels (\"low\", \"medium\", or \"high\")\\n'\n",
      "           '\\n'\n",
      "           'This modified Model3 can be used to classify areas into different '\n",
      "           'price groups based on their features, meeting the specific '\n",
      "           'requirements of the task.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41077f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the task description, I will select Model3 since it is directly relevant to predicting the median house value in California districts.\n",
      "\n",
      "Let's summarize the information about Model3:\n",
      "\n",
      "**Model3: D·ª± ƒëo√°n gi√° nh√† ·ªü c√°c qu·∫≠n Cali (MLP)**\n",
      "\n",
      "*   **Task**: D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o d·∫°ng b·∫£ng (tabular regression).\n",
      "*   **Input**:\n",
      "    *   S·ªë chi·ªÅu: `[batch_size, 8]`\n",
      "    *   Ki·ªÉu d·ªØ li·ªáu: `torch.FloatTensor`\n",
      "    *   C√°c ƒë·∫∑c tr∆∞ng:\n",
      "        *   `MedInc` ‚Äì Thu nh·∫≠p trung v·ªã\n",
      "        *   `HouseAge` ‚Äì Tu·ªïi trung b√¨nh c·ªßa cƒÉn nh√†\n",
      "        *   `AveRooms` ‚Äì S·ªë ph√≤ng trung b√¨nh\n",
      "        *   `AveBedrms` ‚Äì S·ªë ph√≤ng ng·ªß trung b√¨nh\n",
      "        *   `Population` ‚Äì D√¢n s·ªë\n",
      "        *   `AveOccup` ‚Äì S·ªë ng∆∞·ªùi trung b√¨nh tr√™n m·ªói h·ªô\n",
      "        *   `Latitude` ‚Äì Vƒ© ƒë·ªô\n",
      "        *   `Longitude` ‚Äì Kinh ƒë·ªô\n",
      "*   **Output**:\n",
      "    *   Ki·ªÉu: `torch.FloatTensor` c√≥ shape `[batch_size, 1]`\n",
      "    *   √ù nghƒ©a: M·ªôt gi√° tr·ªã th·ª±c duy nh·∫•t d·ª± ƒëo√°n gi√° nh√† trung b√¨nh cho m·ªói m·∫´u.\n",
      "\n",
      "To adapt Model3 for the specific requirements of the task, which involves classifying areas into \"low\", \"medium\", and \"high\" price groups, we can modify the model to output categorical labels instead of continuous values. We can achieve this by:\n",
      "\n",
      "1.  Modifying the model's output layer to produce logits for the three categories.\n",
      "2.  Applying a softmax activation function to obtain probabilities for each category.\n",
      "3.  Using a loss function suitable for classification, such as cross-entropy loss.\n",
      "\n",
      "Here is a Python code snippet demonstrating how to modify Model3 for classification:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from huggingface_hub import PyTorchModelHubMixin\n",
      "\n",
      "class MLP(nn.Module, PyTorchModelHubMixin):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(8, 50)\n",
      "        self.fc2 = nn.Linear(50, 50)\n",
      "        self.fc3 = nn.Linear(50, 50)\n",
      "        self.fc4 = nn.Linear(50, 3)  # Output layer with 3 logits\n",
      "\n",
      "    def forward(self, x):\n",
      "        act = torch.relu(self.fc1(x))\n",
      "        act = torch.relu(self.fc2(act))\n",
      "        act = torch.relu(self.fc3(act))\n",
      "        output = self.fc4(act)\n",
      "        return output\n",
      "\n",
      "# Load the pre-trained model\n",
      "model = MLP.from_pretrained(\"zhaospei/Model_3\")\n",
      "\n",
      "# Modify the model to output categorical labels\n",
      "def classify_price(output):\n",
      "    probabilities = torch.softmax(output, dim=1)\n",
      "    _, predicted = torch.max(probabilities, dim=1)\n",
      "    labels = {0: \"low\", 1: \"medium\", 2: \"high\"}\n",
      "    return [labels[predicted.item()] for predicted in predicted]\n",
      "\n",
      "# Example usage\n",
      "input_features = torch.randn(1, 8)  # Mock input features\n",
      "output = model(input_features)\n",
      "predicted_label = classify_price(output)\n",
      "print(predicted_label)\n",
      "\n",
      "```\n",
      "\n",
      "With this modification, the model can now classify areas into \"low\", \"medium\", and \"high\" price groups based on their input features.\n",
      "\n",
      "The output will be a list of labels, where each label corresponds to the predicted price group for the input features.\n",
      "\n",
      "**Summary**:\n",
      "\n",
      "*   **Model**: Model3 (MLP)\n",
      "*   **Task**: Classification of areas into \"low\", \"medium\", and \"high\" price groups\n",
      "*   **Input**: List of features (MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude)\n",
      "*   **Output**: List of labels (\"low\", \"medium\", or \"high\")\n",
      "\n",
      "This modified Model3 can be used to classify areas into different price groups based on their features, meeting the specific requirements of the task.\n"
     ]
    }
   ],
   "source": [
    "print(res[\"output\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

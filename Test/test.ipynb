{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n",
    "FIRECRAWL_API_KEY='fc-e36282d62d1c4ee8971ec0649f3862c7'\n",
    "BASE_URL='https://api.groq.com/openai/v1'\n",
    "MODEL=\"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42744f82",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "91bed7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"/mnt/g/Ai agents course/LangGraph/Challenge2/data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "953cae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bá»‘i cáº£nh cá»§a váº¥n Ä‘á»:\\nÄiá»u quan trá»ng lÃ  cÃ¡c cÃ´ng ty tháº» tÃ­n dá»¥ng cÃ³ thá»ƒ nháº­n ra cÃ¡c giao dá»‹ch tháº» tÃ­n dá»¥ng gian láº­n Ä‘á»ƒ khÃ¡ch hÃ ng khÃ´ng pháº£i tráº£ tiá»n cho nhá»¯ng máº·t hÃ ng mÃ  há» khÃ´ng mua. Má»™t váº¥n Ä‘á» cá»§a task nÃ y lÃ  dá»¯ liá»‡u training khÃ¡ lÃ  Ã­t cho giao dá»‹ch gian láº­n gÃ¢y váº¥n Ä‘á» máº¥t cÃ¢n báº±ng nhÃ£n dá»¯ liá»‡u.\\n\\nYÃªu cáº§u cá»¥ thá»ƒ cáº§n Ä‘áº¡t Ä‘Æ°á»£c:\\nXÃ¢y dá»±ng má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng nháº­n Ä‘áº§u vÃ o lÃ  má»™t list cÃ¡c features liÃªn quan Ä‘áº¿n sá»± gian láº­n cá»§a giao dá»‹ch vÃ  Ä‘áº§u ra há»‡ thá»‘ng lÃ  phÃ¢n loáº¡i giao dá»‹ch cá»¥ thá»ƒ Ä‘Ã³ cÃ³ gian láº­n hay khÃ´ng\\nMÃ´ hÃ¬nh cáº§n xá»­ lÃ½ Ä‘áº§u vÃ o lÃ  1 list cÃ¡c feature liÃªn quan Ä‘áº¿n gian láº­n cá»§a giao dá»‹ch\\nÄáº§u ra lÃ  nhÃ£n cá»§a giao dá»‹ch Ä‘Ã³ thuá»™c vá»\\n\\nÄá»‹nh dáº¡ng dá»¯ liá»‡u Ä‘áº§u vÃ o cho bÃ i toÃ¡n tá»•ng thá»ƒ:\\nMá»™t file test.csv. Má»—i hÃ ng lÃ  features cho tá»«ng task bao gá»“m cÃ¡c cá»™t:\\n28 Ä‘áº·c trÆ°ng V1, V2, â€¦ V28 lÃ  cÃ¡c thÃ nh pháº§n chÃ­nh thu Ä‘Æ°á»£c tá»« PCA (KhÃ´ng Ä‘Æ°á»£c cÃ´ng bá»‘ cá»¥ thá»ƒ);  hai Ä‘áº·c trÆ°ng khÃ´ng Ä‘Æ°á»£c biáº¿n Ä‘á»•i báº±ng PCA lÃ  'Time' vÃ  'Amount'. Äáº·c trÆ°ng 'Time' thá»ƒ hiá»‡n sá»‘ giÃ¢y Ä‘Ã£ trÃ´i qua giá»¯a má»—i giao dá»‹ch vÃ  giao dá»‹ch Ä‘áº§u tiÃªn trong táº­p dá»¯ liá»‡u. Äáº·c trÆ°ng 'Amount' lÃ  sá»‘ tiá»n cá»§a giao dá»‹ch, Ä‘áº·c trÆ°ng nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho há»c táº­p nháº¡y cáº£m vá»›i chi phÃ­ phá»¥ thuá»™c vÃ o vÃ­ dá»¥ vÃ  cuá»‘i cÃ¹ng lÃ  ID: id cá»§a task\\n \\nÄá»‹nh dáº¡ng káº¿t quáº£ Ä‘áº§u ra mong muá»‘n cho bÃ i toÃ¡n tá»•ng thá»ƒ:\\nFile output.csv má»—i hÃ ng lÃ  káº¿t quáº£ dá»± Ä‘oÃ¡n má»—i task\\ncÃ³ cÃ¡c cá»™t:\\nID: id cá»§a task\\nclass: 1 náº¿u lÃ  giao dá»‹ch gian láº­n, 0 vá»›i trÆ°á»ng há»£p ngÆ°á»£c láº¡i\\n\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "af3bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str) -> str:\n",
    "    \"\"\"Get more details about the model using the model url\"\"\"\n",
    "    scraper = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "    scrape_status = scraper.scrape_url(\n",
    "        url,\n",
    "        formats=['markdown']\n",
    "    )\n",
    "    return scrape_status.markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "77f3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperParameters(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b6a0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = web_scraper('https://huggingface.co/thanhtlx/image_classification_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "52a9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_scrapper\",\n",
    "        func=web_scraper,\n",
    "        description=\"Use to get more detail about the model\",\n",
    "        args_schema=WebScraperParameters\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409f8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( \n",
    "    base_url=BASE_URL,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6511a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(BaseModel):\n",
    "    subtask_one: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 1\"\n",
    "    )\n",
    "    subtask_two: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 2\"\n",
    "    )\n",
    "    subtask_three: str = Field(\n",
    "        ...,\n",
    "        description=\"Detailed description of task 3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0de6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: HumanMessage | None\n",
    "    data: str | None\n",
    "    messages: Annotated[BaseMessage, add_messages]\n",
    "    subtasks: Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ef593964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_agent(state: AgentState) -> AgentState:\n",
    "    structured_llm = llm.with_structured_output(Tasks)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are an expert in task formulation. Given a machine learning task, you will\n",
    "                    help divide the task into these subtasks:\n",
    "                    - Subtask1: for classifying the problem type and task description\n",
    "                    - Subtask2: for identifying the input of the problem\n",
    "                    - Subtask3: for identifying the output of the problem\n",
    "                    describe the each subtask as specifically as possible\n",
    "                    \"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.append(state['task'])\n",
    "    result = structured_llm.invoke(messages)\n",
    "    state['subtasks'] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "14b15c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"task\": HumanMessage(content=task),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "78675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = classify_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd41986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_agent(state: AgentState) -> AgentState:\n",
    "    system_prompt = f\"\"\"\n",
    "                    You are a machine learning expert assigned to select the **best-fit model** for a given task.\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## ğŸ¯ Your Goal\n",
    "\n",
    "                    Given:\n",
    "                    - A user task description\n",
    "                    - A list of available models (names and links)\n",
    "                    - A tool that fetches model details from a provided URL (description, input/output format, usage code)\n",
    "\n",
    "                    Your job is to:\n",
    "                    1. Analyze the task and identify what type of problem it is (e.g., classification, regression, NLP, etc.)\n",
    "                    2. Select a small number of candidate models whose **name or purpose suggests relevance**\n",
    "                    3. Use the **provided tool** to retrieve real details about each candidate model:\n",
    "                        - âœ… Model description\n",
    "                        - ğŸ“¥ Input format\n",
    "                        - ğŸ“¤ Output format\n",
    "                        - ğŸ§ª Code sample (usage code snippet)\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## âš ï¸ VERY IMPORTANT RULES\n",
    "\n",
    "                    - âŒ DO NOT assume or invent any part of the model's description, input/output format, or code\n",
    "                    - âŒ DO NOT generate fake code or use your own knowledge about the model\n",
    "                    - âœ… ONLY use the **actual output** returned from the tool\n",
    "                    - âœ… Include tool content in your final answer exactly as returned (especially code)\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## ğŸ“¦ Available Models:\n",
    "\n",
    "                    {format_model_list(df_model)}\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ## ğŸ§  Output Structure (Final Answer)\n",
    "\n",
    "                    After retrieving tool results, choose ONE best-fit model and output the result in the following format:\n",
    "\n",
    "                    **âœ… Model name and link**  \n",
    "                    `<model name>` â€” `<link>`\n",
    "\n",
    "                    **ğŸ“ Description (from tool):**  \n",
    "                    <model description>\n",
    "\n",
    "                    **ğŸ“¥ Input format (from tool):**  \n",
    "                    <description of expected input>\n",
    "\n",
    "                    **ğŸ“¤ Output format (from tool):**  \n",
    "                    <description of model output>\n",
    "\n",
    "                    **ğŸ§ª Example code (from tool):**  \n",
    "                    ```python\n",
    "                    <exact code snippet from tool>\n",
    "                    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    task_input = state[\"task\"].content if isinstance(state[\"task\"], SystemMessage) else state[\"task\"]\n",
    "\n",
    "    result = executor.invoke({\"input\": task_input})\n",
    "\n",
    "    return {\"output\": result[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d8f92e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34131/7332665.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
      "/tmp/ipykernel_34131/7332665.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = str(row[2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_4'}`\n",
      "responded: To address the task of building a system that can identify fraudulent credit card transactions, we first need to understand the nature of the problem. It's a classification task where the goal is to predict whether a transaction is fraudulent or not based on a list of features related to the transaction.\n",
      "\n",
      "Given the problem description, the task seems to involve handling imbalanced data, where instances of fraudulent transactions are less common than legitimate ones. This is a common challenge in fraud detection.\n",
      "\n",
      "The input to the model is a list of features related to the transaction, specifically:\n",
      "- 28 features (V1, V2, â€¦, V28) derived from PCA\n",
      "- 'Time': the number of seconds elapsed between the transaction and the first transaction in the dataset\n",
      "- 'Amount': the amount of the transaction\n",
      "\n",
      "The output is a classification of the transaction as either fraudulent (1) or not (0).\n",
      "\n",
      "Let's analyze the available models:\n",
      "\n",
      "1. **Nháº­n diá»‡n áº£nh chá»¯ viáº¿t tay** â€” This seems unrelated to the task at hand.\n",
      "2. **PhÃ¢n loáº¡i vÄƒn báº£n thÃ nh cÃ¡c topic** â€” This is about text classification into topics, not relevant here.\n",
      "3. **Dá»± Ä‘oÃ¡n giÃ¡ trung bÃ¬nh nhÃ  á»Ÿ cÃ¡c quáº­n Cali** â€” This involves regression, predicting house prices, not relevant.\n",
      "4. **Dá»± Ä‘oÃ¡n giÃ¡ trung bÃ¬nh nhÃ  á»Ÿ cÃ¡c quáº­n Cali** â€” Similar to model 3, not relevant.\n",
      "5. **PhÃ¢n loáº¡i gian láº­n tháº» tÃ­n dá»¥ng** â€” **This directly matches our task**.\n",
      "6. **PhÃ¢n loáº¡i hÃ¬nh áº£nh** â€” This is about image classification, not relevant.\n",
      "7. **PhÃ¢n loáº¡i hÃ¬nh áº£nh thÃ nh100 lá»›p Ä‘á»‘i tÆ°á»£ng chi tiáº¿t (fine-grained),** â€” Also about image classification, not relevant.\n",
      "\n",
      "Based on the task description, the most suitable model seems to be model 5: **PhÃ¢n loáº¡i gian láº­n tháº» tÃ­n dá»¥ng**.\n",
      "\n",
      "Let's use the `web_scrapper` tool to get more details about model 5.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# ğŸ›¡ï¸ MÃ´ hÃ¬nh PhÃ¡t hiá»‡n Gian láº­n Tháº» TÃ­n dá»¥ng (Imbalanced Classification)\n",
      "\n",
      "## ğŸ“ MÃ´ táº£\n",
      "\n",
      "ÄÃ¢y lÃ  mÃ´ hÃ¬nh nhá»‹ phÃ¢n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n trong giao dá»‹ch tháº» tÃ­n dá»¥ng, sá»­ dá»¥ng táº­p dá»¯ liá»‡u tá»« Kaggle Credit Card Fraud Detection. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Keras vÃ  xá»­ lÃ½ váº¥n Ä‘á» dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nghiÃªm trá»ng (chá»‰ 0.18% giao dá»‹ch lÃ  gian láº­n).\n",
      "keras.io\n",
      "\n",
      "## ğŸ“Œ Nhiá»‡m vá»¥\n",
      "\n",
      "Loáº¡i bÃ i toÃ¡n: PhÃ¢n loáº¡i nhá»‹ phÃ¢n (gian láº­n / khÃ´ng gian láº­n)\n",
      "Dá»¯ liá»‡u Ä‘áº§u vÃ o: Dá»¯ liá»‡u dáº¡ng báº£ng vá»›i 30 Ä‘áº·c trÆ°ng Ä‘Ã£ Ä‘Æ°á»£c PCA hÃ³a\n",
      "Dá»¯ liá»‡u Ä‘áº§u ra: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n\n",
      "\n",
      "## ğŸ“¥ Äáº§u vÃ o\n",
      "\n",
      "Shape: \\[batch\\_size, 30\\]\n",
      "Kiá»ƒu dá»¯ liá»‡u: np.ndarray hoáº·c tf.Tensor\n",
      "Chuáº©n hÃ³a: Dá»¯ liá»‡u Ä‘áº§u vÃ o cáº§n Ä‘Æ°á»£c chuáº©n hÃ³a tÆ°Æ¡ng tá»± nhÆ° trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n\n",
      "\n",
      "## ğŸ“¤ Äáº§u ra\n",
      "\n",
      "Shape: \\[batch\\_size, 1\\]\n",
      "Ã nghÄ©a: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n (giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1)\n",
      "\n",
      "ğŸ›  YÃªu cáº§u thÆ° viá»‡n\n",
      "CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t báº±ng:\n",
      "\n",
      "```bash\n",
      "pip install tensorflow numpy\n",
      "\n",
      "```\n",
      "\n",
      "## ğŸ§ª CÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh\n",
      "\n",
      "DÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ vá» cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from huggingface_hub import from_pretrained_keras\n",
      "\n",
      "# Táº£i mÃ´ hÃ¬nh tá»« Hugging Face Hub\n",
      "model = from_pretrained_keras(\"zhaospei/Model_4\")\n",
      "model.summary()\n",
      "\n",
      "# Táº¡o dá»¯ liá»‡u Ä‘áº§u vÃ o máº«u (giÃ¡ trá»‹ ngáº«u nhiÃªn)\n",
      "x_input = np.random.normal(size=(1, 30)).astype(\"float32\")\n",
      "\n",
      "# Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh\n",
      "prediction = model.predict(x_input)\n",
      "print(f\"XÃ¡c suáº¥t gian láº­n: {pred.flatten()[0][0]:.4f}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month12\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [ğŸ™‹Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=zhaospei/Model_4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bzhaospei%2FModel_4%5D(%2Fzhaospei%2FModel_4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scrapper` with `{'url': 'https://huggingface.co/zhaospei/Model_4'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m**YAML Metadata**\n",
      "**Warning:**\n",
      "empty or missing yaml metadata in repo card\n",
      "( [https://huggingface.co/docs/hub/model-cards#model-card-metadata](https://huggingface.co/docs/hub/model-cards#model-card-metadata))\n",
      "\n",
      "# ğŸ›¡ï¸ MÃ´ hÃ¬nh PhÃ¡t hiá»‡n Gian láº­n Tháº» TÃ­n dá»¥ng (Imbalanced Classification)\n",
      "\n",
      "## ğŸ“ MÃ´ táº£\n",
      "\n",
      "ÄÃ¢y lÃ  mÃ´ hÃ¬nh nhá»‹ phÃ¢n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n trong giao dá»‹ch tháº» tÃ­n dá»¥ng, sá»­ dá»¥ng táº­p dá»¯ liá»‡u tá»« Kaggle Credit Card Fraud Detection. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Keras vÃ  xá»­ lÃ½ váº¥n Ä‘á» dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nghiÃªm trá»ng (chá»‰ 0.18% giao dá»‹ch lÃ  gian láº­n).\n",
      "keras.io\n",
      "\n",
      "## ğŸ“Œ Nhiá»‡m vá»¥\n",
      "\n",
      "Loáº¡i bÃ i toÃ¡n: PhÃ¢n loáº¡i nhá»‹ phÃ¢n (gian láº­n / khÃ´ng gian láº­n)\n",
      "Dá»¯ liá»‡u Ä‘áº§u vÃ o: Dá»¯ liá»‡u dáº¡ng báº£ng vá»›i 30 Ä‘áº·c trÆ°ng Ä‘Ã£ Ä‘Æ°á»£c PCA hÃ³a\n",
      "Dá»¯ liá»‡u Ä‘áº§u ra: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n\n",
      "\n",
      "## ğŸ“¥ Äáº§u vÃ o\n",
      "\n",
      "Shape: \\[batch\\_size, 30\\]\n",
      "Kiá»ƒu dá»¯ liá»‡u: np.ndarray hoáº·c tf.Tensor\n",
      "Chuáº©n hÃ³a: Dá»¯ liá»‡u Ä‘áº§u vÃ o cáº§n Ä‘Æ°á»£c chuáº©n hÃ³a tÆ°Æ¡ng tá»± nhÆ° trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n\n",
      "\n",
      "## ğŸ“¤ Äáº§u ra\n",
      "\n",
      "Shape: \\[batch\\_size, 1\\]\n",
      "Ã nghÄ©a: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n (giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1)\n",
      "\n",
      "ğŸ›  YÃªu cáº§u thÆ° viá»‡n\n",
      "CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t báº±ng:\n",
      "\n",
      "```bash\n",
      "pip install tensorflow numpy\n",
      "\n",
      "```\n",
      "\n",
      "## ğŸ§ª CÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh\n",
      "\n",
      "DÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ vá» cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from huggingface_hub import from_pretrained_keras\n",
      "\n",
      "# Táº£i mÃ´ hÃ¬nh tá»« Hugging Face Hub\n",
      "model = from_pretrained_keras(\"zhaospei/Model_4\")\n",
      "model.summary()\n",
      "\n",
      "# Táº¡o dá»¯ liá»‡u Ä‘áº§u vÃ o máº«u (giÃ¡ trá»‹ ngáº«u nhiÃªn)\n",
      "x_input = np.random.normal(size=(1, 30)).astype(\"float32\")\n",
      "\n",
      "# Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh\n",
      "prediction = model.predict(x_input)\n",
      "print(f\"XÃ¡c suáº¥t gian láº­n: {pred.flatten()[0][0]:.4f}\")\n",
      "\n",
      "```\n",
      "\n",
      "Downloads last month12\n",
      "\n",
      "\n",
      "Inference Providers [NEW](https://huggingface.co/docs/inference-providers)\n",
      "\n",
      "This model isn't deployed by any Inference Provider. [ğŸ™‹Ask for provider support](https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/new?title=zhaospei/Model_4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bzhaospei%2FModel_4%5D(%2Fzhaospei%2FModel_4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A)\n",
      "\n",
      "Inference providers allow you to run inference using different serverless providers.\u001b[0m\u001b[32;1m\u001b[1;3m**âœ… Model name and link**  \n",
      " `PhÃ¢n loáº¡i gian láº­n tháº» tÃ­n dá»¥ng` â€” `https://huggingface.co/zhaospei/Model_4`\n",
      "\n",
      " **ğŸ“ Description (from tool):**  \n",
      " ÄÃ¢y lÃ  mÃ´ hÃ¬nh nhá»‹ phÃ¢n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n trong giao dá»‹ch tháº» tÃ­n dá»¥ng, sá»­ dá»¥ng táº­p dá»¯ liá»‡u tá»« Kaggle Credit Card Fraud Detection. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Keras vÃ  xá»­ lÃ½ váº¥n Ä‘á» dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nghiÃªm trá»ng (chá»‰ 0.18% giao dá»‹ch lÃ  gian láº­n).\n",
      "\n",
      " **ğŸ“¥ Input format (from tool):**  \n",
      " Shape: [batch_size, 30]  \n",
      " Kiá»ƒu dá»¯ liá»‡u: np.ndarray hoáº·c tf.Tensor  \n",
      " Chuáº©n hÃ³a: Dá»¯ liá»‡u Ä‘áº§u vÃ o cáº§n Ä‘Æ°á»£c chuáº©n hÃ³a tÆ°Æ¡ng tá»± nhÆ° trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n\n",
      "\n",
      " **ğŸ“¤ Output format (from tool):**  \n",
      " Shape: [batch_size, 1]  \n",
      " Ã nghÄ©a: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n (giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1)\n",
      "\n",
      " **ğŸ§ª Example code (from tool):**  \n",
      " ```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from huggingface_hub import from_pretrained_keras\n",
      "\n",
      "# Táº£i mÃ´ hÃ¬nh tá»« Hugging Face Hub\n",
      "model = from_pretrained_keras(\"zhaospei/Model_4\")\n",
      "model.summary()\n",
      "\n",
      "# Táº¡o dá»¯ liá»‡u Ä‘áº§u vÃ o máº«u (giÃ¡ trá»‹ ngáº«u nhiÃªn)\n",
      "x_input = np.random.normal(size=(1, 30)).astype(\"float32\")\n",
      "\n",
      "# Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh\n",
      "prediction = model.predict(x_input)\n",
      "print(f\"XÃ¡c suáº¥t gian láº­n: {pred.flatten()[0][0]:.4f}\")\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = modeling_agent(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3da68bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': '**âœ… Model name and link**  \\n'\n",
      "           ' `PhÃ¢n loáº¡i gian láº­n tháº» tÃ­n dá»¥ng` â€” '\n",
      "           '`https://huggingface.co/zhaospei/Model_4`\\n'\n",
      "           '\\n'\n",
      "           ' **ğŸ“ Description (from tool):**  \\n'\n",
      "           ' ÄÃ¢y lÃ  mÃ´ hÃ¬nh nhá»‹ phÃ¢n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n '\n",
      "           'trong giao dá»‹ch tháº» tÃ­n dá»¥ng, sá»­ dá»¥ng táº­p dá»¯ liá»‡u tá»« Kaggle Credit '\n",
      "           'Card Fraud Detection. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Keras vÃ  xá»­ lÃ½ '\n",
      "           'váº¥n Ä‘á» dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nghiÃªm trá»ng (chá»‰ 0.18% giao dá»‹ch lÃ  '\n",
      "           'gian láº­n).\\n'\n",
      "           '\\n'\n",
      "           ' **ğŸ“¥ Input format (from tool):**  \\n'\n",
      "           ' Shape: [batch_size, 30]  \\n'\n",
      "           ' Kiá»ƒu dá»¯ liá»‡u: np.ndarray hoáº·c tf.Tensor  \\n'\n",
      "           ' Chuáº©n hÃ³a: Dá»¯ liá»‡u Ä‘áº§u vÃ o cáº§n Ä‘Æ°á»£c chuáº©n hÃ³a tÆ°Æ¡ng tá»± nhÆ° trong '\n",
      "           'quÃ¡ trÃ¬nh huáº¥n luyá»‡n\\n'\n",
      "           '\\n'\n",
      "           ' **ğŸ“¤ Output format (from tool):**  \\n'\n",
      "           ' Shape: [batch_size, 1]  \\n'\n",
      "           ' Ã nghÄ©a: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n (giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1)\\n'\n",
      "           '\\n'\n",
      "           ' **ğŸ§ª Example code (from tool):**  \\n'\n",
      "           ' ```python\\n'\n",
      "           'import numpy as np\\n'\n",
      "           'import tensorflow as tf\\n'\n",
      "           'from huggingface_hub import from_pretrained_keras\\n'\n",
      "           '\\n'\n",
      "           '# Táº£i mÃ´ hÃ¬nh tá»« Hugging Face Hub\\n'\n",
      "           'model = from_pretrained_keras(\"zhaospei/Model_4\")\\n'\n",
      "           'model.summary()\\n'\n",
      "           '\\n'\n",
      "           '# Táº¡o dá»¯ liá»‡u Ä‘áº§u vÃ o máº«u (giÃ¡ trá»‹ ngáº«u nhiÃªn)\\n'\n",
      "           'x_input = np.random.normal(size=(1, 30)).astype(\"float32\")\\n'\n",
      "           '\\n'\n",
      "           '# Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh\\n'\n",
      "           'prediction = model.predict(x_input)\\n'\n",
      "           'print(f\"XÃ¡c suáº¥t gian láº­n: {pred.flatten()[0][0]:.4f}\")\\n'\n",
      "           '```'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "41077f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**âœ… Model name and link**  \n",
      " `PhÃ¢n loáº¡i gian láº­n tháº» tÃ­n dá»¥ng` â€” `https://huggingface.co/zhaospei/Model_4`\n",
      "\n",
      " **ğŸ“ Description (from tool):**  \n",
      " ÄÃ¢y lÃ  mÃ´ hÃ¬nh nhá»‹ phÃ¢n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n trong giao dá»‹ch tháº» tÃ­n dá»¥ng, sá»­ dá»¥ng táº­p dá»¯ liá»‡u tá»« Kaggle Credit Card Fraud Detection. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Keras vÃ  xá»­ lÃ½ váº¥n Ä‘á» dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nghiÃªm trá»ng (chá»‰ 0.18% giao dá»‹ch lÃ  gian láº­n).\n",
      "\n",
      " **ğŸ“¥ Input format (from tool):**  \n",
      " Shape: [batch_size, 30]  \n",
      " Kiá»ƒu dá»¯ liá»‡u: np.ndarray hoáº·c tf.Tensor  \n",
      " Chuáº©n hÃ³a: Dá»¯ liá»‡u Ä‘áº§u vÃ o cáº§n Ä‘Æ°á»£c chuáº©n hÃ³a tÆ°Æ¡ng tá»± nhÆ° trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n\n",
      "\n",
      " **ğŸ“¤ Output format (from tool):**  \n",
      " Shape: [batch_size, 1]  \n",
      " Ã nghÄ©a: XÃ¡c suáº¥t giao dá»‹ch lÃ  gian láº­n (giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1)\n",
      "\n",
      " **ğŸ§ª Example code (from tool):**  \n",
      " ```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from huggingface_hub import from_pretrained_keras\n",
      "\n",
      "# Táº£i mÃ´ hÃ¬nh tá»« Hugging Face Hub\n",
      "model = from_pretrained_keras(\"zhaospei/Model_4\")\n",
      "model.summary()\n",
      "\n",
      "# Táº¡o dá»¯ liá»‡u Ä‘áº§u vÃ o máº«u (giÃ¡ trá»‹ ngáº«u nhiÃªn)\n",
      "x_input = np.random.normal(size=(1, 30)).astype(\"float32\")\n",
      "\n",
      "# Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh\n",
      "prediction = model.predict(x_input)\n",
      "print(f\"XÃ¡c suáº¥t gian láº­n: {pred.flatten()[0][0]:.4f}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(res[\"output\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

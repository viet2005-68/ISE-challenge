{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3e60a",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535f3e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python312.zip', '/usr/local/lib/python3.12', '/usr/local/lib/python3.12/lib-dynload', '', '/home/hieuclc/ise_chenla/venv/lib/python3.12/site-packages', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from firecrawl import FirecrawlApp\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "from tools.fetching_description_from_huggingface import fetching_description_from_huggingface\n",
    "load_dotenv(override = True)\n",
    "\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    temperature=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36830718",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5827b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Public task.csv\")\n",
    "df_model = pd.read_csv(\"data/ISE - AutoCode Challenge 2 Public - Model zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = df_task[\"Task\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6909b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_list(df):\n",
    "    model_strings = []\n",
    "    for i, row in df.iterrows():\n",
    "        desc = str(row[1]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        url = str(row[2])\n",
    "        model_strings.append(f\"{i + 1} - {desc} [More info]({url})\")\n",
    "    return \"\\n\".join(model_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c40886",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c27b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentCodingState(TypedDict):\n",
    "    problem_description: str\n",
    "    model_description: str\n",
    "    input_description: str\n",
    "    output_description: str\n",
    "    output_classes: str | None\n",
    "    code: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e762f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = r\"\"\"\n",
    "    You are a specialist in Machine Learning. Your task is to generate a **fully functional with all necessary imports and dependencies** codebase in **Python** that can be executed flawlessly.\n",
    "\n",
    "    You will be provided with:\n",
    "    - A problem description\n",
    "    - An input specification\n",
    "    - An output specification\n",
    "    - A model description\n",
    "\n",
    "    ### Input:\n",
    "    - Problem description: {problem_description}\n",
    "    - Model description: {model_description}\n",
    "    - Input specification: {input_description}\n",
    "    - Output specification: {output_description}\n",
    "    - Output classes: {output_classes}\n",
    "\n",
    "    ### Guidelines\n",
    "\n",
    "    You **must** strictly follow the following guidelines:\n",
    "    - The preprocessing step should be suitable for the data type.\n",
    "    - The postprocessing step should notices the differences between the data returned by the model and the output requirements. You must extract and use the exact class labels as defined in the output specification.\n",
    "    - Do **not invent new labels or translate** the class names. Use them exactly as given.\n",
    "\n",
    "    Your implementation **must strictly follow** the structure below:\n",
    "    1. **Imports**: All required libraries.\n",
    "    2. **Preprocessing**: Handle and transform the input as defined.\n",
    "    3. **Inference logic**: Use the described model for prediction. You **must** use `tqdm` or similar logging library to track progress.\n",
    "    4. **Postprocessing**: Format or transform the raw output into the final result as described.\n",
    "\n",
    "    You must **not** include any explanations, markdown, or logging outside what is required by the problem.\n",
    "\n",
    "    Return **only** the complete Python codebase. Wrap it with:\n",
    "    \\`\\`\\`python\n",
    "    # code here\n",
    "    \\`\\`\\`\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5143755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputState(TypedDict):\n",
    "    output_classes: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ca6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_agent(state: OutputState) -> OutputState:\n",
    "    prompt = r\"\"\"\n",
    "        Your are a specialist in machine learning. Your task is to identify the absolute classes of the given problem description, following with an output description.\n",
    "        ### Input:\n",
    "        - Problem description: {problem_description}\n",
    "        - Output description: {output_description}\n",
    "\n",
    "        You must return an array, strictly following these guidelines:\n",
    "        - Understand the context from the given problem description.\n",
    "        - Extract the class names from the output description. You **must not** invent new labels or translate the class names. Use them exactly as given in the output description.\n",
    "        - Create an array containing the classes.\n",
    "\n",
    "        You must return only the array containing those classes, without any formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt.format(\n",
    "        problem_description = state[\"problem_description\"],\n",
    "        output_description = state[\"output_description\"]\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"output_classes\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3ba2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_state = {\n",
    "    \"problem_description\": \"\"\"B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\n",
    "        Nh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay l√† m·ªôt b√†i to√°n c∆° b·∫£n trong lƒ©nh v·ª±c h·ªçc m√°y v√† x·ª≠ l√Ω ·∫£nh, v·ªõi nhi·ªÅu ·ª©ng d·ª•ng th·ª±c ti·ªÖn nh∆∞ nh·∫≠n d·∫°ng ch·ªØ s·ªë tr√™n phi·∫øu kh·∫£o s√°t, h√≥a ƒë∆°n hay b√†i thi t·ª± ƒë·ªông. Vi·ªác ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay th√†nh s·ªë nguy√™n t·ªë ho·∫∑c kh√¥ng gi√∫p m·ªü r·ªông kh·∫£ nƒÉng ·ª©ng d·ª•ng trong c√°c b√†i to√°n to√°n h·ªçc t·ª± ƒë·ªông, ki·ªÉm tra b√†i t·∫≠p, ho·∫∑c c√°c ·ª©ng d·ª•ng gi√°o d·ª•c.\n",
    "\n",
    "        Y√™u c·∫ßu c·ª• th·ªÉ c·∫ßn ƒë·∫°t ƒë∆∞·ª£c:\n",
    "        X√¢y d·ª±ng m·ªôt h·ªá th·ªëng c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ ·∫£nh v√† x√°c ƒë·ªãnh xem s·ªë ƒë√≥ c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng.\n",
    "        ƒê·∫ßu v√†o l√† ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay.\n",
    "        ƒê·∫ßu ra l√† nh√£n ph√¢n lo·∫°i nh·ªã ph√¢n: \"\"\"\"nguy√™n t·ªë\"\"\"\" ho·∫∑c \"\"\"\"kh√¥ng nguy√™n t·ªë\"\"\"\".\n",
    "\n",
    "        ƒê·ªãnh d·∫°ng d·ªØ li·ªáu ƒë·∫ßu v√†o cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        M·ªôt th∆∞ m·ª•c c√≥ t√™n l√† \"\"\"\"images\"\"\"\" ch·ª©a c√°c ·∫£nh grayscale 28x28 pixel, m·ªói ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9.\n",
    "\n",
    "        ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ƒë·∫ßu ra mong mu·ªën cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        File output.csv m·ªói h√†ng l√† k·∫øt qu·∫£ d·ª± ƒëo√°n m·ªói ·∫£nh\n",
    "        c√≥ c√°c c·ªôt:\n",
    "        file_name: t√™n file ·∫£nh\n",
    "        prediction: nh√£n c·ªßa ·∫£nh:\n",
    "        \"\"\"\"s·ªë nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh l√† s·ªë nguy√™n t·ªë.\n",
    "        \"\"\"\"kh√¥ng nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh kh√¥ng ph·∫£i s·ªë nguy√™n t·ªë.\"\"\",\n",
    "    \"output_description\": \"\"\"ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ƒë·∫ßu ra mong mu·ªën cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        File output.csv m·ªói h√†ng l√† k·∫øt qu·∫£ d·ª± ƒëo√°n m·ªói ·∫£nh\n",
    "        c√≥ c√°c c·ªôt:\n",
    "        file_name: t√™n file ·∫£nh\n",
    "        prediction: nh√£n c·ªßa ·∫£nh:\n",
    "        \"\"\"\"s·ªë nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh l√† s·ªë nguy√™n t·ªë.\n",
    "        \"\"\"\"kh√¥ng nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh kh√¥ng ph·∫£i s·ªë nguy√™n t·ªë.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "151e4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = output_agent(output_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c5f0050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"s·ªë nguy√™n t·ªë\", \"kh√¥ng nguy√™n t·ªë\"]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[\"output_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c501f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_agent(state: AgentCodingState) -> AgentCodingState:\n",
    "    prompt = base_prompt.format(\n",
    "        problem_description = state[\"problem_description\"],\n",
    "        model_description = state[\"model_description\"],\n",
    "        input_description = state[\"input_description\"],\n",
    "        output_description = state[\"output_description\"],\n",
    "        output_classes = state[\"output_classes\"]\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"code\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2be5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_state = {\n",
    "    \"problem_description\": \"\"\"B·ªëi c·∫£nh c·ªßa v·∫•n ƒë·ªÅ:\n",
    "        Nh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay l√† m·ªôt b√†i to√°n c∆° b·∫£n trong lƒ©nh v·ª±c h·ªçc m√°y v√† x·ª≠ l√Ω ·∫£nh, v·ªõi nhi·ªÅu ·ª©ng d·ª•ng th·ª±c ti·ªÖn nh∆∞ nh·∫≠n d·∫°ng ch·ªØ s·ªë tr√™n phi·∫øu kh·∫£o s√°t, h√≥a ƒë∆°n hay b√†i thi t·ª± ƒë·ªông. Vi·ªác ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay th√†nh s·ªë nguy√™n t·ªë ho·∫∑c kh√¥ng gi√∫p m·ªü r·ªông kh·∫£ nƒÉng ·ª©ng d·ª•ng trong c√°c b√†i to√°n to√°n h·ªçc t·ª± ƒë·ªông, ki·ªÉm tra b√†i t·∫≠p, ho·∫∑c c√°c ·ª©ng d·ª•ng gi√°o d·ª•c.\n",
    "\n",
    "        Y√™u c·∫ßu c·ª• th·ªÉ c·∫ßn ƒë·∫°t ƒë∆∞·ª£c:\n",
    "        X√¢y d·ª±ng m·ªôt h·ªá th·ªëng c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay t·ª´ ·∫£nh v√† x√°c ƒë·ªãnh xem s·ªë ƒë√≥ c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng.\n",
    "        ƒê·∫ßu v√†o l√† ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay.\n",
    "        ƒê·∫ßu ra l√† nh√£n ph√¢n lo·∫°i nh·ªã ph√¢n: \"\"\"\"nguy√™n t·ªë\"\"\"\" ho·∫∑c \"\"\"\"kh√¥ng nguy√™n t·ªë\"\"\"\".\n",
    "\n",
    "        ƒê·ªãnh d·∫°ng d·ªØ li·ªáu ƒë·∫ßu v√†o cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        M·ªôt th∆∞ m·ª•c c√≥ t√™n l√† \"\"\"\"images\"\"\"\" ch·ª©a c√°c ·∫£nh grayscale 28x28 pixel, m·ªói ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9.\n",
    "\n",
    "        ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ƒë·∫ßu ra mong mu·ªën cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        File output.csv m·ªói h√†ng l√† k·∫øt qu·∫£ d·ª± ƒëo√°n m·ªói ·∫£nh\n",
    "        c√≥ c√°c c·ªôt:\n",
    "        file_name: t√™n file ·∫£nh\n",
    "        prediction: nh√£n c·ªßa ·∫£nh:\n",
    "        \"\"\"\"s·ªë nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh l√† s·ªë nguy√™n t·ªë.\n",
    "        \"\"\"\"kh√¥ng nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh kh√¥ng ph·∫£i s·ªë nguy√™n t·ªë.\"\"\",\n",
    "    \"model_description\": \"\"\"Image Classification Model - Handwritten Digit Recognition (Color Images)\n",
    "        üìù M√¥ t·∫£\n",
    "        ƒê√¢y l√† m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n di·ªán c√°c ch·ªØ s·ªë vi·∫øt tay (t·ª´ 0 ƒë·∫øn 9) trong ·∫£nh m√†u. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c Vision Transformer (ViT) v√† ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi t·∫≠p d·ªØ li·ªáu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay ƒë∆∞·ª£c ch·ª•p ho·∫∑c scan d∆∞·ªõi d·∫°ng ·∫£nh m√†u.\n",
    "        üìå Chi ti·∫øt c√°c m√¥ h√¨nh\n",
    "        Ph√¢n lo·∫°i ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9\n",
    "        üì• ƒê·∫ßu v√†o\n",
    "        ƒê·ªãnh d·∫°ng: ·∫¢nh m√†u (RGB)\n",
    "        Ki·ªÉu d·ªØ li·ªáu: PIL.Image.Image\n",
    "        K√≠ch th∆∞·ªõc ·∫£nh: M√¥ h√¨nh s·∫Ω t·ª± resize theo c·∫•u h√¨nh c·ªßa ViTImageProcessor (th∆∞·ªùng l√† 224x224)\n",
    "        Gi√° tr·ªã pixel: [0, 255] (chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi processor)\n",
    "        üì§ ƒê·∫ßu ra\n",
    "        M·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9, l√† k·∫øt qu·∫£ ph√¢n lo·∫°i t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë xu·∫•t hi·ªán trong ·∫£nh.\n",
    "        üõ† Y√™u c·∫ßu th∆∞ vi·ªán\n",
    "        C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán sau b·∫±ng pip:\n",
    "        pip install transformers torch\n",
    "        üß™ S·ª≠ d·ª•ng m√¥ h√¨nh\n",
    "        D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n m√£ m·∫´u ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh:\n",
    "        from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "        from PIL import Image\n",
    "        import torch\n",
    "        model_name = \"thanhtlx/image_classification_01\"\n",
    "        model = ViTForImageClassification.from_pretrained(model_name)\n",
    "        processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "        # ƒê·ªçc ·∫£nh c·∫ßn ph√¢n lo·∫°i\n",
    "        image = Image.open(\"images.png\")\n",
    "        # X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "        predicted_class = outputs.logits.argmax(-1).item()\n",
    "        print(f\"prediction: {predicted_class}\")\"\"\",\n",
    "    \"input_description\": \"\"\"ƒê·ªãnh d·∫°ng d·ªØ li·ªáu ƒë·∫ßu v√†o cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        M·ªôt th∆∞ m·ª•c c√≥ t√™n l√† \"\"\"\"images\"\"\"\" ch·ª©a c√°c ·∫£nh grayscale 28x28 pixel, m·ªói ·∫£nh ch·ª©a m·ªôt ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9.\"\"\",\n",
    "    \"output_description\": \"\"\"ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ƒë·∫ßu ra mong mu·ªën cho b√†i to√°n t·ªïng th·ªÉ:\n",
    "        File output.csv m·ªói h√†ng l√† k·∫øt qu·∫£ d·ª± ƒëo√°n m·ªói ·∫£nh\n",
    "        c√≥ c√°c c·ªôt:\n",
    "        file_name: t√™n file ·∫£nh\n",
    "        prediction: nh√£n c·ªßa ·∫£nh:\n",
    "        \"\"\"\"s·ªë nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh l√† s·ªë nguy√™n t·ªë.\n",
    "        \"\"\"\"kh√¥ng nguy√™n t·ªë\"\"\"\" n·∫øu s·ªë trong ·∫£nh kh√¥ng ph·∫£i s·ªë nguy√™n t·ªë.\"\"\",\n",
    "    \"output_classes\": new_state[\"output_classes\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77f913b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = coding_agent(prev_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1537d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed5049dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import os\n",
      "import csv\n",
      "from tqdm import tqdm\n",
      "from PIL import Image\n",
      "import torch\n",
      "from transformers import ViTForImageClassification, ViTImageProcessor\n",
      "\n",
      "# Load the pre-trained model and processor\n",
      "model_name = \"thanhtlx/image_classification_01\"\n",
      "model = ViTForImageClassification.from_pretrained(model_name)\n",
      "processor = ViTImageProcessor.from_pretrained(model_name)\n",
      "model.eval()\n",
      "\n",
      "# Define the directory containing images\n",
      "images_dir = \"images\"\n",
      "# Define output CSV file\n",
      "output_csv = \"output.csv\"\n",
      "\n",
      "# Function to check if a number is prime\n",
      "def is_prime(n):\n",
      "    if n < 2:\n",
      "        return False\n",
      "    if n == 2:\n",
      "        return True\n",
      "    if n % 2 == 0:\n",
      "        return False\n",
      "    sqrt_n = int(n ** 0.5) + 1\n",
      "    for i in range(3, sqrt_n, 2):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "# Prepare list to hold results\n",
      "results = []\n",
      "\n",
      "# List all image files in the directory\n",
      "image_files = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
      "\n",
      "# Process each image\n",
      "for file_name in tqdm(image_files, desc=\"Processing images\"):\n",
      "    image_path = os.path.join(images_dir, file_name)\n",
      "    # Open image\n",
      "    image = Image.open(image_path).convert(\"RGB\")\n",
      "    # Process image\n",
      "    inputs = processor(images=image, return_tensors=\"pt\")\n",
      "    # Perform inference\n",
      "    with torch.no_grad():\n",
      "        outputs = model(**inputs)\n",
      "    predicted_class = outputs.logits.argmax(-1).item()\n",
      "    # Determine if the predicted digit is prime\n",
      "    if is_prime(predicted_class):\n",
      "        prediction_label = \"s·ªë nguy√™n t·ªë\"\n",
      "    else:\n",
      "        prediction_label = \"kh√¥ng nguy√™n t·ªë\"\n",
      "    # Append result\n",
      "    results.append({\"file_name\": file_name, \"prediction\": prediction_label})\n",
      "\n",
      "# Write results to CSV\n",
      "with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
      "    writer = csv.DictWriter(csvfile, fieldnames=[\"file_name\", \"prediction\"])\n",
      "    writer.writeheader()\n",
      "    for row in results:\n",
      "        writer.writerow(row)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(state[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93fcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
